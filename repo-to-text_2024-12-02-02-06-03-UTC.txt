Directory: DiffAbXL

Directory Structure:
```
.
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ assets
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ assets/diffabxl_results1.png
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ assets/diffabxl_results2.png
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ assets/qr_img.png
‚îú‚îÄ‚îÄ AUTHORS.md
‚îú‚îÄ‚îÄ compute_loglikelihood.py
‚îú‚îÄ‚îÄ config
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ config/sabdab.yaml
‚îú‚îÄ‚îÄ CONTRIBUTING.md
‚îú‚îÄ‚îÄ environment.yml
‚îú‚îÄ‚îÄ foldseek
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ foldseek/bin
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ foldseek/bin/foldseek
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ foldseek/README.md
‚îú‚îÄ‚îÄ foldseek-linux-avx2.tar.gz
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ prepare_data.py
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ src
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ src/model.py
‚îú‚îÄ‚îÄ train.py
‚îî‚îÄ‚îÄ utils
    ‚îú‚îÄ‚îÄ utils/arguments.py
    ‚îú‚îÄ‚îÄ utils/geometry.py
    ‚îú‚îÄ‚îÄ utils/load_data.py
    ‚îú‚îÄ‚îÄ utils/loss_functions.py
    ‚îú‚îÄ‚îÄ utils/model_utils.py
    ‚îú‚îÄ‚îÄ utils/protein_constants.py
    ‚îú‚îÄ‚îÄ utils/transformations.py
    ‚îú‚îÄ‚îÄ utils/utils_diff.py
    ‚îî‚îÄ‚îÄ utils/utils.py
```

Contents of compute_loglikelihood.py:
```
"""
Author: Talip Ucar
email: ucabtuc@gmail.com

Description: Sample script to compute log-likelihood.
"""

import torch


def compute_log_likelihood(sequence_tokens_list, posterior_list, parent_aa_list=None):
    """
    Compute the log-likelihood for each sequence in the batch.

    Args:
        sequence_tokens_list (list of Tensors): List of tensors of size (batch_size_i, sequence_length) containing sequence tokens.
        posterior_list (list of Tensors): List of tensors of size (batch_size_i, sequence_length, 20) containing posterior probabilities over amino acids.
        parent_aa_list (list of Tensors, optional): List of tensors containing parent amino acid tokens.

    Returns:
        log_likelihoods (Tensor): Tensor of log-likelihood values for the batch.
        log_likelihood_per_position (Tensor): Tensor of log-likelihood per position.
    """
    # Concatenate the list of tensors along the batch dimension
    sequence_tokens = torch.cat(sequence_tokens_list, dim=0)
    posterior = torch.cat(posterior_list, dim=0)

    # Compute log probabilities from posterior
    log_posterior = torch.log(posterior + 1e-9)  # Avoid log(0) by adding a small epsilon
    log_posterior = log_posterior.sum(0).unsqueeze(0).repeat(sequence_tokens.size(0), 1, 1)

    # Gather the log probabilities corresponding to the actual sequence tokens
    log_likelihood_per_position = torch.gather(
        log_posterior, dim=2, index=sequence_tokens.unsqueeze(-1)
    ).squeeze(-1)

    if parent_aa_list is not None and len(parent_aa_list) > 0:
        parent_aa_tokens = torch.cat(parent_aa_list, dim=0)
        parent_log_likelihood_per_position = torch.gather(
            log_posterior, dim=2, index=parent_aa_tokens.unsqueeze(-1)
        ).squeeze(-1)
        log_likelihood_per_position = log_likelihood_per_position - parent_log_likelihood_per_position

    # Sum the log-likelihood over the sequence length to get the total log-likelihood for each sequence
    log_likelihoods = log_likelihood_per_position.sum(dim=1)

    return log_likelihoods, log_likelihood_per_position

```

Contents of prepare_data.py:
```
#!/usr/bin/env python
"""
Data preparation script for DiffAbXL training using Foldseek for structural clustering.
Downloads and processes SAbDab dataset and splits data based on structural similarity.

Author: Assistant
Updated: 2024-11-30
"""

import os
import sys
import time
import argparse
import logging
import pickle
import lmdb
import yaml
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Set
from Bio import PDB
from Bio.PDB.Polypeptide import is_aa
from Bio.Data.IUPACData import protein_letters_3to1
import torch
from tqdm.auto import tqdm
import urllib.request
import urllib.error
import gzip
import shutil
import concurrent.futures
from datetime import datetime
import random
import subprocess
from Bio.PDB import PDBIO, Select, StructureBuilder
import copy


# Constants
SABDAB_BASE_URL = "https://opig.stats.ox.ac.uk/webapps/abdb"
SABDAB_SUMMARY_URL = "https://opig.stats.ox.ac.uk/webapps/newsabdab/sabdab/summary/all"
SABDAB_STRUCTURE_URL = f"{SABDAB_BASE_URL}/entries"
MAX_RETRIES = 3
RETRY_DELAY = 5  # seconds
MAX_WORKERS = 4

# HTTP Headers for requests
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'Connection': 'keep-alive',
}

class DataPreparationError(Exception):
    """Custom exception for data preparation errors."""
    pass

def setup_logger(log_dir: str, debug: bool = False) -> logging.Logger:
    """Set up logging configuration."""
    os.makedirs(log_dir, exist_ok=True)
    log_file = os.path.join(log_dir, f'data_prep_{datetime.now():%Y%m%d_%H%M%S}.log')
    
    level = logging.DEBUG if debug else logging.INFO
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler(log_file)
        ]
    )
    return logging.getLogger(__name__)

def three_to_one(residue_name: str) -> str:
    """Convert three-letter amino acid code to one-letter code."""
    return protein_letters_3to1.get(residue_name.upper(), 'X')

def download_with_retry(url: str, max_retries: int = MAX_RETRIES) -> bytes:
    """Download with retry logic and proper error handling."""
    last_exception = None
    
    # Create an opener that handles redirects
    opener = urllib.request.build_opener(urllib.request.HTTPRedirectHandler())
    urllib.request.install_opener(opener)
    
    for attempt in range(max_retries):
        try:
            req = urllib.request.Request(url, headers=HEADERS)
            with opener.open(req) as response:
                return response.read()
                
        except urllib.error.HTTPError as e:
            if e.code == 429:  # Too Many Requests
                wait_time = (attempt + 1) * RETRY_DELAY
                logger.warning(f"Rate limited. Waiting {wait_time} seconds...")
                time.sleep(wait_time)
                continue
            elif e.code == 308:  # Permanent Redirect
                if 'Location' in e.headers:
                    url = e.headers['Location']
                    logger.info(f"Following redirect to {url}")
                    continue
            last_exception = e
        except Exception as e:
            if attempt < max_retries - 1:
                time.sleep(RETRY_DELAY)
                continue
            last_exception = e
            
    raise DataPreparationError(f"Failed to download after {max_retries} attempts: {last_exception}")

def inspect_structure(pdb_path: str) -> Dict[str, List[str]]:
    """Inspect a PDB file to determine available chains and their types."""
    parser = PDB.PDBParser(QUIET=True)
    try:
        structure = parser.get_structure('protein', pdb_path)
        chain_info = {'chains': [], 'ids': []}
        
        for chain in structure[0]:
            chain_info['chains'].append(chain)
            chain_info['ids'].append(chain.id)
            
        logger.debug(f"Found chains in {pdb_path}: {chain_info['ids']}")
        return chain_info
    except Exception as e:
        logger.error(f"Error inspecting {pdb_path}: {e}")
        return None

def download_sabdab_summary(output_file: str):
    """Download the SAbDab summary file."""
    try:
        logger.info("Downloading SAbDab summary...")
        
        content = download_with_retry(SABDAB_SUMMARY_URL)
        
        # Save the content
        with open(output_file, 'wb') as f:
            f.write(content)
        
        # Verify file content
        with open(output_file) as f:
            header = f.readline().strip().split('\t')
            if not all(field in header for field in ['pdb', 'Hchain', 'Lchain']):
                raise DataPreparationError("Downloaded summary file has incorrect format")
                
        logger.info(f"Successfully downloaded summary file to {output_file}")
        
    except Exception as e:
        logger.error(f"Failed to download SAbDab summary: {e}")
        if os.path.exists(output_file):
            os.remove(output_file)
        raise DataPreparationError("Could not download SAbDab summary file")

def download_pdb(pdb_id: str, output_dir: str) -> bool:
    """Download individual PDB file."""
    pdb_id = pdb_id.lower()
    output_path = os.path.join(output_dir, f"{pdb_id}.pdb")
    
    if os.path.exists(output_path):
        return True
        
    try:
        # Try downloading Chothia numbered version first
        url = f"{SABDAB_STRUCTURE_URL}/{pdb_id}/structure/chothia/{pdb_id}.pdb"
        
        content = download_with_retry(url)
        
        # Save the content
        with open(output_path, 'wb') as f:
            f.write(content)
        
        # Verify file contains ATOM records
        with open(output_path) as f:
            file_content = f.read()
            if "ATOM" not in file_content:
                logger.error(f"Downloaded file for {pdb_id} contains no ATOM records")
                os.remove(output_path)
                return False
            
        return True
        
    except Exception as e:
        logger.error(f"Failed to download {pdb_id}: {e}")
        if os.path.exists(output_path):
            os.remove(output_path)
        return False

class AntibodyStructureProcessor:
    """
    Process antibody structures into the required format.

    Parameters
    ----------
    config : dict
        Configuration dictionary containing model hyperparameters and settings.
    """
    def __init__(self, config):
        self.config = config
        self.parser = PDB.PDBParser(QUIET=True)
        self.max_atoms = config.get('max_num_heavyatoms', 15)
        self.atom_order = ['N', 'CA', 'C', 'O', 'CB']
    
    def process_structure(self, pdb_path: str, heavy_chain: str = None, 
                        light_chain: str = None, antigen_chains: List[str] = None) -> Dict:
        """
        Process a PDB structure into the required format.

        Parameters
        ----------
        pdb_path : str
            Path to the PDB file
        heavy_chain : str, optional
            Chain ID for heavy chain
        light_chain : str, optional
            Chain ID for light chain
        antigen_chains : List[str], optional
            List of chain IDs for antigens

        Returns
        -------
        Dict
            Processed structure dictionary
        """
        try:
            # First inspect the structure
            chain_info = inspect_structure(pdb_path)
            if not chain_info:
                raise DataPreparationError("Failed to inspect structure")

            structure = self.parser.get_structure('protein', pdb_path)
            
            struct_dict = {
                'heavy': None,
                'light': None,
                'structure_type': 'A',
                'light_ctype': None,
                'antigen': [],
                'cdr_sequences': {'heavy': {}, 'light': {}},
                'cdr_structures': {'heavy': {}, 'light': {}},
                'cdr_residues': {'heavy': {}, 'light': {}}
            }
            
            chains = structure[0]
            
            # Process heavy chain
            if heavy_chain and heavy_chain in chains:
                try:
                    heavy_chain_data = self._process_chain(chains[heavy_chain], 'heavy')
                    struct_dict['heavy'] = heavy_chain_data
                    # Extract CDR sequences and residues
                    cdr_sequences, cdr_residues = self._extract_cdrs(chains[heavy_chain], 'heavy')
                    struct_dict['cdr_sequences']['heavy'] = cdr_sequences
                    struct_dict['cdr_residues']['heavy'] = cdr_residues
                except Exception as e:
                    logger.error(f"Error processing heavy chain in {pdb_path}: {str(e)}")
                    struct_dict['heavy'] = None

            # Process light chain
            if light_chain and light_chain in chains:
                try:
                    light_chain_data = self._process_chain(chains[light_chain], 'light')
                    struct_dict['light'] = light_chain_data
                    struct_dict['light_ctype'] = self._get_light_chain_type(chains[light_chain])
                    # Extract CDR sequences and residues
                    cdr_sequences, cdr_residues = self._extract_cdrs(chains[light_chain], 'light')
                    struct_dict['cdr_sequences']['light'] = cdr_sequences
                    struct_dict['cdr_residues']['light'] = cdr_residues
                except Exception as e:
                    logger.error(f"Error processing light chain in {pdb_path}: {str(e)}")
                    struct_dict['light'] = None

            # Process antigen chains if needed
            if antigen_chains:
                for chain_id in antigen_chains:
                    if chain_id in chains:
                        try:
                            antigen_data = self._process_chain(chains[chain_id], 'antigen')
                            struct_dict['antigen'].append(antigen_data)
                        except Exception as e:
                            logger.error(f"Error processing antigen chain {chain_id} in {pdb_path}: {str(e)}")
            
            # Return structure only if at least one chain was processed successfully
            if struct_dict['heavy'] is not None or struct_dict['light'] is not None:
                return struct_dict
            else:
                raise DataPreparationError("No antibody chains were processed successfully")
                
        except Exception as e:
            raise DataPreparationError(f"Error processing {pdb_path}: {str(e)}")

    def _process_chain(self, chain, chain_type: str) -> Dict:
        """
        Process a single chain.

        Parameters
        ----------
        chain : Bio.PDB.Chain
            Chain to process
        chain_type : str
            Type of chain ('heavy', 'light', or 'antigen')

        Returns
        -------
        Dict
            Processed chain data
        """
        try:
            residues = [res for res in chain if is_aa(res, standard=True)]
            if not residues:
                raise DataPreparationError(f"No standard amino acids found in chain {chain.id}")

            aa_list = []
            pos_list = []
            mask_list = []
            resseq_list = []
            icode_list = []

            for residue in residues:
                aa = three_to_one(residue.get_resname())
                aa_list.append(self._aa_to_idx(aa))

                pos, mask = self._process_atoms(residue)
                pos_list.append(pos)
                mask_list.append(mask)

                resseq_list.append(residue.id[1])
                icode_list.append(residue.id[2])

            # Create chain dictionary
            chain_dict = {
                'aa': torch.tensor(aa_list, dtype=torch.long),
                'pos_heavyatom': torch.tensor(np.array(pos_list), dtype=torch.float),
                'mask_heavyatom': torch.tensor(np.array(mask_list), dtype=torch.bool),
                'chain_id': [chain.id] * len(aa_list),
                'resseq': resseq_list,
                'icode': icode_list,
                'res_nb': torch.tensor(resseq_list, dtype=torch.long)
            }

            # Initialize CDR locations for antibody chains
            if chain_type in ['heavy', 'light']:
                chain_dict['cdr_locations'] = self._get_cdr_locations(chain_dict, chain_type)

            return chain_dict

        except Exception as e:
            raise DataPreparationError(f"Error processing chain {chain.id}: {str(e)}")

    def _process_atoms(self, residue: PDB.Residue.Residue) -> Tuple[np.ndarray, np.ndarray]:
        """
        Process atoms in a residue.

        Parameters
        ----------
        residue : Bio.PDB.Residue
            Residue to process

        Returns
        -------
        Tuple[np.ndarray, np.ndarray]
            Arrays of atomic positions and masks
        """
        pos = np.zeros((self.max_atoms, 3))
        mask = np.zeros(self.max_atoms, dtype=bool)
        
        # Process backbone and CB atoms first
        for idx, atom_name in enumerate(self.atom_order):
            if atom_name in residue:
                pos[idx] = residue[atom_name].get_coord()
                mask[idx] = True
        
        # Process remaining heavy atoms
        idx = len(self.atom_order)
        for atom in residue:
            if idx >= self.max_atoms:
                break
            if atom.name not in self.atom_order and not atom.element == 'H':
                pos[idx] = atom.get_coord()
                mask[idx] = True
                idx += 1
                
        return pos, mask

    def _aa_to_idx(self, aa: str) -> int:
        """Convert amino acid one-letter code to index."""
        aa_dict = {
            'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4,
            'G': 5, 'H': 6, 'I': 7, 'K': 8, 'L': 9,
            'M': 10, 'N': 11, 'P': 12, 'Q': 13, 'R': 14,
            'S': 15, 'T': 16, 'V': 17, 'W': 18, 'Y': 19,
            'X': 20
        }
        return aa_dict.get(aa, 20)

    def _get_light_chain_type(self, chain: PDB.Chain.Chain) -> str:
        """Determine the light chain type (kappa or lambda)."""
        sequence = ''
        for residue in chain:
            if is_aa(residue, standard=True):
                aa = three_to_one(residue.get_resname())
                sequence += aa

        # Use sequence motifs to determine the light chain type
        kappa_motifs = ['TVS', 'TVT', 'VTV', 'VSV']
        lambda_motifs = ['TIS', 'TIT', 'VTI', 'VSI']
        
        kappa_score = sum(sequence.count(motif) for motif in kappa_motifs)
        lambda_score = sum(sequence.count(motif) for motif in lambda_motifs)
        
        if kappa_score > lambda_score:
            return 'K'
        elif lambda_score > kappa_score:
            return 'L'
        else:
            return 'K'  # Default to kappa if scores are equal

    def _extract_cdrs(self, chain, chain_type: str) -> Tuple[Dict[str, str], Dict[str, List[PDB.Residue.Residue]]]:
        """
        Extract CDR sequences and residues.

        Parameters
        ----------
        chain : Bio.PDB.Chain
            Chain to process
        chain_type : str
            Type of chain ('heavy' or 'light')

        Returns
        -------
        Tuple[Dict[str, str], Dict[str, List[Bio.PDB.Residue]]]
            CDR sequences and residues
        """
        try:
            cdr_sequences = {}
            cdr_residues = {}
            cdr_definitions = self._get_cdr_definitions(chain_type)
            
            # Get residue numbers as a list for easier lookup
            residue_list = [res for res in chain if is_aa(res, standard=True)]
            
            for cdr_name, (start_resseq, end_resseq) in cdr_definitions.items():
                sequence = ''
                residues = []
                
                # Find residues within CDR range
                for residue in residue_list:
                    resseq = residue.id[1]
                    if start_resseq <= resseq <= end_resseq:
                        try:
                            aa = three_to_one(residue.get_resname())
                            sequence += aa
                            residues.append(residue)
                        except Exception as e:
                            logger.warning(f"Could not process residue {residue.get_resname()} in CDR {cdr_name}: {str(e)}")
                            continue
                
                if sequence and residues:  # Only add if we found valid residues
                    cdr_sequences[cdr_name] = sequence
                    cdr_residues[cdr_name] = residues
            
            return cdr_sequences, cdr_residues
            
        except Exception as e:
            raise DataPreparationError(f"Error extracting CDRs: {str(e)}")

    def _get_cdr_definitions(self, chain_type: str) -> Dict[str, Tuple[int, int]]:
        """Get CDR definitions based on Chothia numbering scheme."""
        if chain_type == 'heavy':
            return {
                'CDR-H1': (26, 32),
                'CDR-H2': (52, 56),
                'CDR-H3': (95, 102)
            }
        elif chain_type == 'light':
            return {
                'CDR-L1': (24, 34),
                'CDR-L2': (50, 56),
                'CDR-L3': (89, 97)
            }
        else:
            return {}

    def _get_cdr_locations(self, chain_dict: Dict, chain_type: str) -> torch.Tensor:
        """
        Determine CDR locations based on Chothia numbering.

        Parameters
        ----------
        chain_dict : Dict
            Dictionary containing chain data
        chain_type : str
            Type of chain ('heavy' or 'light')

        Returns
        -------
        torch.Tensor
            Tensor indicating CDR locations
        """
        cdr_locations = torch.zeros_like(chain_dict['res_nb'])
        cdr_definitions = self._get_cdr_definitions(chain_type)
        
        for cdr_num, (start, end) in enumerate(cdr_definitions.values(), start=1):
            mask = (chain_dict['res_nb'] >= start) & (chain_dict['res_nb'] <= end)
            cdr_locations[mask] = cdr_num
            
        return cdr_locations

class DataPreparation:
    """Main class for preparing the DiffAbXL dataset."""
    
    def __init__(self, config: Dict):
        self.config = config
        self.processor = AntibodyStructureProcessor(config)
        
    def prepare_dataset(self, skip_download: bool = False):
        """Main function to prepare the entire dataset."""
        logger.info("Starting dataset preparation...")
        
        # Create directories
        self._create_directories()
        
        # Process SAbDab summary
        summary_df = self._get_sabdab_summary()
        
        # Download PDB files if needed
        if not skip_download:
            self._download_pdb_files(summary_df)
        else:
            logger.info("Skipping PDB downloads...")
        
        # Process structures
        entries_list = self._process_structures(summary_df)
        
        # Perform structural clustering using Foldseek
        self._perform_structural_clustering(entries_list)
        
        logger.info("Dataset preparation completed successfully!")
        
    def _create_directories(self):
        """Create necessary directories."""
        os.makedirs(self.config['data_dir'], exist_ok=True)
        os.makedirs(self.config['pdb_dir'], exist_ok=True)
        os.makedirs(self.config['processed_dir'], exist_ok=True)
        os.makedirs(self.config['foldseek_dir'], exist_ok=True)
        
    def _get_sabdab_summary(self) -> pd.DataFrame:
        """Download and process SAbDab summary file."""
        summary_file = os.path.join(self.config['data_dir'], 'sabdab_summary_all.tsv')
        
        if not os.path.exists(summary_file):
            download_sabdab_summary(summary_file)
        
        # Read and process summary file
        df = pd.read_csv(summary_file, sep='\t', na_values=['NA', '', 'None'])
        
        logger.info(f"Total entries before filtering: {len(df)}")
        # Convert PDB IDs to lowercase
        df['pdb'] = df['pdb'].str.lower()
        df['Hchain'] = df['Hchain'].astype(str)
        df['Lchain'] = df['Lchain'].astype(str)
        df['antigen_chain'] = df['antigen_chain'].astype(str)
        
        # Convert resolution to float, handling non-numeric values
        df['resolution'] = pd.to_numeric(df['resolution'], errors='coerce')
        
        # Split antigen types and filter based on the configuration
        df['antigen_type'] = df['antigen_type'].astype(str)
        df['antigen_types'] = df['antigen_type'].str.split('|')
        filtered_df = df[
            (df['resolution'].notna()) &  # Remove entries without resolution
            (df['resolution'] <= self.config['resolution_threshold']) &
            df['antigen_types'].apply(lambda x: any(ag_type.strip() in self.config['ag_types'] for ag_type in x))
        ]
        
        # Reset index after filtering
        filtered_df = filtered_df.reset_index(drop=True)
        
        logger.info(f"Found {len(filtered_df)} entries after filtering")
        logger.info(f"Antigen types found: {filtered_df['antigen_type'].unique()}")
        
        return filtered_df
    
    def _check_existing_files(self, df: pd.DataFrame) -> Tuple[List[str], List[str]]:
        """Check which PDB files exist and which need downloading."""
        existing = []
        missing = []
        
        for pdb_id in df['pdb'].unique():
            pdb_path = os.path.join(self.config['pdb_dir'], f"{pdb_id.lower()}.pdb")
            if os.path.exists(pdb_path):
                existing.append(pdb_id)
            else:
                missing.append(pdb_id)
                
        return existing, missing
        
    def _download_pdb_files(self, df: pd.DataFrame):
        """Download PDB files using parallel processing."""
        pdb_ids = df['pdb'].unique()
        
        logger.info(f"Downloading {len(pdb_ids)} PDB files...")
        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            futures = [
                executor.submit(download_pdb, pdb_id, self.config['pdb_dir'])
                for pdb_id in pdb_ids
            ]
            
            for _ in tqdm(
                concurrent.futures.as_completed(futures),
                total=len(futures),
                desc="Downloading PDB files"
            ):
                pass
                
    def _process_structures(self, df: pd.DataFrame) -> List[Dict]:
        """Process structures and create LMDB database."""
        lmdb_path = os.path.join(self.config['processed_dir'], 'structures.lmdb')
        
        env = lmdb.open(
            lmdb_path,
            map_size=1024*1024*1024*64,  # 64GB
            subdir=False,
            readonly=False,
            meminit=False,
            map_async=True
        )
        
        entries_list = []
        
        with env.begin(write=True) as txn:
            for _, row in tqdm(df.iterrows(), total=len(df), desc="Processing structures"):
                try:
                    pdb_id = row['pdb'].lower()
                    pdb_file = os.path.join(self.config['pdb_dir'], f"{pdb_id}.pdb")
                    if not os.path.exists(pdb_file):
                        continue
                        
                    logger.info(f"Processing {pdb_id}...")
                    logger.debug(f"Heavy chain: {row['Hchain']}")
                    logger.debug(f"Light chain: {row['Lchain']}")
                    logger.debug(f"Antigen chain: {row.get('antigen_chain', 'Not specified')}")
                    
                    antigen_chains = row.get('antigen_chain', None)
                    if pd.isna(antigen_chains):
                        antigen_chains = None
                    else:
                        antigen_chains = [ch.strip() for ch in antigen_chains.split(',')]
                    
                    struct_dict = self.processor.process_structure(
                        pdb_file,
                        heavy_chain=row['Hchain'],
                        light_chain=row['Lchain'],
                        antigen_chains=antigen_chains
                    )
                    
                    # Save to LMDB
                    txn.put(
                        pdb_id.encode(),
                        pickle.dumps(struct_dict)
                    )
                    
                    # Add to entries list
                    entries_list.append({
                        'id': pdb_id,
                        'entry': {
                            'ag_name': row.get('antigen', 'Unknown'),
                            'resolution': row['resolution'],
                            'method': row['method'],
                            'scfv': row.get('scfv', False),
                            'light_ctype': struct_dict.get('light_ctype', None),
                            'cdr_sequences': struct_dict['cdr_sequences'],
                            'cdr_structures': struct_dict['cdr_structures']
                        }
                    })
                    
                except Exception as e:
                    logger.error(f"Error processing {row['pdb']}: {e}")
                    continue
                    
        # Save entries list
        entries_file = os.path.join(self.config['processed_dir'], 'entries_list.pkl')
        with open(entries_file, 'wb') as f:
            pickle.dump(entries_list, f)
            
        return entries_list

    def _perform_structural_clustering(self, entries_list: List[Dict]):
        """Cluster antibody structures based on structural similarity using Foldseek."""
        logger.info("Starting structural clustering using Foldseek...")
        
        # Create a directory for Foldseek files
        foldseek_dir = self.config['foldseek_dir']
        os.makedirs(foldseek_dir, exist_ok=True)
        
        # Extract the heavy chain CDR-H3 regions and save as separate PDB files
        cdr_pdb_dir = os.path.join(foldseek_dir, 'cdr_pdbs')
        os.makedirs(cdr_pdb_dir, exist_ok=True)
        
        pdb_id_to_cdr_pdb = {}  # Mapping from PDB ID to extracted CDR PDB file
        
        for entry in entries_list:
            pdb_id = entry['id']
            struct = entry['entry']
            cdr_residues = struct.get('cdr_residues', {})
            heavy_cdrs = cdr_residues.get('heavy', {})
            
            # Extract CDR-H3 residues
            cdr_h3_residues = heavy_cdrs.get('CDR-H3')
            if cdr_h3_residues is not None and len(cdr_h3_residues) > 0:
                # Save CDR-H3 as a PDB file
                cdr_pdb_path = os.path.join(cdr_pdb_dir, f"{pdb_id}_cdrh3.pdb")
                self._write_cdr_pdb_residues(cdr_h3_residues, cdr_pdb_path)
                pdb_id_to_cdr_pdb[pdb_id] = cdr_pdb_path
            else:
                logger.warning(f"No CDR-H3 residues for {pdb_id}")

        
        # Create Foldseek database from the CDR PDB files
        db_dir = os.path.join(foldseek_dir, 'foldseek_db')
        os.makedirs(db_dir, exist_ok=True)
        pdb_list_file = os.path.join(cdr_pdb_dir, 'pdb_list.txt')
        with open(pdb_list_file, 'w') as f:
            for pdb_id, cdr_pdb_path in pdb_id_to_cdr_pdb.items():
                f.write(f"{cdr_pdb_path}\n")
        
        # Run Foldseek createdb
        createdb_cmd = [
            'foldseek', 'createdb',
            pdb_list_file,
            os.path.join(db_dir, 'antibody_db')
        ]
        self._run_subprocess(createdb_cmd)
        
        # Run Foldseek all-vs-all search
        result_file = os.path.join(db_dir, 'results.m8')
        search_cmd = [
            'foldseek', 'search',
            os.path.join(db_dir, 'antibody_db'),
            os.path.join(db_dir, 'antibody_db'),
            result_file,
            os.path.join(db_dir, 'tmp'),
            '-a'  # Include alignment in output
        ]
        self._run_subprocess(search_cmd)
        
        # Read Foldseek results and build similarity matrix
        similarity_df = pd.read_csv(
            result_file,
            sep='\t',
            header=None,
            names=[
                'query', 'target', 'prob', 'evalue', 'score',
                'aligned_cols', 'identity', 'similarity', 'query_start', 'query_end',
                'target_start', 'target_end', 'alignment'
            ]
        )
        
        # Map PDB IDs from file paths
        similarity_df['query_pdb'] = similarity_df['query'].apply(lambda x: os.path.basename(x).split('_')[0])
        similarity_df['target_pdb'] = similarity_df['target'].apply(lambda x: os.path.basename(x).split('_')[0])
        
        # Build a distance matrix based on Foldseek scores
        pdb_ids = list(pdb_id_to_cdr_pdb.keys())
        pdb_id_to_index = {pdb_id: idx for idx, pdb_id in enumerate(pdb_ids)}
        num_pdbs = len(pdb_ids)
        distance_matrix = np.zeros((num_pdbs, num_pdbs))
        
        for _, row in similarity_df.iterrows():
            query_idx = pdb_id_to_index[row['query_pdb']]
            target_idx = pdb_id_to_index[row['target_pdb']]
            score = row['score']
            # Convert score to distance (you may need to adjust this based on Foldseek output)
            distance = 1.0 / (score + 1e-6)
            distance_matrix[query_idx, target_idx] = distance
            distance_matrix[target_idx, query_idx] = distance  # Symmetric
        
        # Perform clustering using hierarchical clustering
        from scipy.cluster.hierarchy import linkage, fcluster
        from scipy.spatial.distance import squareform
        
        condensed_dist_matrix = squareform(distance_matrix)
        Z = linkage(condensed_dist_matrix, method='average')
        
        # Determine clusters using a distance threshold
        threshold = self.config.get('clustering_threshold', 0.5)  # Adjust as needed
        cluster_labels = fcluster(Z, t=threshold, criterion='distance')
        
        # Map PDB IDs to cluster labels
        id_to_cluster = {pdb_id: cluster_labels[idx] for pdb_id, idx in pdb_id_to_index.items()}
        
        # Assign clusters to data splits
        unique_clusters = np.unique(cluster_labels)
        np.random.seed(self.config.get('seed', 42))
        np.random.shuffle(unique_clusters)
        
        total_clusters = len(unique_clusters)
        train_ratio = self.config.get('train_ratio', 0.8)
        val_ratio = self.config.get('val_ratio', 0.1)
        num_train_clusters = int(total_clusters * train_ratio)
        num_val_clusters = int(total_clusters * val_ratio)
        num_test_clusters = total_clusters - num_train_clusters - num_val_clusters
        
        train_clusters = unique_clusters[:num_train_clusters]
        val_clusters = unique_clusters[num_train_clusters:num_train_clusters + num_val_clusters]
        test_clusters = unique_clusters[num_train_clusters + num_val_clusters:]
        
        # Assign PDB IDs to splits
        pdb_to_split = {}
        for pdb_id in pdb_ids:
            cluster_label = id_to_cluster[pdb_id]
            if cluster_label in train_clusters:
                pdb_to_split[pdb_id] = 'train'
            elif cluster_label in val_clusters:
                pdb_to_split[pdb_id] = 'val'
            else:
                pdb_to_split[pdb_id] = 'test'
        
        # Write the clustering results
        cluster_file = os.path.join(self.config['processed_dir'], 'cluster_results.tsv')
        with open(cluster_file, 'w') as f:
            for pdb_id, split in pdb_to_split.items():
                f.write(f"{split}\t{pdb_id}\n")
        
        logger.info(f"Cluster file created with splits: {len(train_clusters)} train clusters, {len(val_clusters)} val clusters, {len(test_clusters)} test clusters.")
    
    def _write_cdr_pdb_residues(self, residues: List[PDB.Residue.Residue], output_path: str):
        """Write CDR residues to a PDB file."""
        from Bio.PDB import PDBIO
        class CDRSelect(PDB.Select):
            def accept_residue(self, residue):
                return residue in residues
        io = PDBIO()
        # Create a new structure containing only the selected residues
        builder = PDB.StructureBuilder.StructureBuilder()
        builder.init_structure('CDR')
        builder.init_model(0)
        builder.init_chain('A')
        for residue in residues:
            builder.structure[0]['A'].add(residue)
        io.set_structure(builder.structure)
        io.save(output_path, select=CDRSelect())

    def _write_cdr_pdb(self, coords: np.ndarray, output_path: str):
        """Write CDR coordinates to a PDB file."""
        with open(output_path, 'w') as f:
            for i, coord in enumerate(coords):
                f.write(f"ATOM  {i+1:5d}  CA  ALA A {i+1:4d}    {coord[0]:8.3f}{coord[1]:8.3f}{coord[2]:8.3f}  1.00  0.00           C\n")
            f.write("END\n")
    
    def _run_subprocess(self, cmd_list: List[str]):
        """Run a subprocess and handle exceptions."""
        try:
            logger.info(f"Running command: {' '.join(cmd_list)}")
            subprocess.run(cmd_list, check=True)
        except subprocess.CalledProcessError as e:
            logger.error(f"Command failed with error: {e}")
            raise DataPreparationError(f"Subprocess failed: {' '.join(cmd_list)}")

def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(description='Prepare DiffAbXL training data using Foldseek')
    parser.add_argument('--config', type=str, required=True, help='Path to config file')
    parser.add_argument('--output', type=str, default='data', help='Output directory')
    parser.add_argument('--num-workers', type=int, default=4, help='Number of download workers')
    parser.add_argument('--skip-download', action='store_true', help='Skip downloading PDB files')
    parser.add_argument('--reprocess', action='store_true', help='Reprocess existing structures')
    parser.add_argument('--debug', action='store_true', help='Enable debug logging')
    # New flags for clustering parameters
    parser.add_argument('--train-ratio', type=float, default=0.8, help='Ratio of data for training')
    parser.add_argument('--val-ratio', type=float, default=0.1, help='Ratio of data for validation')
    parser.add_argument('--seed', type=int, default=42, help='Random seed for shuffling')
    parser.add_argument('--clustering-threshold', type=float, default=0.5, help='Threshold for clustering')
    args = parser.parse_args()
    
    # Load config
    try:
        with open(args.config) as f:
            config = yaml.safe_load(f)
    except Exception as e:
        print(f"Error loading config file: {e}")
        sys.exit(1)
    
    # Update config with command line arguments
    config.update({
        'data_dir': args.output,
        'pdb_dir': os.path.join(args.output, 'sabdab/pdbs'),
        'processed_dir': os.path.join(args.output, 'processed'),
        'log_dir': os.path.join(args.output, 'logs'),
        'foldseek_dir': os.path.join(args.output, 'foldseek'),
        'train_ratio': args.train_ratio,
        'val_ratio': args.val_ratio,
        'seed': args.seed,
        'clustering_threshold': args.clustering_threshold,
    })
    
    # Set up logging
    global logger
    logger = setup_logger(config['log_dir'], debug=args.debug)
    
    try:
        # Set number of workers
        global MAX_WORKERS
        MAX_WORKERS = args.num_workers
        
        # Prepare dataset
        data_prep = DataPreparation(config)
        data_prep.prepare_dataset(skip_download=args.skip_download)
        
    except KeyboardInterrupt:
        logger.info("Process interrupted by user")
        sys.exit(1)
    except Exception as e:
        logger.error(f"Dataset preparation failed: {e}")
        raise

if __name__ == "__main__":
    main()


# Example usage:
# python prepare_data.py --config config/data_prep.yaml --output data --num-workers 4 --train-ratio 0.8 --val-ratio 0.1 --clustering-threshold 0.35

```

Contents of pyproject.toml:
```
[tool.black]
multi_line_output = 3
include_trailing_comma = true
force_grid_wrap = 0
use_parentheses = true
ensure_newline_before_comments = true
line_length = 120
```

Contents of CONTRIBUTING.md:
```
# Contributing to the Benchmarking Project

- We are not accepting any contribution in the short term although we might be open to it in the future. 
- However, If you have found a bug, please file an issue that illustrates the bug with a minimal reproducible example.
```

Contents of AUTHORS.md:
```
**Author:** Talip Ucar <br>
**Email:** ucabtuc@gmail.com or talip.ucar@astrazeneca.com

```

Contents of train.py:
```
"""
Author: Talip Ucar
email: ucabtuc@gmail.com

Description: Training script.
"""

# Standard library imports
import os
import traceback
from datetime import date, timedelta

# Third-party library imports
import yaml
import torch
import lightning as L
from lightning.pytorch.callbacks import LearningRateMonitor, ModelCheckpoint
from lightning.pytorch.loggers import CSVLogger, WandbLogger
from lightning.pytorch.strategies import DDPStrategy

# Custom module imports
from src.model import DiffAbXLWrapper
from utils.load_data import AbLoader
from utils.arguments import get_arguments, get_config, print_config_summary
from utils.utils import set_dirs

# Set the NCCL blocking wait environment variable to avoid deadlocks in multi-GPU training
os.environ["NCCL_BLOCKING_WAIT"] = "1"


def train(config, data_loader):
    """
    Trains the DiffAbXL model using the provided configuration and data loader.

    Args:
        config (dict): A dictionary containing configuration options and arguments.
        data_loader (AbLoader): Data loader containing training and validation datasets.

    """
    # Instantiate the model
    model = DiffAbXLWrapper(config)

    # Monitor learning rate during training
    lr_monitor = LearningRateMonitor(logging_interval="step")
    callbacks = [lr_monitor]

    # Model checkpointing configuration
    filename = config["model_name"]
    checkpoint_callback = ModelCheckpoint(
        dirpath=model._model_path,
        filename=filename,
        save_top_k=1,
        verbose=True,
        every_n_epochs=config["model_save_freq"],
    )
    callbacks.append(checkpoint_callback)

    # Set up logging (Wandb or CSV depending on config)
    today = date.today()
    log_name = f"{filename}_{today.strftime('%Y-%m-%d')}"
    logger = (
        WandbLogger(project="diff_allCDRs", name=log_name, log_model=False)
        if config["wandb"]
        else CSVLogger(save_dir=config["results_dir"], name=log_name)
    )

    # Get training and validation data loaders
    train_loader = data_loader.train_loader
    validation_loader = data_loader.validation_loader

    # Configure the trainer
    trainer = L.Trainer(
        devices=config['num_gpus'],
        accelerator="gpu",
        strategy=DDPStrategy(timeout=timedelta(seconds=15400), find_unused_parameters=True),
        precision=32,
        max_epochs=config["epochs"],
        logger=logger,
        callbacks=callbacks,
        enable_checkpointing=True,
        val_check_interval=config["val_check_interval"],
        log_every_n_steps=config["log_every_n_steps"],
    )

    # Start training
    trainer.fit(model, train_loader, validation_loader)

    # Save the config file for future reference
    config_path = f"{model._results_path}/config.yml"
    with open(config_path, "w") as config_file:
        yaml.dump(config, config_file, default_flow_style=False)

    print("Training completed successfully.")


def main(config):
    """
    Main entry point for the training process. Sets up necessary directories, loads data, 
    and initiates the training process.

    Args:
        config (dict): A dictionary containing configuration options and arguments.

    """
    # Ensure necessary directories are set up
    set_dirs(config)

    # Load the data for the specified dataset
    ds_loader = AbLoader(config, dataset_name=config["dataset"])

    # Proceed with training
    train(config, ds_loader)


if __name__ == "__main__":
    # Parse command-line arguments
    args = get_arguments()

    # Load the configuration file
    config = get_config(args)

    # Experiment name --- can be changed, default is the name of the dataset
    config["experiment"] = config["dataset"]

    # Print configuration summary for verification
    print_config_summary(config, args)

    # Run the main training function with error handling
    try:
        main(config)
    except Exception as e:
        print(traceback.format_exc())

```

Contents of README.md:
```
![Maturity-level-0](https://img.shields.io/badge/Maturity%20Level-ML--0-red)

# DiffAbXL: 
##### Author: Talip Ucar (ucabtuc@gmail.com)

The implementation of DiffAbXL benchmarked in the paper: [Exploring Log-Likelihood Scores for Ranking Antibody Sequence Designs](https://www.biorxiv.org/content/10.1101/2024.10.07.617023v4.full.pdf).

- Please note that the paper was originally titled "Benchmarking Generative Models for Antibody Design" but we decided to change it to better highlight its core contributions.
- This is a re-implementation of the original work, DiffAb: [[Paper](https://www.biorxiv.org/content/10.1101/2022.07.10.499510v5.abstract) and [Code](https://github.com/luost26/diffab/tree/main?tab=readme-ov-file)]


## Table of Contents:

1. [Current Leaderboard](#current-leaderboard)
2. [Benchmarking results from the paper](#benchmarking-results)
3. [How to Build an Interface for Benchmarking Models](#how-to-build-an-interface-for-benchmarking-models)
4. [Training](#training)
5. [Structure of the repo](#structure-of-the-repo)
6. [Experiment tracking](#experiment-tracking)
7. [Citing the paper](#citing-the-paper)
8. [Citing this repo](#citing-this-repo)


## Current Leaderboard

<table border="1">
  <tr>
    <th rowspan="2">Rank</th>
    <th rowspan="2">Models</th>
    <th colspan="2">Absci HER2</th>
    <th colspan="2">Nature</th>
    <th rowspan="2">AZ Target-2</th>
    <th rowspan="2">Ave. ùúå</th>
  </tr>
  <tr>
    <th>Zero Shot</th>
    <th>SPR Control</th>
    <th>HEL</th>
    <th>HER2</th>
  </tr>
  <tr>
    <td>1</td>
    <td>DiffAbXL-A-DN</td>
    <td>0.43</td>
    <td>0.22</td>
    <td>0.62</td>
    <td>0.37</td>
    <td>0.41</td>
    <td>0.41</td>
  </tr>
  <tr>
    <td>2</td>
    <td>DiffAbXL-A-SG</td>
    <td>0.46</td>
    <td>0.22</td>
    <td>0.64</td>
    <td>-0.38</td>
    <td>0.43</td>
    <td>0.274</td>
  </tr>
  <tr>
    <td>3</td>
    <td>DiffAbXL-H3-DN</td>
    <td>0.49</td>
    <td>0</td>
    <td>0.52</td>
    <td>-0.08</td>
    <td>0.37</td>
    <td>0.26</td>
  </tr>
  <tr>
    <td>4</td>
    <td>IgBlend (struct. only)</td>
    <td>0.40</td>
    <td>0.21</td>
    <td>0.54</td>
    <td>-0.30</td>
    <td>0.31</td>
    <td>0.232</td>
  </tr>
  <tr>
    <td>5</td>
    <td>Antifold</td>
    <td>0.43</td>
    <td>0.22</td>
    <td>0.4</td>
    <td>-0.47</td>
    <td>0.38</td>
    <td>0.192</td>
  </tr>
  <tr>
    <td>6</td>
    <td>DiffAbXL-H3-SG</td>
    <td>0.48</td>
    <td>0</td>
    <td>0.4</td>
    <td>-0.41</td>
    <td>0.29</td>
    <td>0.152</td>
  </tr>
  <tr>
    <td>7</td>
    <td>ESM</td>
    <td>0.29</td>
    <td>0</td>
    <td>0</td>
    <td>0.18</td>
    <td>0.27</td>
    <td>0.148</td>
  </tr>
  <tr>
    <td>8</td>
    <td>DiffAb</td>
    <td>0.34</td>
    <td>0.21</td>
    <td>0</td>
    <td>-0.14</td>
    <td>0.22</td>
    <td>0.126</td>
  </tr>
  <tr>
    <td>9</td>
    <td>AbLang2</td>
    <td>0.3</td>
    <td>0</td>
    <td>0</td>
    <td>-0.07</td>
    <td>0.36</td>
    <td>0.118</td>
  </tr>
  <tr>
    <td>10</td>
    <td>IgBlend (seq. only)</td>
    <td>0.27</td>
    <td>0</td>
    <td>0</td>
    <td>-0.1</td>
    <td>0.36</td>
    <td>0.106</td>
  </tr>
  <tr>
    <td>11</td>
    <td>AbLang</td>
    <td>0.3</td>
    <td>0</td>
    <td>0</td>
    <td>-0.13</td>
    <td>0.35</td>
    <td>0.104</td>
  </tr>
  <tr>
    <td>12</td>
    <td>dyMEAN</td>
    <td>0.37</td>
    <td>0.15</td>
    <td>0</td>
    <td>0</td>
    <td>0</td>
    <td>0.104</td>
  </tr>
  <tr>
    <td>13</td>
    <td>AbX</td>
    <td>0.28</td>
    <td>0.19</td>
    <td>0</td>
    <td>0</td>
    <td>0</td>
    <td>0.094</td>
  </tr>
  <tr>
    <td>14</td>
    <td>AntiBERTy</td>
    <td>0.26</td>
    <td>0</td>
    <td>0</td>
    <td>-0.17</td>
    <td>0.35</td>
    <td>0.088</td>
  </tr>
  <tr>
    <td>15</td>
    <td>MEAN</td>
    <td>0.36</td>
    <td>0</td>
    <td>0</td>
    <td>0.02</td>
    <td>0</td>
    <td>0.076</td>
  </tr>
  <tr>
    <td>16</td>
    <td>ESM-IF</td>
    <td>0</td>
    <td>-0.27</td>
    <td>0</td>
    <td>-0.53</td>
    <td>0.42</td>
    <td>-0.076</td>
  </tr>
</table>

- **Note-1:** Ave. ùúå refers to average Spearman correlation across five datasets. The leaderboard above is based on five target datasets, with a score of zero assigned to models that did not demonstrate statistically significant correlation or were not suitable for score computation (e.g., requiring an antigen).
- **Note-2:** Log-likelihood scores in this work are computed using a naive approach, as outlined in Equation-11 in the paper, to maintain consistency across models. However, it is worth noting that more principled methods exist for calculating these scores, which may vary depending on the model type (e.g., autoregressive vs. masked language models). We plan to investigate these alternative approaches in future work.

## Benchmarking Results
#### 1- Correlation between DiffAbXL's log-likelihood and binding affinity across different targets 

![Results-1](./assets/diffabxl_results1.png)

**Figure-1: Results for DiffAbXL:** **a)** DiffAbXL-H3-DN for Absci zero-shot HER2 data **b)** DiffAbXL-A-SG for AZ Target-2, **c)** DiffAbXL-A-SG for Nature HEL, **d)** DiffAbXL-A-DN for Nature HER2.

#### 2- Comparing Diffusion-based, LLM-based and Graph-based models     

![Results-2](./assets/diffabxl_results2.png)

**Table-1:** Summary of the results for Spearman correlation. Abbreviations: DN: De Novo mode, SG: Structure Guidance mode, NA: Epitope or complex structure required, but not available. *, **, *** indicate p-values under 0.05, 0.01 and 1e-4 respectively. 

## How to Build an Interface for Benchmarking Models
To make it easier for us to benchmark your model, we recommend that you implement an interface as a Python method in a class that we can easily integrate with our evaluation pipeline. The method should accept the following inputs:
1. **Antibody sequences**: A list of antibody sequences.
2. **Optional structure information**: If applicable, structure data (i.e. PDB file) related to the sequences.
3. **Additional model-specific parameters**: Any other inputs your model requires.

The method should return a dictionary containing:
1. **Log-likelihood scores**: For ranking antibody sequences based on their predicted binding affinity.
2. **Other relevant metrics**: Such as RMSD, pAE, or any model-specific outputs you believe are relevant.

Here's a basic template in Python for implementing this interface:

```python
    def benchmark(self, sequences, structure=None, mask=None, **kwargs):
        """
        Benchmark the model on provided antibody sequences and structures.

        Parameters:
        sequences (list of str): List of antibody sequences.
        structure (optional): Path to a PDB file. Currently, only one PDB file is provided per target dataset.
                              The PDB file may contain either just the antibody or an antibody-antigen complex,
                              depending on the dataset.
        mask (optional): Binary list or array indicating the regions of interest in the sequences for metric calculations.
        kwargs (optional): Additional parameters required by the model.

        Returns:
        dict: A dictionary containing log-likelihood scores and other relevant metrics.
        """
        pass
```

Please make sure that your model outputs the log-likelihood scores in a format we can use directly for benchmarking antibody sequence designs. This will help us compare your model's performance across our datasets efficiently.



## Training
There is one configuration file: sabdab.yaml, which can be used to change any of the parameters. You can train the model by using:

```
python train.py # For training. 
```


## Structure of the repo

<pre>
.
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ assets
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ assets/diffabxl_results1.png
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ assets/diffabxl_results2.png
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ assets/qr_img.png
‚îú‚îÄ‚îÄ AUTHORS.md
‚îú‚îÄ‚îÄ compute_loglikelihood.py
‚îú‚îÄ‚îÄ config
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ config/sabdab.yaml
‚îú‚îÄ‚îÄ data
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ processed
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ sabdab_chothia
‚îú‚îÄ‚îÄ results/sabdab
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ evaluation
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ training
‚îú‚îÄ‚îÄ CONTRIBUTING.md
‚îú‚îÄ‚îÄ environment.yml
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ src
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ src/model.py
‚îú‚îÄ‚îÄ train.py
‚îî‚îÄ‚îÄ utils
    ‚îú‚îÄ‚îÄ utils/arguments.py
    ‚îú‚îÄ‚îÄ utils/geometry.py
    ‚îú‚îÄ‚îÄ utils/load_data.py
    ‚îú‚îÄ‚îÄ utils/loss_functions.py
    ‚îú‚îÄ‚îÄ utils/model_utils.py
    ‚îú‚îÄ‚îÄ utils/protein_constants.py
    ‚îú‚îÄ‚îÄ utils/transformations.py
    ‚îú‚îÄ‚îÄ utils/utils_diff.py
    ‚îî‚îÄ‚îÄ utils/utils.py
</pre>



## Experiment tracking
Weights & Biases can be used to track experiments. It is turned off by default, but can be turned on by changing option in the config file in ```./config/sabdab.yaml```


## Citing the paper

```
@article {Ucar2024.10.07.617023,
	author = {Ucar, Talip and Malherbe, Cedric and Gonzalez Hernandez, Ferran},
	title = {Exploring Log-Likelihood Scores for Ranking Antibody Sequence Designs},
	elocation-id = {2024.10.07.617023},
	year = {2024},
	doi = {10.1101/2024.10.07.617023},
	publisher = {Cold Spring Harbor Laboratory},
	URL = {https://www.biorxiv.org/content/early/2024/10/24/2024.10.07.617023},
	eprint = {https://www.biorxiv.org/content/early/2024/10/24/2024.10.07.617023.full.pdf},
	journal = {bioRxiv}
}
```

## Citing this repo
If you use DiffAbXL in your own studies, and work, please cite it by using the following:

```
@Misc{talip_ucar_2024_DiffAbXL,
	author =   {Talip Ucar},
	title = {Exploring Log-Likelihood Scores for Ranking Antibody Sequence Designs},
	URL = {https://github.com/AstraZeneca/DiffAbXL},
	month = {October},
	year = {since 2024}
}
```

```

Contents of LICENSE:
```
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

```

Contents of requirements.txt:
```
biopython==1.84
biotite==0.38.0
datatable @ git+https://github.com/h2oai/datatable
easydict==1.9
lightning==2.3.3
lightning-utilities==0.11.2
llvmlite==0.42.0
lmdb==1.4.1
markdown-it-py==3.0.0
numpy==1.26.4
nvidia-cublas-cu12==12.1.3.1
nvidia-cuda-cupti-cu12==12.1.105
nvidia-cuda-nvrtc-cu12==12.1.105
nvidia-cuda-runtime-cu12==12.1.105
nvidia-cudnn-cu12==8.9.2.26
nvidia-cufft-cu12==11.0.2.54
nvidia-curand-cu12==10.3.2.106
nvidia-cusolver-cu12==11.4.5.107
nvidia-cusparse-cu12==12.1.0.106
nvidia-nccl-cu12==2.20.5
nvidia-nvjitlink-cu12==12.4.99
nvidia-nvtx-cu12==12.1.105
opt-einsum==3.3.0
pandas==2.2.1
pickleshare==0.7.5
pillow==10.2.0
progressbar2==4.4.2
python-utils==3.8.2
pytorch-lightning==1.8.6
regex==2023.12.25
scikit-learn==1.3.0
scipy==1.11.4
seaborn==0.13.2
tables==3.9.2
tensorboardX==2.6.2.2
texttable==1.6.7
tokenizers==0.15.2
torch==2.3.1
torch_geometric==2.4.0
torchaudio==2.3.1
torchmetrics==1.3.2
torchvision==0.18.1
transformers==4.39.2
wandb==0.16.6
```

Contents of foldseek-linux-avx2.tar.gz:
```
[Could not decode file contents]

```

Contents of environment.yml:
```
name: modelling-dev
channels:
  - conda-forge
dependencies:
  - python=3.11.8
  - numpy >= 1.16
  - pandas >= 1
  - matplotlib >= 3.1
  - seaborn
  - xlrd
  - scipy
  - pytest
# Notebooks
  - jupyter
  - jupyterlab
  - nodejs
  - ipympl
# utilities
  - black
  - isort
  - tqdm
  - pyyaml
  - pip >= 19
```

Contents of utils/arguments.py:
```
"""
Author: Talip Ucar
email: ucabtuc@gmail.com

Description: - Collects arguments from command line, and loads configuration from the yaml files.
             - Prints a summary of all options and arguments.
"""

import os
from argparse import ArgumentParser
import sys
import torch
from utils.utils import get_runtime_and_model_config, print_config
import sys
import os
import torch
from argparse import ArgumentParser

class ArgParser(ArgumentParser):
    """
    Inherits from ArgumentParser to provide a more user-friendly error handling mechanism.
    If an error occurs, it prints the help message and exits the program.
    """
    def error(self, message):
        """
        Overrides the default error behavior to print a custom error message and show the help prompt.

        Parameters
        ----------
        message : str
            The error message to display.
        """
        sys.stderr.write(f'error: {message}\n')
        self.print_help()
        sys.exit(2)


def get_arguments():
    """
    Retrieves command line arguments using ArgParser.

    Returns
    -------
    Namespace
        Parsed command line arguments.
    """
    parser = ArgParser()

    # Dataset to use (must have a corresponding config file)
    parser.add_argument(
        "-d", "--dataset", type=str, default="sabdab",
        help="Name of the dataset to use. It should have a config file with the same name."
    )

    # Epoch for loading saved models
    parser.add_argument(
        "-e", "--epoch", type=int, default=None,
        help="Defines the epoch when loading the model, if the model is saved at specific epochs."
    )

    # Batch size
    parser.add_argument(
        "-bs", "--batch_size", type=int, default=None,
        help="Defines batch size. If None, use batch size defined in the config file."
    )

    # GPU usage
    parser.add_argument(
        "-g", "--gpu", dest="gpu", action="store_true",
        help="Assigns GPU as the device, assuming that GPU is available."
    )
    parser.add_argument(
        "-ng", "--no_gpu", dest="gpu", action="store_false",
        help="Assigns CPU as the device."
    )
    parser.set_defaults(gpu=True)

    # Fine-tuning option
    parser.add_argument(
        "-ft", "--fine_tune", dest="fine_tune", action="store_true",
        help="Used to fine-tune the model."
    )
    parser.set_defaults(fine_tune=False)

    # Device number for GPU (e.g., "cuda:0")
    parser.add_argument(
        "-dn", "--device_number", type=str, default="0",
        help="Defines which GPU to use. Default is 0."
    )

    # Experiment number for MLFlow
    parser.add_argument(
        "-ex", "--experiment", type=int, default=1,
        help="Used as a suffix for MLFlow experiments, if MLFlow is enabled."
    )

    # Antibody-antigen docking options
    parser.add_argument(
        "--antigen", type=str, default="./data/examples/Omicron_RBD.pdb",
        help="Path to the antigen structure (PDB file)."
    )
    parser.add_argument(
        "--antibody", type=str, default="./data/examples/3QHF_Fv.pdb",
        help="Path to the antibody structure (PDB file)."
    )
    parser.add_argument(
        "-nd", "--num_docks", type=int, default=10,
        help="Number of docking attempts."
    )
    parser.add_argument(
        "--heavy", type=str, default="H",
        help="Chain ID of the heavy chain."
    )
    parser.add_argument(
        "--light", type=str, default="L",
        help="Chain ID of the light chain."
    )

    return parser.parse_args()


def get_config(args):
    """
    Loads the configuration settings from YAML files and incorporates command line arguments.

    Parameters
    ----------
    args : Namespace
        Command line arguments parsed from `get_arguments()`.

    Returns
    -------
    dict
        Configuration dictionary combining runtime settings and command line arguments.
    """
    config = get_runtime_and_model_config(args)
    
    # Device setup: GPU or CPU
    config["device"] = torch.device(
        f'cuda:{args.device_number}' if torch.cuda.is_available() and args.gpu else 'cpu'
    )

    # Epoch override if specified
    config["epoch"] = args.epoch

    # Antibody settings
    config["heavy"] = args.heavy
    config["light"] = args.light
    config["dataset"] = args.dataset

    # System configurations
    config["num_workers"] = os.cpu_count()

    # Batch size override if specified
    if args.batch_size is not None:
        config["batch_size"] = args.batch_size

    return config


def print_config_summary(config, args=None):
    """
    Prints a summary of the current configuration and command line arguments (if provided).

    Parameters
    ----------
    config : dict
        The configuration dictionary to print.
    args : Namespace, optional
        Parsed command line arguments, if available.
    """
    print("=" * 100)
    print("Here is the configuration being used:\n")
    print_config(config)
    print("=" * 100)
    
    if args is not None:
        print("Arguments being used:\n")
        print_config(args)
        print("=" * 100)
```

Contents of utils/model_utils.py:
```
"""
Author: Talip Ucar
email: ucabtuc@gmail.com

Description: Library of models and related support functions for protein structure and sequence prediction.
"""

import copy
import functools
import math
import os
import pickle
import random

import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from einops import rearrange
from tqdm.auto import tqdm
from torch import einsum, nn

from lightning import Callback
from lightning.pytorch.callbacks import BasePredictionWriter

from utils.geometry import (apply_rotation_to_vector, construct_3d_basis, get_3d_basis, get_bb_dihedral_angles,
                            global2local, local2global, normalize_vector, pairwise_dihedrals, quaternion_1ijk_to_rotation_matrix,
                            random_uniform_so3, randn_so3, rotation_to_so3vec, so3_vec2rotation)
from utils.loss_functions import rotation_loss
from utils.protein_constants import AALib, BBHeavyAtom, CDR, resindex_to_ressymb, restype_to_heavyatom_names
from utils.utils_diff import clampped_one_hot

class DiffAbXL(nn.Module):
    """
    DiffAbXL model for protein sequence and structure denoising and generation.

    Parameters
    ----------
    config : dict
        Configuration dictionary containing model hyperparameters and settings.

    Attributes
    ----------
    config : dict
        Model configuration settings.
    train_structure : bool
        Flag to indicate whether to train structure denoising.
    train_sequence : bool
        Flag to indicate whether to train sequence denoising.
    residue_emb : ResidueEmbedding
        Embedding module for residue-level embeddings.
    pair_emb : PairEmbedding
        Embedding module for pairwise residue embeddings.
    diffusion : Diffusion
        Diffusion model for sequence and structure generation.
    """
    def __init__(self, config):
        super().__init__()

        # Device configuration and model settings
        config["device"] = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.config = config
        self.train_structure = self.config['train_structure']
        self.train_sequence = self.config['train_sequence']

        # Embedding dimensions and model components
        num_atoms = config['num_atoms']
        residue_dim = config['residue_dim']
        pair_dim = config['pair_dim']

        # Residue and pair embeddings
        self.residue_emb = ResidueEmbedding(residue_dim, num_atoms, max_aa_types=config['max_aa_types'], max_chain_types=10)
        self.pair_emb = PairEmbedding(pair_dim, num_atoms, max_aa_types=config['max_aa_types'], max_relpos=32)

        # Diffusion model
        self.diffusion = Diffusion(self.config)

    def forward(self, batch):
        """
        Forward pass through the model.

        Parameters
        ----------
        batch : dict
            Input batch containing sequence, structure, and mask information.

        Returns
        -------
        loss_dict : dict
            Dictionary of loss values for the current batch.
        """
        # Extract generation and residue masks
        generation_mask = batch['generation_mask']
        residue_mask = batch['residue_mask']

        # Encode batch to extract initial embeddings and positions
        v0, p0, s0, res_emb, pair_emb = self.encode_batch(batch)

        # Compute diffusion-based loss and predictions
        loss_dict, eps_p_pred, Rpred, R0, res_emb_intermediate = self.diffusion(
            v0, p0, s0, res_emb, pair_emb, generation_mask, residue_mask, 
            denoise_structure=self.train_structure, denoise_sequence=self.train_sequence
        )

        return loss_dict

    def encode_batch(self, batch):
        """
        Encode the input batch to get residue embeddings, pair embeddings, 
        initial AA sequence, and position of atoms.

        Parameters
        ----------
        batch : dict
            Input batch containing residue sequence and structural information.

        Returns
        -------
        v0 : torch.Tensor
            SO(3) vector representation of rotations for each residue.
        p0 : torch.Tensor
            Positions of C-alpha atoms.
        s0 : torch.Tensor
            Initial amino acid sequence.
        res_emb : torch.Tensor
            Residue-level embeddings.
        pair_emb : torch.Tensor
            Pairwise residue embeddings.
        """
        # Extract sequence, fragment type, and heavy atom positional information
        s0 = batch['aa']
        res_nb = batch['res_nb']
        fragment_type = batch['fragment_type']
        pos_heavyatom = batch['pos_heavyatom']
        mask_heavyatom = batch['mask_heavyatom']
        generation_mask_bar = ~batch['generation_mask']

        # Construct context masks for training structure and sequence
        context_mask = torch.logical_and(
            batch['mask_heavyatom'][:, :, BBHeavyAtom.CA], 
            ~batch['generation_mask']
        )
        structure_mask = context_mask if self.train_structure else None
        sequence_mask = context_mask if self.train_sequence else None

        # Compute residue embeddings
        res_emb = self.residue_emb(
            aa=s0, res_nb=res_nb, fragment_type=fragment_type, 
            pos_atoms=pos_heavyatom, mask_atoms=mask_heavyatom, 
            structure_mask=structure_mask, sequence_mask=sequence_mask, 
            generation_mask_bar=generation_mask_bar
        )

        # Compute pairwise residue embeddings
        pair_emb = self.pair_emb(
            aa=s0, res_nb=res_nb, fragment_type=fragment_type, 
            pos_atoms=pos_heavyatom, mask_atoms=mask_heavyatom, 
            structure_mask=structure_mask, sequence_mask=sequence_mask
        )

        # Extract positions of C-alpha atoms and construct 3D basis
        p0 = pos_heavyatom[:, :, BBHeavyAtom.CA]
        R0 = construct_3d_basis(
            center=pos_heavyatom[:, :, BBHeavyAtom.CA], 
            p1=pos_heavyatom[:, :, BBHeavyAtom.C], 
            p2=pos_heavyatom[:, :, BBHeavyAtom.N]
        )
        v0 = rotation_to_so3vec(R0)

        return v0, p0, s0, res_emb, pair_emb

    @torch.no_grad()
    def sample(self, batch, sample_structure=True, sample_sequence=True):
        """
        Sample new sequences and structures using the diffusion model.

        Parameters
        ----------
        batch : dict
            Input batch containing initial positions and sequences.
        sample_structure : bool, optional
            Flag indicating whether to sample structure, by default True.
        sample_sequence : bool, optional
            Flag indicating whether to sample sequence, by default True.

        Returns
        -------
        traj : torch.Tensor
            Trajectory of sampled positions and sequences.
        """
        generation_mask = batch['generation_mask']
        residue_mask = batch['residue_mask']

        # Encode the batch
        v0, p0, s0, res_emb, pair_emb = self.encode_batch(batch)

        # Sample trajectory
        traj, _ = self.diffusion.sample(
            v0, p0, s0, res_emb, pair_emb, generation_mask, residue_mask, 
            sample_structure=sample_structure, sample_sequence=sample_sequence
        )
        return traj

    @torch.no_grad()
    def optimize(self, batch, opt_step, sample_structure=True, sample_sequence=True):
        """
        Perform optimization step using the diffusion model.

        Parameters
        ----------
        batch : dict
            Input batch containing initial positions and sequences.
        opt_step : int
            Optimization step number.
        sample_structure : bool, optional
            Flag indicating whether to optimize structure, by default True.
        sample_sequence : bool, optional
            Flag indicating whether to optimize sequence, by default True.

        Returns
        -------
        traj : torch.Tensor
            Trajectory of positions and sequences.
        """
        generation_mask = batch['generation_mask']
        residue_mask = batch['residue_mask']

        # Encode the batch
        v0, p0, s0, res_emb, pair_emb = self.encode_batch(batch)

        # Perform optimization and return trajectory
        traj = self.diffusion.optimize(
            opt_step, v0, p0, s0, res_emb, pair_emb, generation_mask, residue_mask, 
            sample_structure=sample_structure, sample_sequence=sample_sequence
        )
        return traj

    @torch.no_grad()
    def get_posterior(self, batch, sample_structure=False, sample_sequence=False):
        """
        Compute posterior of the sampled sequences.

        Parameters
        ----------
        batch : dict
            Input batch containing sequence and structure information.
        sample_structure : bool, optional
            Flag indicating whether to sample structure, by default False.
        sample_sequence : bool, optional
            Flag indicating whether to sample sequence, by default False.

        Returns
        -------
        seq_org : torch.Tensor
            Original sequences from the batch.
        subpos : torch.Tensor
            Subpositions predicted by the model.
        """
        generation_mask = batch['generation_mask']
        residue_mask = batch['residue_mask']

        # Encode the batch
        v0, p0, s0, res_emb, pair_emb = self.encode_batch(batch)

        # Sample from the diffusion model
        traj, post = self.diffusion.sample(
            v0, p0, s0, res_emb, pair_emb, generation_mask, residue_mask, 
            sample_structure=sample_structure, sample_sequence=sample_sequence, 
            move_to_cpu=False
        )

        # Extract the original sequence and predicted subpositions
        subpos = post[batch['generation_mask']].view(p0.size(0), -1, 20)
        seq_org = batch['original_seq'][batch['generation_mask']].view(p0.size(0), -1)

        return seq_org, subpos


class Diffusion(nn.Module):
    """
    Diffusion model for sequence and structure denoising and generation.

    Parameters
    ----------
    config : dict
        Configuration dictionary containing model hyperparameters and settings.

    Attributes
    ----------
    config : dict
        Model configuration settings.
    num_steps : int
        Number of diffusion steps.
    eps_net : EpsilonNet
        Network to predict noise in the denoising process.
    rot_trans : RotationTransition
        Transition model for rotations.
    pos_trans : PositionTransition
        Transition model for positions.
    seq_trans : SequenceTransition
        Transition model for sequences.
    position_mean : torch.Tensor
        Mean used to normalize positions.
    position_scale : torch.Tensor
        Scale used to normalize positions.
    """
    def __init__(self, config):
        super(Diffusion, self).__init__()

        self.config = config
        self.num_steps = config["num_steps"]
        
        # Define noise predictor
        self.eps_net = EpsilonNet(config)
        
        # Transitions for rotation, position, and sequence
        self.rot_trans = RotationTransition(config)
        self.pos_trans = PositionTransition(config)
        self.seq_trans = SequenceTransition(config) if config["noising_scheme"] == "uniform" else SequenceTransitionMasked(config)
        
        # Register buffers for position normalization
        self.register_buffer('position_mean', torch.FloatTensor(config['position_mean']).view(1, 1, -1))
        self.register_buffer('position_scale', torch.FloatTensor(config['position_scale']).view(1, 1, -1))
        self.register_buffer('_dummy', torch.empty([0, ]))
        
    def forward(self, v0, p0, s0, res_emb, pair_emb, generation_mask, residue_mask, denoise_structure, denoise_sequence, t=None):
        """
        Forward pass through the diffusion process.

        Parameters
        ----------
        v0 : torch.Tensor
            Initial rotations (SO(3) vectors).
        p0 : torch.Tensor
            Initial positions (C-alpha atom positions).
        s0 : torch.Tensor
            Initial sequence (amino acid indices).
        res_emb : torch.Tensor
            Residue-level embeddings.
        pair_emb : torch.Tensor
            Pairwise residue embeddings.
        generation_mask : torch.Tensor
            Mask for indicating which residues are generated.
        residue_mask : torch.Tensor
            Mask for valid residues.
        denoise_structure : bool
            Flag to indicate whether to denoise structure (rotation, position).
        denoise_sequence : bool
            Flag to indicate whether to denoise sequence.
        t : torch.Tensor, optional
            Time steps for the diffusion process, by default None.

        Returns
        -------
        loss_dict : dict
            Dictionary of computed loss values.
        eps_p_pred : torch.Tensor
            Predicted noise for positions.
        Rpred : torch.Tensor
            Predicted rotation matrices.
        R0 : torch.Tensor
            Ground truth rotation matrices.
        res_emb_intermediate : torch.Tensor
            Intermediate residue embeddings during the denoising process.
        """
        N, L = res_emb.shape[:2]
        loss_dict = {}

        # 1--- Prepare time steps and normalize position
        if t is None:
            t = torch.randint(0, self.num_steps, (N,), dtype=torch.long, device=p0.device)

        # Get beta values and normalize the initial position
        beta = self.pos_trans.var_schedule.betas[t]
        p0 = self._normalize_position(p0)

        # Get rotation matrices from SO(3) vectors
        R0 = so3_vec2rotation(v0)
        
        # 2--- Apply diffusion (add noise)
        if denoise_structure:
            # Add noise to rotation and position
            v_noisy, _ = self.rot_trans.add_noise(v0, generation_mask, t)
            p_noisy, eps_p = self.pos_trans.add_noise(p0, generation_mask, t)
        else:
            v_noisy = v0.clone()
            p_noisy = p0.clone()

        if denoise_sequence:
            # Add noise to sequence
            _, s_noisy = self.seq_trans.add_noise(s0, generation_mask, t)
        else:
            s_noisy = s0.clone()
            
        # 3--- Predict denoised values
        v_pred, Rpred, eps_p_pred, c_denoised, residue_time_emb, res_emb_intermediate = self.eps_net(
            v_noisy, p_noisy, s_noisy, res_emb, pair_emb, beta, generation_mask, residue_mask
        )

        # 4--- Compute losses
        # Rotation loss
        loss_rot = rotation_loss(Rpred, R0)
        loss_dict = self.mask_out_loss(loss_rot, generation_mask, loss_dict, loss_type='rot')

        # Position loss
        loss_pos = F.mse_loss(eps_p_pred, eps_p, reduction='none').sum(dim=-1)
        loss_dict = self.mask_out_loss(loss_pos, generation_mask, loss_dict, loss_type='pos')

        # Sequence loss (KL divergence)
        posterior_true = self.seq_trans.posterior(s_noisy, s0, t)
        log_posterior_pred = torch.log(self.seq_trans.posterior(s_noisy, c_denoised, t) + 1e-8)
        kl_div = F.kl_div(log_posterior_pred, posterior_true, reduction='none').sum(dim=-1)
        loss_dict = self.mask_out_loss(kl_div, generation_mask, loss_dict, loss_type='seq')

        return loss_dict, eps_p_pred, Rpred, R0, res_emb_intermediate

    @torch.no_grad() 
    def sample(self, v, p, s, res_emb, pair_emb, generation_mask, residue_mask, sample_structure=True, sample_sequence=True, pbar=False, move_to_cpu=True):
        """
        Sample new sequences and structures using reverse diffusion.

        Parameters
        ----------
        v : torch.Tensor
            Initial orientations of residues.
        p : torch.Tensor
            Initial positions of residues.
        s : torch.Tensor
            Initial sequence of residues.
        res_emb : torch.Tensor
            Residue-level embeddings.
        pair_emb : torch.Tensor
            Pairwise residue embeddings.
        generation_mask : torch.Tensor
            Mask for generated residues.
        residue_mask : torch.Tensor
            Mask for valid residues.
        sample_structure : bool, optional
            Flag to indicate whether to sample structure, by default True.
        sample_sequence : bool, optional
            Flag to indicate whether to sample sequence, by default True.
        pbar : bool, optional
            Flag to indicate whether to show a progress bar, by default False.
        move_to_cpu : bool, optional
            Flag to indicate whether to move intermediate results to CPU, by default True.

        Returns
        -------
        traj : dict
            Trajectory of sampled rotations, positions, and sequences across time steps.
        s_post : torch.Tensor
            Posterior sequence probabilities after sampling.
        """
        N, L = res_emb.shape[:2]

        # Normalize initial position
        p = self._normalize_position(p)

        # 1--- Initialize random values for structure and sequence
        v_init, p_init, s_init = v, p, s
        if sample_structure:
            v_rand = random_uniform_so3([N, L], device=v.device)
            p_rand = torch.randn_like(p)
            v_init = torch.where(generation_mask[:, :, None].expand_as(v), v_rand, v)
            p_init = torch.where(generation_mask[:, :, None].expand_as(p), p_rand, p)

        if sample_sequence:
            s_rand = torch.randint_like(s, low=0, high=19)
            s_init = torch.where(generation_mask, s_rand, s)        

        # 2--- Run reverse diffusion to sample structure and sequence
        traj, s_post = self.run_reverse_diffusion(
            v_init, p_init, s_init, res_emb, pair_emb, generation_mask, residue_mask, time_step=self.num_steps, desc='Sampling...', move_to_cpu=move_to_cpu
        )
        
        return traj, s_post

    @torch.no_grad()
    def optimize(self, time_step, v, p, s, res_emb, pair_emb, generation_mask, residue_mask, sample_structure=True, sample_sequence=True, pbar=False, move_to_cpu=False):
        """
        Optimize the denoising process by adding noise and then denoising.

        Parameters
        ----------
        time_step : int
            The current time step in the diffusion process.
        v : torch.Tensor
            Initial orientations of residues.
        p : torch.Tensor
            Initial positions of residues.
        s : torch.Tensor
            Initial sequence of residues.
        res_emb : torch.Tensor
            Residue-level embeddings.
        pair_emb : torch.Tensor
            Pairwise residue embeddings.
        generation_mask : torch.Tensor
            Mask for generated residues.
        residue_mask : torch.Tensor
            Mask for valid residues.
        sample_structure : bool, optional
            Flag to indicate whether to optimize structure, by default True.
        sample_sequence : bool, optional
            Flag to indicate whether to optimize sequence, by default True.
        pbar : bool, optional
            Flag to indicate whether to show a progress bar, by default False.
        move_to_cpu : bool, optional
            Flag to indicate whether to move intermediate results to CPU, by default False.

        Returns
        -------
        traj : dict
            Optimized trajectory of rotations, positions, and sequences.
        s_post : torch.Tensor
            Posterior sequence probabilities after optimization.
        """
        N, L = res_emb.shape[:2]

        # Normalize initial position
        p = self._normalize_position(p)
        t = torch.full([N, ], fill_value=time_step, dtype=torch.long, device=p.device)
        
        # 1--- Add noise to structure and sequence
        v_init, p_init, s_init = v, p, s
        if sample_structure:
            v_noisy, _ = self.rot_trans.add_noise(v, generation_mask, t)
            p_noisy, _ = self.pos_trans.add_noise(p, generation_mask, t)
            v_init = torch.where(generation_mask[:, :, None].expand_as(v), v_noisy, v)
            p_init = torch.where(generation_mask[:, :, None].expand_as(p), p_noisy, p)

        if sample_sequence:
            _, s_noisy = self.seq_trans.add_noise(s, generation_mask, t)
            s_init = torch.where(generation_mask, s_noisy, s)
            
        # 2--- Run reverse diffusion for optimization
        traj, s_post = self.run_reverse_diffusion(
            v_init, p_init, s_init, res_emb, pair_emb, generation_mask, residue_mask, time_step=time_step, desc='Optimizing...', move_to_cpu=move_to_cpu
        )
        
        return traj, s_post

    @torch.no_grad() 
    def run_reverse_diffusion(self, v_init, p_init, s_init, res_emb, pair_emb, generation_mask, residue_mask, time_step=100, desc='Sampling...', move_to_cpu=True):
        """
        Run the reverse diffusion process to denoise and sample structure and sequence.

        Parameters
        ----------
        v_init : torch.Tensor
            Initial orientations of residues.
        p_init : torch.Tensor
            Initial positions of residues.
        s_init : torch.Tensor
            Initial sequence of residues.
        res_emb : torch.Tensor
            Residue-level embeddings.
        pair_emb : torch.Tensor
            Pairwise residue embeddings.
        generation_mask : torch.Tensor
            Mask for generated residues.
        residue_mask : torch.Tensor
            Mask for valid residues.
        time_step : int, optional
            Total number of time steps, by default 100.
        desc : str, optional
            Description for progress bar, by default 'Sampling...'.
        move_to_cpu : bool, optional
            Flag to indicate whether to move intermediate results to CPU, by default True.

        Returns
        -------
        traj : dict
            Trajectory of rotations, positions, and sequences at each time step.
        s_post : torch.Tensor
            Posterior sequence probabilities after reverse diffusion.
        """
        N, L = v_init.shape[:2]
        traj = {time_step: (v_init, self._unnormalize_position(p_init), s_init)}
        
        pbar = functools.partial(tqdm, total=time_step, desc=desc) if self.pbar else lambda x: x
            
        for t in pbar(range(time_step, 0, -1)):
            # Get values at current time step
            v_t, p_t, s_t = traj[t]
            p_t = self._normalize_position(p_t)
            beta = self.pos_trans.var_schedule.betas[t].expand([N, ])
            t_tensor = torch.full([N, ], fill_value=t, dtype=torch.long, device=p_t.device)

            # Predict denoised values
            v_tm1, R_tm1, eps_p, c_denoised, residue_time_emb, _ = self.eps_net(
                v_t, p_t, s_t, res_emb, pair_emb, beta, generation_mask, residue_mask
            )

            # Denoise rotation, position, and sequence
            v_tm1 = self.rot_trans.denoise(v_t, v_tm1, generation_mask, t_tensor)
            p_tm1 = self.pos_trans.denoise(p_t, eps_p, generation_mask, t_tensor)
            s_post, s_tm1 = self.seq_trans.denoise(s_t, c_denoised, generation_mask, t_tensor)

            if not self.sample_structure:
                v_tm1, p_tm1 = v_t, p_t
            if not self.sample_sequence:
                s_tm1 = s_t

            # Record the trajectory at (t-1)
            traj[t-1] = (v_tm1, self._unnormalize_position(p_tm1), s_tm1)

            # Optionally move to CPU to save memory
            if move_to_cpu:
                traj[t] = tuple(x.cpu() for x in traj[t])

        return traj, s_post

    def mask_out_loss(self, loss, mask, loss_dict, loss_type='rot'):
        """
        Apply mask to loss and add it to the loss dictionary.

        Parameters
        ----------
        loss : torch.Tensor
            Loss tensor to be masked.
        mask : torch.Tensor
            Mask to apply to the loss.
        loss_dict : dict
            Dictionary to store the masked loss.
        loss_type : str, optional
            Type of loss ('rot', 'pos', 'seq'), by default 'rot'.

        Returns
        -------
        dict
            Updated loss dictionary.
        """
        loss_dict[loss_type] = (loss * mask).sum() / (mask.sum().float() + 1e-8)
        return loss_dict
        
    def _normalize_position(self, p):
        """
        Normalize positions by subtracting the mean and scaling by standard deviation.

        Parameters
        ----------
        p : torch.Tensor
            Input positions to normalize.

        Returns
        -------
        torch.Tensor
            Normalized positions.
        """
        return (p - self.position_mean) / self.position_scale
        
    def _unnormalize_position(self, p):
        """
        Unnormalize positions by adding the mean and scaling by standard deviation.

        Parameters
        ----------
        p : torch.Tensor
            Input normalized positions to unnormalize.

        Returns
        -------
        torch.Tensor
            Unnormalized positions.
        """
        return p * self.position_scale + self.position_mean


class EpsilonNet(nn.Module):
    """
    Epsilon network for predicting noise during denoising in the diffusion process.

    Parameters
    ----------
    config : dict
        Configuration dictionary containing model hyperparameters.

    Attributes
    ----------
    config : dict
        Model configuration settings.
    residue_dim : int
        Dimensionality of residue embeddings.
    pair_dim : int
        Dimensionality of pairwise embeddings.
    num_layers : int
        Number of layers in the network.
    seq_emb : nn.Embedding
        Embedding layer for sequences (amino acids).
    residue_encoder : nn.Sequential
        MLP for encoding residue embeddings.
    att_encoder : ResPairformer
        Attention-based encoder for residues and pair embeddings.
    eps_pos_net : nn.Sequential
        Network for predicting noise in position.
    eps_rot_net : nn.Sequential
        Network for predicting noise in rotation.
    eps_seq_net : nn.Sequential
        Network for predicting sequence.
    """
    def __init__(self, config):
        super(EpsilonNet, self).__init__()
        
        self.config = config
        self.residue_dim = config['residue_dim']
        self.pair_dim = config['pair_dim']  
        self.num_layers = config['num_layers']
        
        # Sequence embedding for amino acids (25 unique tokens)
        self.seq_emb = nn.Embedding(25, self.residue_dim)
        
        # Residue encoder (MLP for encoding combined residue embeddings)
        self.residue_encoder = nn.Sequential(
            nn.Linear(2 * self.residue_dim, self.residue_dim), 
            nn.ReLU(), 
            nn.Linear(self.residue_dim, self.residue_dim),
        )

        # Attention-based encoder for residue and pair embeddings
        self.att_encoder = ResPairformer(config)
        
        # Networks for predicting position, rotation, and sequence noise
        self.eps_pos_net = self.get_eps_network(sequence=False, out_dim=3)
        self.eps_rot_net = self.get_eps_network(sequence=False, out_dim=3)
        self.eps_seq_net = self.get_eps_network(sequence=True, out_dim=20)

    def get_eps_network(self, sequence=False, out_dim=3):
        """
        Create the epsilon network for predicting noise in either structure or sequence.

        Parameters
        ----------
        sequence : bool, optional
            If True, create network for sequence prediction, by default False.
        out_dim : int, optional
            Output dimensionality of the network, by default 3.

        Returns
        -------
        nn.Sequential
            A sequential network for noise prediction.
        """
        # Network architecture for noise prediction
        modules = [
            nn.Linear(self.residue_dim + 3, self.residue_dim), 
            nn.ReLU(),
            nn.Linear(self.residue_dim, self.residue_dim), 
            nn.ReLU(),
            nn.Linear(self.residue_dim, out_dim)
        ]
        
        if sequence:
            # For sequence prediction, apply softmax at the output layer
            modules.append(nn.Softmax(dim=-1))
        
        return nn.Sequential(*modules)

    def forward(self, v_t, p_t, s_t, res_emb, pair_emb, beta, generation_mask, residue_mask):
        """
        Forward pass through the Epsilon network for predicting position, rotation, and sequence.

        Parameters
        ----------
        v_t : torch.Tensor
            Current orientations of residues (SO(3) vectors), shape (N, L, 3).
        p_t : torch.Tensor
            Current positions of residues (C-alpha positions), shape (N, L, 3).
        s_t : torch.Tensor
            Current sequence of residues (amino acid indices), shape (N, L).
        res_emb : torch.Tensor
            Residue-level embeddings, shape (N, L, residue_dim).
        pair_emb : torch.Tensor
            Pairwise residue embeddings, shape (N, L, L, pair_dim).
        beta : torch.Tensor
            Time-dependent noise scaling factor, shape (N,).
        generation_mask : torch.Tensor
            Mask indicating which residues are generated, shape (N, L).
        residue_mask : torch.Tensor
            Mask indicating valid residues, shape (N, L).

        Returns
        -------
        v_tm1 : torch.Tensor
            Predicted orientation (SO(3) vectors) at t-1, shape (N, L, 3).
        R_tm1 : torch.Tensor
            Predicted rotation matrix at t-1, shape (N, L, 3, 3).
        eps_pos : torch.Tensor
            Predicted noise in position, shape (N, L, 3).
        c_denoised : torch.Tensor
            Denoised categorical distribution over sequences, shape (N, L, 20).
        residue_time_emb : torch.Tensor
            Combined residue and time embeddings used for prediction, shape (N, L, residue_dim+3).
        res_emb : torch.Tensor
            Updated residue embeddings after attention encoding, shape (N, L, residue_dim).
        """
        N, L = v_t.shape[:2]

        # Get rotation matrices from SO(3) vectors
        R_t = so3_vec2rotation(v_t)
        
        # 1--- Embed residues and update embeddings
        # Concatenate the initial and current sequence embeddings, and encode them
        res_emb_t = self.seq_emb(s_t)  # Embed current sequence
        res_emb_cat = torch.cat([res_emb, res_emb_t], dim=-1)  # Concatenate with previous embeddings
        res_emb = self.residue_encoder(res_emb_cat)  # Encode concatenated embeddings
        
        # Apply attention encoder to the updated residue and pair embeddings
        res_emb = self.att_encoder(R_t, p_t, res_emb, pair_emb, residue_mask)
        
        # 2--- Combine updated residue embedding with time embedding
        # Create time embedding from beta and concatenate with residue embeddings
        t_embed = torch.stack([beta, torch.sin(beta), torch.cos(beta)], dim=-1)[:, None, :].expand(N, L, 3)
        residue_time_emb = torch.cat([res_emb, t_embed], dim=-1)
        
        # 3--- Predict position noise
        eps_pos1 = self.eps_pos_net(residue_time_emb)  # Predict noise for position
        eps_pos2 = apply_rotation_to_vector(R_t, eps_pos1)  # Apply rotation to the predicted noise
        eps_pos3 = torch.where(generation_mask[:, :, None].expand_as(eps_pos2), eps_pos2, torch.zeros_like(eps_pos2))
        
        # 4--- Predict rotation noise
        eps_rot = self.eps_rot_net(residue_time_emb)  # Predict noise for rotation
        U = quaternion_1ijk_to_rotation_matrix(eps_rot)  # Convert quaternion to rotation matrix
        R_tm1 = R_t @ U  # Apply rotation update
        v_tm1 = rotation_to_so3vec(R_tm1)  # Convert back to SO(3) vectors
        v_tm1 = torch.where(generation_mask[:, :, None].expand_as(v_tm1), v_tm1, v_t)  # Mask out non-generated regions

        # 5--- Predict sequence noise (already softmaxed)
        c_denoised = self.eps_seq_net(residue_time_emb)

        return v_tm1, R_tm1, eps_pos3, c_denoised, residue_time_emb, res_emb

class ResPairformer(nn.Module):
    """
    Residue-Pairformer network consisting of multiple ResPairBlock layers,
    which perform attention-based interactions between residue and pair embeddings.

    Parameters
    ----------
    config : dict
        Configuration dictionary containing model hyperparameters.

    Attributes
    ----------
    blocks : nn.ModuleList
        A list of ResPairBlock layers used for hierarchical attention-based feature encoding.
    """
    def __init__(self, config):
        super(ResPairformer, self).__init__()
        
        residue_dim = config['residue_dim']
        pair_dim = config['pair_dim']
        num_layers = config['num_layers']
        
        # List of Residue-Pair attention blocks
        self.blocks = nn.ModuleList([ResPairBlock(residue_dim, pair_dim) for _ in range(num_layers)])
        
    def forward(self, R, t, res_feat, pair_feat, mask):
        """
        Forward pass through the ResPairformer.

        Parameters
        ----------
        R : torch.Tensor
            Frame basis matrices, shape (N, L, 3, 3).
        t : torch.Tensor
            Frame external (absolute) coordinates, shape (N, L, 3).
        res_feat : torch.Tensor
            Node-wise features (residue features), shape (N, L, F).
        pair_feat : torch.Tensor
            Pair-wise features (residue pair interactions), shape (N, L, L, C).
        mask : torch.Tensor
            Masks for valid residues, shape (N, L).

        Returns
        -------
        torch.Tensor
            Updated node-wise features (residue features), shape (N, L, F).
        """
        for block in self.blocks:
            res_feat = block(R, t, res_feat, pair_feat, mask)
        return res_feat
    

class ResPairBlock(nn.Module):
    """
    Residue-Pair attention block that performs node-wise, pair-wise, and spatial attention
    between residue features using learned attention weights.

    Parameters
    ----------
    residue_dim : int
        Dimensionality of residue features.
    pair_dim : int
        Dimensionality of pair-wise features.
    q_dim : int, optional
        Dimensionality of query projections, by default 32.
    v_dim : int, optional
        Dimensionality of value projections, by default 32.
    num_q_points : int, optional
        Number of query points, by default 8.
    num_v_points : int, optional
        Number of value points, by default 8.
    num_heads : int, optional
        Number of attention heads, by default 12.
    bias : bool, optional
        Whether to include bias in linear projections, by default False.
    """
    def __init__(self, residue_dim, pair_dim, q_dim=32, v_dim=32, num_q_points=8, num_v_points=8, num_heads=12, bias=False):
        super(ResPairBlock, self).__init__()
        
        self.residue_dim = residue_dim
        self.pair_dim = pair_dim
        self.q_dim = q_dim
        self.v_dim = v_dim
        self.num_q_points = num_q_points
        self.num_v_points = num_v_points
        self.num_heads = num_heads
        self.bias = bias
        
        # Node layers (query, key, value projections)
        self.q_proj = nn.Linear(residue_dim, q_dim * num_heads, bias=bias)
        self.k_proj = nn.Linear(residue_dim, q_dim * num_heads, bias=bias)
        self.v_proj = nn.Linear(residue_dim, v_dim * num_heads, bias=bias)
        
        # Pair layer (pair-wise attention bias projection)
        self.pair_bias_proj = nn.Linear(pair_dim, num_heads, bias=bias)
        
        # Spatial coefficient (log-scaling for softplus)
        coeff = torch.full([1, 1, 1, num_heads], fill_value=np.log(np.exp(1.0) - 1.0))
        self.spatial_coef = nn.Parameter(coeff, requires_grad=True)
        
        # Projections for spatial query, key, and value
        self.q_point_proj = nn.Linear(residue_dim, num_q_points * num_heads * 3, bias=bias)
        self.k_point_proj = nn.Linear(residue_dim, num_q_points * num_heads * 3, bias=bias)
        self.v_point_proj = nn.Linear(residue_dim, num_v_points * num_heads * 3, bias=bias)

        # Output transformation layer
        input_features = (num_heads * v_dim) + (num_heads * pair_dim) + (num_heads * num_v_points * (3+3+1))
        self.out_transform = nn.Linear(input_features, residue_dim)
        
        # MLP transition for residual updates
        self.mlp_transition = nn.Sequential(
            nn.Linear(residue_dim, residue_dim), 
            nn.ReLU(), 
            nn.Linear(residue_dim, residue_dim), 
            nn.ReLU(), 
            nn.Linear(residue_dim, residue_dim)
        )
        
        # Layer normalization
        self.layer_norm_1 = nn.LayerNorm(residue_dim)
        self.layer_norm_2 = nn.LayerNorm(residue_dim)

    def forward(self, R, coord, residue_feat, pair_feat, mask):
        """
        Forward pass through the Residue-Pair block.

        Parameters
        ----------
        R : torch.Tensor
            Frame basis matrices, shape (N, L, 3, 3).
        coord : torch.Tensor
            Frame external (absolute) coordinates, shape (N, L, 3).
        residue_feat : torch.Tensor
            Node-wise features (residue features), shape (N, L, F).
        pair_feat : torch.Tensor
            Pair-wise features, shape (N, L, L, C).
        mask : torch.Tensor
            Mask indicating valid residues, shape (N, L).

        Returns
        -------
        torch.Tensor
            Updated node-wise features, shape (N, L, F).
        """
        # 1--- Compute attention logits for node, pair, and spatial components
        logits_node = self._node_logits(residue_feat)
        logits_pair = self._pair_logits(pair_feat)
        logits_spatial = self._spatial_logits(R, coord, residue_feat)
        
        # Combine logits and compute attention weights (alpha)
        logits_sum = (logits_node + logits_pair + logits_spatial) * np.sqrt(1/3)
        alpha = self._alpha_from_logits(logits_sum, mask)
        
        # 2--- Aggregate features from nodes, pairs, and spatial information
        feat_node = self._node_aggregation(alpha, residue_feat)
        feat_pair = self._pair_aggregation(alpha, pair_feat)
        feat_spatial = self._spatial_aggregation(alpha, R, coord, residue_feat)
        
        # 3--- Update node embeddings with the aggregated features
        feat_all = torch.cat([feat_pair, feat_node, feat_spatial], dim=-1)
        feat_all = self.out_transform(feat_all)
        feat_all = self.mask_zero(mask.unsqueeze(-1), feat_all)
        residue_feat_updated = self.layer_norm_1(residue_feat + feat_all)
        residue_feat_updated = self.layer_norm_2(residue_feat_updated + self.mlp_transition(residue_feat_updated))
        
        return residue_feat_updated

    def mask_zero(self, mask, value):
        """
        Apply masking to avoid invalid updates for padded residues.

        Parameters
        ----------
        mask : torch.Tensor
            Mask for valid residues, shape (N, L, 1).
        value : torch.Tensor
            Values to be masked, shape (N, L, F).

        Returns
        -------
        torch.Tensor
            Masked values, shape (N, L, F).
        """
        return torch.where(mask, value, torch.zeros_like(value))


    def _alpha_from_logits(self, logits, mask, inf=1e5):
        """
        Compute attention weights (alpha) from logits.

        Parameters
        ----------
        logits : torch.Tensor
            Logit matrices, shape (N, L, L, num_heads).
        mask : torch.Tensor
            Mask for valid residues, shape (N, L).
        inf : float, optional
            Large negative value to apply for masking, by default 1e5.

        Returns
        -------
        torch.Tensor
            Attention weights (alpha), shape (N, L, L, num_heads).
        """
        N, L, _, _ = logits.size()
        mask_row = mask.view(N, L, 1, 1).expand_as(logits)
        mask_pair = mask_row * mask_row.permute(0, 2, 1, 3)

        logits = torch.where(mask_pair, logits, logits - inf)
        alpha = torch.softmax(logits, dim=2)
        alpha = torch.where(mask_row, alpha, torch.zeros_like(alpha))
        return alpha
        
    def _node_logits(self, residue_feat):
        """
        Compute node-wise attention logits from residue features.

        Parameters
        ----------
        residue_feat : torch.Tensor
            Residue features, shape (N, L, residue_dim).

        Returns
        -------
        torch.Tensor
            Node-wise attention logits, shape (N, L, L, num_heads).
        """
        N, L, _ = residue_feat.size()

        # Project residue features to query and key vectors
        q = self.q_proj(residue_feat).view(N, L, self.num_heads, self.q_dim)
        k = self.k_proj(residue_feat).view(N, L, self.num_heads, self.q_dim)
        
        # Compute attention logits
        logits = q.unsqueeze(2) * k.unsqueeze(1) * (1 / np.sqrt(self.q_dim))
        logits = logits.sum(-1)
        
        return logits

    def _pair_logits(self, pair_feat):
        """
        Compute pair-wise attention logits from pair features.

        Parameters
        ----------
        pair_feat : torch.Tensor
            Pair-wise features, shape (N, L, L, pair_dim).

        Returns
        -------
        torch.Tensor
            Pair-wise attention logits, shape (N, L, L, num_heads).
        """
        return self.pair_bias_proj(pair_feat)

    def _compute_q_or_k(self, residue_feat, R, coord, fn):
        """
        Compute query or key vectors in global frame of reference.

        Parameters
        ----------
        residue_feat : torch.Tensor
            Residue features, shape (N, L, residue_dim).
        R : torch.Tensor
            Frame basis matrices, shape (N, L, 3, 3).
        coord : torch.Tensor
            Frame external coordinates, shape (N, L, 3).
        fn : callable
            Function for projection (for query or key).

        Returns
        -------
        torch.Tensor
            Projected query or key vectors, shape (N, L, num_heads, num_q_points*3).
        """
        N, L = residue_feat.size()[:2]
        
        h = fn(residue_feat).view(N, L, self.num_heads * self.num_q_points, 3)
        h = local2global(R, coord, h)
        h = h.reshape(N, L, self.num_heads, -1)
        return h

    def _spatial_logits(self, R, coord, residue_feat):
        """
        Compute spatial attention logits based on frame transformations.

        Parameters
        ----------
        R : torch.Tensor
            Frame basis matrices, shape (N, L, 3, 3).
        coord : torch.Tensor
            Frame external coordinates, shape (N, L, 3).
        residue_feat : torch.Tensor
            Residue features, shape (N, L, residue_dim).

        Returns
        -------
        torch.Tensor
            Spatial attention logits, shape (N, L, L, num_heads).
        """
        q = self._compute_q_or_k(residue_feat, R, coord, fn=self.q_point_proj)
        k = self._compute_q_or_k(residue_feat, R, coord, fn=self.k_point_proj)
        
        sum_sq_dist = ((q.unsqueeze(2) - k.unsqueeze(1)) ** 2).sum(-1)
        gamma = F.softplus(self.spatial_coef)
        logits_spatial = sum_sq_dist * ((-1 * gamma * np.sqrt(2 / (9 * self.num_q_points))) / 2)
        
        return logits_spatial

    def _pair_aggregation(self, alpha, pair_feat):
        """
        Aggregate pair-wise features using attention weights.

        Parameters
        ----------
        alpha : torch.Tensor
            Attention weights, shape (N, L, L, num_heads).
        pair_feat : torch.Tensor
            Pair-wise features, shape (N, L, L, pair_dim).

        Returns
        -------
        torch.Tensor
            Aggregated pair-wise features, shape (N, L, num_heads * pair_dim).
        """
        feat_p2n = alpha.unsqueeze(-1) * pair_feat.unsqueeze(-2)
        feat_p2n = feat_p2n.sum(dim=2)
        
        return feat_p2n.reshape(pair_feat.size(0), pair_feat.size(1), -1)

    def _node_aggregation(self, alpha, residue_feat):
        """
        Aggregate node-wise features using attention weights.

        Parameters
        ----------
        alpha : torch.Tensor
            Attention weights, shape (N, L, L, num_heads).
        residue_feat : torch.Tensor
            Residue features, shape (N, L, residue_dim).

        Returns
        -------
        torch.Tensor
            Aggregated node-wise features, shape (N, L, num_heads * v_dim).
        """
        v = self.v_proj(residue_feat).view(residue_feat.size(0), residue_feat.size(1), self.num_heads, self.v_dim)
        feat_node = alpha.unsqueeze(-1) * v.unsqueeze(1)
        feat_node = feat_node.sum(dim=2)
        
        return feat_node.reshape(residue_feat.size(0), residue_feat.size(1), -1)


    def _spatial_aggregation(self, alpha, R, coord, residue_feat):
        """
        Aggregate spatial features using attention weights.

        Parameters
        ----------
        alpha : torch.Tensor
            Attention weights, shape (N, L, L, num_heads).
        R : torch.Tensor
            Frame basis matrices, shape (N, L, 3, 3).
        coord : torch.Tensor
            Frame external coordinates, shape (N, L, 3).
        residue_feat : torch.Tensor
            Residue features, shape (N, L, residue_dim).

        Returns
        -------
        torch.Tensor
            Aggregated spatial features, shape (N, L, num_heads * (points + direction + distance)).
        """
        # Project residue features to value points in global frame
        v_points = self.v_point_proj(residue_feat).view(residue_feat.size(0), residue_feat.size(1), self.num_heads * self.num_v_points, 3)
        
        # Convert local to global coordinates
        v_points = local2global(R, coord, v_points.reshape(residue_feat.size(0), residue_feat.size(1), self.num_heads, self.num_v_points, 3))
        
        # Attention-weighted aggregation of spatial features
        agg_points = alpha.reshape(residue_feat.size(0), residue_feat.size(1), residue_feat.size(1), self.num_heads, 1, 1) * v_points.unsqueeze(1)
        agg_points = agg_points.sum(dim=2)
        
        # Convert global back to local coordinates
        feat_points = global2local(R, coord, agg_points)
        
        # Calculate distance and direction features
        feat_distance = feat_points.norm(dim=-1)
        feat_direction = normalize_vector(feat_points, dim=-1, eps=1e-4)
        
        # Concatenate points, distance, and direction features
        feat_spatial = torch.cat([
            feat_points.reshape(residue_feat.size(0), residue_feat.size(1), -1),
            feat_distance.reshape(residue_feat.size(0), residue_feat.size(1), -1),
            feat_direction.reshape(residue_feat.size(0), residue_feat.size(1), -1)
        ], dim=-1)
        
        return feat_spatial

        
class VarianceSchedule(nn.Module):
    """
    Variance schedule module to compute alphas, betas, and sigmas used in diffusion processes.

    Parameters
    ----------
    num_steps : int, optional
        Number of time steps for the variance schedule. Default is 100.
    s : float, optional
        Smoothing factor for variance schedule calculation. Default is 0.01.
    """
    def __init__(self, num_steps=100, s=0.01):
        super().__init__()

        T = num_steps
        t = torch.arange(0, num_steps+1, dtype=torch.float)

        # Compute alphas and alpha_bars based on cosine schedule
        ft = (torch.cos((np.pi / 2) * (t / T + s) / (1 + s)) ** 2)
        alpha_bars = ft / ft[0]

        # Compute betas from alpha_bars
        betas = 1 - (alpha_bars[1:] / alpha_bars[:-1])
        betas = torch.cat([torch.zeros([1]), betas], dim=0).clamp_max(0.999)

        # Compute sigmas using alpha_bars and betas
        sigmas = torch.zeros_like(betas)
        for i in range(1, betas.size(0)):
            sigmas[i] = ((1 - alpha_bars[i-1]) / (1 - alpha_bars[i])) * betas[i]
        sigmas = torch.sqrt(sigmas)

        # Store parameters as buffers
        self.betas = torch.nn.Parameter(data=betas, requires_grad=False)
        self.alphas = torch.nn.Parameter(data=1 - betas, requires_grad=False)
        self.alpha_bars = torch.nn.Parameter(data=alpha_bars, requires_grad=False)
        self.sigmas = torch.nn.Parameter(data=sigmas, requires_grad=False)


class ApproxAngularDistribution(nn.Module):
    """
    Approximate angular distribution using either histograms or Gaussian approximation
    depending on the standard deviation.

    Parameters
    ----------
    stddevs : list of float
        List of standard deviations for different distributions.
    std_threshold : float, optional
        Threshold to decide whether to use histogram approximation or Gaussian sampling.
        Default is 0.1.
    num_bins : int, optional
        Number of bins for the histogram. Default is 8192.
    num_iters : int, optional
        Number of iterations for the PDF approximation. Default is 1024.
    """
    def __init__(self, stddevs, std_threshold=0.1, num_bins=8192, num_iters=1024):
        super().__init__()
        self.std_threshold = std_threshold
        self.num_bins = num_bins
        self.num_iters = num_iters

        # Register standard deviations and compute mask for Gaussian approximation
        self.register_buffer('stddevs', torch.FloatTensor(stddevs))
        self.register_buffer('approx_mask', self.stddevs <= std_threshold)
        
        # Precompute histograms for angular distributions
        self._precompute_histograms()

    def sample(self, std_idx):
        """
        Sample angles from the approximate distribution given a standard deviation index.

        Parameters
        ----------
        std_idx : torch.Tensor
            Tensor of indices representing different standard deviations.

        Returns
        -------
        torch.Tensor
            Sampled angles based on the distribution, shaped according to input.
        """
        size = std_idx.size()
        std_idx = std_idx.flatten()

        # Sample from histogram
        prob = self.hist[std_idx]
        bin_idx = torch.multinomial(prob[:, :-1], num_samples=1).squeeze(-1)
        bin_start = self.X[std_idx, bin_idx]
        bin_width = self.X[std_idx, bin_idx + 1] - self.X[std_idx, bin_idx]
        samples_from_hist = bin_start + torch.rand_like(bin_start) * bin_width

        # Sample from Gaussian approximation
        std = self.stddevs[std_idx]
        mu = 2 * std
        samples_from_gauss = mu + torch.randn_like(mu) * std
        samples_from_gauss = samples_from_gauss.abs() % math.pi

        # Choose between histogram or Gaussian samples based on mask
        gauss_mask = self.approx_mask[std_idx]
        samples = torch.where(gauss_mask, samples_from_gauss, samples_from_hist)

        return samples.reshape(size)

    def _precompute_histograms(self):
        """
        Precompute histograms for each standard deviation in `stddevs`.
        """
        X, Y = [], []

        # Compute histogram for each standard deviation
        for std in self.stddevs:
            std = std.item()
            x = torch.linspace(0, math.pi, self.num_bins)
            y = self._pdf(x, std, self.num_iters)
            y = torch.nan_to_num(y).clamp_min(0)
            X.append(x)
            Y.append(y)

        # Register buffers for histogram bins and probabilities
        self.register_buffer('X', torch.stack(X, dim=0))
        self.register_buffer('hist', torch.stack(Y, dim=0))

    @staticmethod
    def _pdf(x, std, num_iters):
        """
        Compute the probability density function for angular distribution.

        Parameters
        ----------
        x : torch.Tensor
            Input angles.
        std : float
            Standard deviation of the distribution.
        num_iters : int
            Number of iterations for the approximation.

        Returns
        -------
        torch.Tensor
            Probability densities for input angles.
        """
        x = x[:, None]
        c = ((1 - torch.cos(x)) / math.pi)
        l = torch.arange(0, num_iters)[None, :]
        a = (2 * l + 1) * torch.exp(-l * (l + 1) * (std ** 2))
        b = (torch.sin((l + 0.5) * x) + 1e-6) / (torch.sin(x / 2) + 1e-6)
        f = (c * a * b).sum(dim=-1)
        return f


class RotationTransition(nn.Module):
    """
    Handles rotation-based transitions for forward and reverse diffusion processes.

    Parameters
    ----------
    config : dict
        Configuration dictionary containing model parameters like number of steps and device.
    """
    def __init__(self, config):
        super(RotationTransition, self).__init__()

        self.config = config
        self.num_steps = config['num_steps']
        self.var_schedule = VarianceSchedule(num_steps=self.num_steps, s=config['ns_bias']).to(config["device"])

        # Forward diffusion angular distribution
        c1 = torch.sqrt(1 - self.var_schedule.alpha_bars)
        self.angular_distribution_forward = ApproxAngularDistribution(c1.tolist())

        # Backward diffusion angular distribution
        sigmas = self.var_schedule.sigmas
        self.angular_distribution_backward = ApproxAngularDistribution(sigmas.tolist())

    def add_noise(self, v0, generation_mask, t):
        """
        Adds noise to rotations during the forward diffusion process.

        Parameters
        ----------
        v0 : torch.Tensor
            Initial SO(3) vectors, shape (N, L, 3).
        generation_mask : torch.Tensor
            Mask for generation, shape (N, L).
        t : torch.Tensor
            Time step, shape (N,).

        Returns
        -------
        torch.Tensor
            Noisy SO(3) vectors, shape (N, L, 3).
        torch.Tensor
            Noise applied in SO(3), shape (N, L, 3).
        """
        N, L = generation_mask.size()
        alpha_bar = self.var_schedule.alpha_bars[t]

        # Compute scaling factors
        c0 = torch.sqrt(alpha_bar).view(-1, 1, 1)
        c1 = torch.sqrt(1 - alpha_bar).view(-1, 1, 1)

        # Sample rotation noise from IGso3
        e_scaled = randn_so3(t[:, None].expand(N, L), self.angular_distribution_forward, device=t.device)
        E_scaled = so3_vec2rotation(e_scaled)

        # Apply scaling to the true rotation and add noise
        R0_scaled = so3_vec2rotation(c0 * v0)
        R_noisy = R0_scaled @ E_scaled
        v_noisy = rotation_to_so3vec(R_noisy)

        # Apply the generation mask
        v_noisy = torch.where(generation_mask[..., None].expand_as(v0), v_noisy, v0)

        return v_noisy, e_scaled

    def denoise(self, v_t, v_tm1, generation_mask, t):
        """
        Denoises rotations during the reverse diffusion process.

        Parameters
        ----------
        v_t : torch.Tensor
            Noisy SO(3) vectors at time t, shape (N, L, 3).
        v_tm1 : torch.Tensor
            Predicted SO(3) vectors at time t-1, shape (N, L, 3).
        generation_mask : torch.Tensor
            Mask for generation, shape (N, L).
        t : torch.Tensor
            Time step, shape (N,).

        Returns
        -------
        torch.Tensor
            Denoised SO(3) vectors, shape (N, L, 3).
        """
        N, L = generation_mask.size()

        # Sample rotation noise for the backward diffusion
        e = randn_so3(t[:, None].expand(N, L), self.angular_distribution_backward, device=t.device)
        e = torch.where((t > 1)[:, None, None].expand(N, L, 3), e, torch.zeros_like(e))

        # Apply rotation and denoise
        E = so3_vec2rotation(e)
        R_tm1 = so3_vec2rotation(v_tm1)
        R_tm1 = R_tm1 @ E
        v_tm1 = rotation_to_so3vec(R_tm1)

        # Apply the generation mask
        v_tm1 = torch.where(generation_mask[..., None].expand_as(v_tm1), v_tm1, v_t)

        return v_tm1


class PositionTransition(nn.Module):
    """
    Handles position-based transitions for forward and reverse diffusion processes.

    Parameters
    ----------
    config : dict
        Configuration dictionary containing model parameters like number of steps and device.
    """
    def __init__(self, config):
        super(PositionTransition, self).__init__()

        self.config = config
        self.num_steps = config['num_steps']
        self.var_schedule = VarianceSchedule(num_steps=self.num_steps).to(config["device"])
        self.alphas = self.var_schedule.alphas
        self.alpha_bars = self.var_schedule.alpha_bars
        self.sigmas = self.var_schedule.sigmas

    def add_noise(self, p0, generation_mask, t):
        """
        Adds noise to positions during the forward diffusion process.

        Parameters
        ----------
        p0 : torch.Tensor
            Initial positions, shape (N, L, 3).
        generation_mask : torch.Tensor
            Mask for generation, shape (N, L).
        t : torch.Tensor
            Time step, shape (N,).

        Returns
        -------
        torch.Tensor
            Noisy positions, shape (N, L, 3).
        torch.Tensor
            Noise applied to positions, shape (N, L, 3).
        """
        alpha_bar = self.var_schedule.alpha_bars[t]

        # Compute scaling factors
        c0 = torch.sqrt(alpha_bar).view(-1, 1, 1)
        c1 = torch.sqrt(1 - alpha_bar).view(-1, 1, 1)

        eps = torch.randn_like(p0)
        eps_input = torch.randn_like(p0) if self.config["input_error"] else torch.zeros_like(p0)
        gamma = 0.1 * torch.ones_like(t).view(-1, 1, 1)

        # Add noise to positions
        p_noisy = c0 * p0 + c1 * (eps + gamma * eps_input)
        p_noisy = torch.where(generation_mask[..., None].expand_as(p0), p_noisy, p0)

        return p_noisy, eps

    def denoise(self, p_t, eps_hat, generation_mask, t):
        """
        Denoises positions during the reverse diffusion process.

        Parameters
        ----------
        p_t : torch.Tensor
            Noisy positions at time t, shape (N, L, 3).
        eps_hat : torch.Tensor
            Predicted noise to remove, shape (N, L, 3).
        generation_mask : torch.Tensor
            Mask for generation, shape (N, L).
        t : torch.Tensor
            Time step, shape (N,).

        Returns
        -------
        torch.Tensor
            Denoised positions, shape (N, L, 3).
        """
        alpha = self.alphas[t].clamp_min(self.alphas[-2])
        alpha_bar = self.alpha_bars[t]
        sigma = self.sigmas[t].view(-1, 1, 1)

        # Compute scaling factors for denoising
        c0 = (1.0 / torch.sqrt(alpha + 1e-8)).view(-1, 1, 1)
        c1 = ((1.0 - alpha) / torch.sqrt(1 - alpha_bar + 1e-8)).view(-1, 1, 1)

        # Sample random noise
        z = torch.where((t > 1)[:, None, None].expand_as(p_t), torch.randn_like(p_t), torch.zeros_like(p_t))

        # Compute denoised positions
        p_tm1 = c0 * (p_t - c1 * eps_hat) + sigma * z
        p_tm1 = torch.where(generation_mask[..., None].expand_as(p_t), p_tm1, p_t)

        return p_tm1


class SequenceTransition(nn.Module):
    """
    Handles sequence-based transitions for forward and reverse diffusion processes.

    Parameters
    ----------
    config : dict
        Configuration dictionary containing model parameters like number of steps and device.
    """
    def __init__(self, config):
        super(SequenceTransition, self).__init__()

        self.config = config
        self.num_steps = config['num_steps']
        self.K = config['num_aa_types']
        self.var_schedule = VarianceSchedule(num_steps=self.num_steps).to(config["device"])
        self.alphas = self.var_schedule.alphas
        self.alpha_bars = self.var_schedule.alpha_bars

    @staticmethod
    def _sample(c):
        """
        Samples sequences based on categorical probabilities.

        Parameters
        ----------
        c : torch.Tensor
            Input probabilities for each category, shape (N, L, K).

        Returns
        -------
        torch.Tensor
            Sampled sequences, shape (N, L).
        """
        N, L, K = c.size()
        c = c.view(N * L, K) + 1e-8
        seqs = torch.multinomial(c, 1).view(N, L)
        return seqs

    def posterior(self, x_t, x_0, t):
        """
        Computes the posterior probability at time step t-1.

        Parameters
        ----------
        x_t : torch.Tensor
            Sequence at time t, either in categorical form (N, L) or probability form (N, L, K).
        x_0 : torch.Tensor
            Original sequence at time t=0, either in categorical form (N, L) or probability form (N, L, K).
        t : torch.Tensor
            Time step, shape (N,).

        Returns
        -------
        torch.Tensor
            Posterior probability, shape (N, L, K).
        """
        K = self.K

        c_0 = x_0 if x_0.dim() == 3 else self.clampped_one_hot(x_0, num_classes=K).float()
        c_t = x_t if x_t.dim() == 3 else self.clampped_one_hot(x_t, num_classes=K).float()

        alpha = self.alphas[t][:, None, None]
        alpha_bar = self.alpha_bars[torch.clamp(t - 1, min=0)][:, None, None]

        theta = (alpha * c_t + (1 - alpha) / K) * (alpha_bar * c_0 + (1 - alpha_bar) / K)
        theta = theta / (theta.sum(dim=-1, keepdim=True) + 1e-8)

        return theta

    def clampped_one_hot(self, x, num_classes):
        """
        Converts a tensor to a clamped one-hot encoding.

        Parameters
        ----------
        x : torch.Tensor
            Input tensor with categories, shape (N, L).
        num_classes : int
            Number of classes for one-hot encoding.

        Returns
        -------
        torch.Tensor
            One-hot encoded tensor, shape (N, L, num_classes).
        """
        mask = (x >= 0) & (x < num_classes)
        x = x.clamp(min=0, max=num_classes - 1)
        y = F.one_hot(x, num_classes) * mask[..., None]
        return y

    def add_noise(self, x0, generation_mask, t):
        """
        Adds noise to sequences during the forward diffusion process.

        Parameters
        ----------
        x0 : torch.Tensor
            Original sequence at time t=0, shape (N, L).
        generation_mask : torch.Tensor
            Mask for generation, shape (N, L).
        t : torch.Tensor
            Time step, shape (N,).

        Returns
        -------
        torch.Tensor
            Noisy sequence probabilities, shape (N, L, K).
        torch.Tensor
            Sampled noisy sequence, shape (N, L).
        """
        N, L = x0.size()
        K = self.K

        c0 = self.clampped_one_hot(x0, num_classes=K).float()
        alpha_bar = self.alpha_bars[t][:, None, None]

        uniform_noise = 1 / K
        c_noisy = (alpha_bar * c0) + ((1 - alpha_bar) * uniform_noise)
        c_t = torch.where(generation_mask[..., None].expand(N, L, K), c_noisy, c0)
        x_t = self._sample(c_t)

        return c_t, x_t

    def denoise(self, x_t, c0_pred, generation_mask, t):
        """
        Denoises sequences during the reverse diffusion process.

        Parameters
        ----------
        x_t : torch.Tensor
            Noisy sequence at time t, shape (N, L).
        c0_pred : torch.Tensor
            Predicted sequence probabilities at time t=0, shape (N, L, K).
        generation_mask : torch.Tensor
            Mask for generation, shape (N, L).
        t : torch.Tensor
            Time step, shape (N,).

        Returns
        -------
        torch.Tensor
            Posterior probability at time t-1, shape (N, L, K).
        torch.Tensor
            Sampled sequence at time t-1, shape (N, L).
        """
        N, L = x_t.size()
        c_t = self.clampped_one_hot(x_t, num_classes=self.K).float()
        post = self.posterior(c_t, c0_pred, t=t)
        post = torch.where(generation_mask[..., None].expand(N, L, self.K), post, c_t)
        x_tm1 = self._sample(post)

        return post, x_tm1


class ResidueEmbedding(nn.Module):
    """
    Embeds residue-level features, including amino acid types, chain types, dihedral angles,
    and atom coordinates, into a fixed-dimensional embedding space.

    Parameters
    ----------
    residue_dim : int
        Dimension of the residue embedding.
    num_atoms : int
        Number of atoms to consider in each residue.
    max_aa_types : int, optional
        Maximum number of amino acid types (default is 22).
    max_chain_types : int, optional
        Maximum number of chain types (default is 10).
    """
    def __init__(self, residue_dim, num_atoms, max_aa_types=22, max_chain_types=10):
        super(ResidueEmbedding, self).__init__()
        
        self.residue_dim = residue_dim
        self.num_atoms = num_atoms
        self.max_aa_types = max_aa_types
        
        # Embeddings for amino acids, chain types, and dihedral angles
        self.aa_emb = nn.Embedding(max_aa_types, residue_dim)
        self.chain_emb = nn.Embedding(max_chain_types, residue_dim, padding_idx=0)
        self.dihedral_emb = DihedralEncoding()

        # Input dimension for the MLP layer
        input_dim = residue_dim + max_aa_types * num_atoms * 3 + self.dihedral_emb.get_dim() + residue_dim
        self.mlp = nn.Sequential(
            nn.Linear(input_dim, 2 * residue_dim), nn.ReLU(), 
            nn.Linear(2 * residue_dim, residue_dim), nn.ReLU(), 
            nn.Linear(residue_dim, residue_dim), nn.ReLU(), 
            nn.Linear(residue_dim, residue_dim)
        )

    def forward(self, aa, res_nb, fragment_type, pos_atoms, mask_atoms, structure_mask=None, sequence_mask=None, generation_mask_bar=None):
        """
        Forward pass for residue embedding.

        Parameters
        ----------
        aa : torch.Tensor
            Amino acid types, shape (N, L).
        res_nb : torch.Tensor
            Residue numbers, shape (N, L).
        fragment_type : torch.Tensor
            Chain fragment types, shape (N, L).
        pos_atoms : torch.Tensor
            Atom coordinates, shape (N, L, A, 3).
        mask_atoms : torch.Tensor
            Atom masks, shape (N, L, A).
        structure_mask : torch.Tensor, optional
            Mask for known structures, shape (N, L).
        sequence_mask : torch.Tensor, optional
            Mask for known amino acids, shape (N, L).
        generation_mask_bar : torch.Tensor, optional
            Mask for generated amino acids, shape (N, L).

        Returns
        -------
        torch.Tensor
            Residue embeddings, shape (N, L, residue_dim).
        """
        N, L = aa.size()

        # Mask for valid residues based on atoms
        mask_residue = mask_atoms[:, :, BBHeavyAtom.CA]
        pos_atoms = pos_atoms[:, :, :self.num_atoms]
        mask_atoms = mask_atoms[:, :, :self.num_atoms]

        # 1. Chain embedding (N, L, residue_dim)
        chain_emb = self.chain_emb(fragment_type)

        # 2. Amino acid embedding (N, L, residue_dim)
        if sequence_mask is not None:
            aa = torch.where(sequence_mask, aa, torch.full_like(aa, fill_value=AALib.UNK))
        aa_emb = self.aa_emb(aa)

        # 3. Coordinate embedding (N, L, max_aa_types * num_atoms * 3)
        bb_center = pos_atoms[:, :, BBHeavyAtom.CA]
        R = get_3d_basis(center=bb_center, p1=pos_atoms[:, :, BBHeavyAtom.C], p2=pos_atoms[:, :, BBHeavyAtom.N])
        local_coords = global2local(R, bb_center, pos_atoms)
        local_coords = torch.where(mask_atoms[:, :, :, None].expand_as(local_coords), local_coords, torch.zeros_like(local_coords))

        # Expand amino acid embedding and apply mask
        aa_expand = aa[:, :, None, None, None].expand(N, L, self.max_aa_types, self.num_atoms, 3)
        aa_range = torch.arange(0, self.max_aa_types)[None, None, :, None, None].expand(N, L, self.max_aa_types, self.num_atoms, 3).to(aa_expand)
        aa_expand_mask = (aa_expand == aa_range)
        local_coords_expand = local_coords[:, :, None, :, :].expand(N, L, self.max_aa_types, self.num_atoms, 3)
        local_coords = torch.where(aa_expand_mask, local_coords_expand, torch.zeros_like(local_coords_expand))
        local_coords = local_coords.reshape(N, L, self.max_aa_types * self.num_atoms * 3)

        if structure_mask is not None and structure_mask.dim() == 2:
            structure_mask = structure_mask.unsqueeze(-1)  # Expand to (N, L, 1)
            local_coords = local_coords * structure_mask

        # 4. Dihedral angle embedding (N, L, 39)
        bb_dihedral, mask_bb_dihedral = get_bb_dihedral_angles(pos_atoms, fragment_type, res_nb=res_nb, mask_residue=mask_residue)
        dihedral_emb = self.dihedral_emb(bb_dihedral[:, :, :, None])
        dihedral_emb = dihedral_emb * mask_bb_dihedral[:, :, :, None]
        dihedral_emb = dihedral_emb.reshape(N, L, -1)

        if structure_mask is not None:
            dihedral_mask = torch.logical_and(
                structure_mask.squeeze(-1),
                torch.logical_and(
                    torch.roll(structure_mask.squeeze(-1), shifts=+1, dims=1), 
                    torch.roll(structure_mask.squeeze(-1), shifts=-1, dims=1)
                )
            )
            dihedral_emb = dihedral_emb * dihedral_mask[:, :, None]

        # 5. Concatenate all features and apply mask
        all_features = torch.cat([aa_emb, local_coords, dihedral_emb, chain_emb], dim=-1)
        all_features = all_features * mask_residue[:, :, None].expand_as(all_features)

        # 6. Apply MLP to generate final embeddings
        out_features = self.mlp(all_features)
        out_features = out_features * mask_residue[:, :, None]

        return out_features


class PairEmbedding(nn.Module):
    """
    Embeds pairwise residue features including amino acid pairs, relative positions, atom-atom distances, and dihedral angles.

    Parameters
    ----------
    pair_dim : int
        Dimension of the pair embedding.
    num_atoms : int
        Number of atoms to consider for pairwise distance calculations.
    max_aa_types : int, optional
        Maximum number of amino acid types (default is 22).
    max_relpos : int, optional
        Maximum relative position (default is 32).
    """
    def __init__(self, pair_dim, num_atoms, max_aa_types=22, max_relpos=32):
        super(PairEmbedding, self).__init__()

        self.pair_dim = pair_dim
        self.num_atoms = num_atoms
        self.max_aa_types = max_aa_types
        self.max_relpos = max_relpos

        # Pair embedding, relative position embedding, and distance embedding
        self.aa_pair_emb = nn.Embedding(max_aa_types**2, pair_dim)
        self.relpos_emb = nn.Embedding(2 * max_relpos + 1, pair_dim)
        self.aapair_to_dist_coeff = nn.Embedding(max_aa_types**2, num_atoms**2)
        nn.init.zeros_(self.aapair_to_dist_coeff.weight)

        # Distance embedding and dihedral embedding
        self.dist_emb = nn.Sequential(nn.Linear(num_atoms**2, pair_dim), nn.ReLU(), nn.Linear(pair_dim, pair_dim), nn.ReLU())
        self.dihedral_emb = DihedralEncoding()
        dihedral_feature_dim = self.dihedral_emb.get_dim(num_dim=2)

        # MLP for final pair embedding
        all_features_dim = 3 * pair_dim + dihedral_feature_dim
        self.mlp = nn.Sequential(nn.Linear(all_features_dim, pair_dim), nn.ReLU(), nn.Linear(pair_dim, pair_dim), nn.ReLU(), nn.Linear(pair_dim, pair_dim))

    def forward(self, aa, res_nb, fragment_type, pos_atoms, mask_atoms, structure_mask=None, sequence_mask=None):
        """
        Forward pass for pairwise residue embedding.

        Parameters
        ----------
        aa : torch.Tensor
            Amino acid types, shape (N, L).
        res_nb : torch.Tensor
            Residue numbers, shape (N, L).
        fragment_type : torch.Tensor
            Chain fragment types, shape (N, L).
        pos_atoms : torch.Tensor
            Atom coordinates, shape (N, L, A, 3).
        mask_atoms : torch.Tensor
            Atom masks, shape (N, L, A).
        structure_mask : torch.Tensor, optional
            Mask for known structures, shape (N, L).
        sequence_mask : torch.Tensor, optional
            Mask for known amino acids, shape (N, L).

        Returns
        -------
        torch.Tensor
            Pairwise residue embeddings, shape (N, L, L, pair_dim).
        """
        N, L = aa.size()

        # Mask for valid residues
        mask_residue = mask_atoms[:, :, BBHeavyAtom.CA]
        pos_atoms = pos_atoms[:, :, :self.num_atoms]
        mask_atoms = mask_atoms[:, :, :self.num_atoms]
        mask2d_pair = mask_residue[:, :, None] * mask_residue[:, None, :]

        # 1. Pairwise amino acid embedding
        if sequence_mask is not None:
            aa = torch.where(sequence_mask, aa, torch.full_like(aa, fill_value=AALib.UNK))
        aa_pair = self.max_aa_types * aa[:, :, None] + aa[:, None, :]
        aa_pair_emb = self.aa_pair_emb(aa_pair)

        # 2. Relative position embedding
        relative_pos = res_nb[:, :, None] - res_nb[:, None, :]
        relative_pos = torch.clamp(relative_pos, min=-self.max_relpos, max=self.max_relpos) + self.max_relpos
        relative_pos_emb = self.relpos_emb(relative_pos)
        mask2d_chain = (fragment_type[:, :, None] == fragment_type[:, None, :])
        relative_pos_emb = relative_pos_emb * mask2d_chain[:, :, :, None]

        # 3. Atom-atom distance embedding
        a2a_coords = pos_atoms[:, :, None, :, None] - pos_atoms[:, None, :, None, :]
        a2a_dist = torch.linalg.norm(a2a_coords, dim=-1)
        a2a_dist_nm = a2a_dist / 10.
        a2a_dist_nm = a2a_dist_nm.reshape(N, L, L, -1)
        coeff = F.softplus(self.aapair_to_dist_coeff(aa_pair))
        dist_rbf = torch.exp(-1.0 * coeff * a2a_dist_nm**2)
        mask2d_aa_pair = mask_atoms[:, :, None, :, None] * mask_atoms[:, None, :, None, :]
        mask2d_aa_pair = mask2d_aa_pair.reshape(N, L, L, -1)
        dist_emb = self.dist_emb(dist_rbf * mask2d_aa_pair)

        # 4. Dihedral angle embedding
        dihedral_angles = pairwise_dihedrals(pos_atoms)
        dihedral_emb = self.dihedral_emb(dihedral_angles)

        # Apply structure mask to avoid data leakage
        if structure_mask is not None and structure_mask.dim() == 2:
            structure_mask = structure_mask.unsqueeze(-1)
            dist_emb = dist_emb * structure_mask[:, :, :, None]
            dihedral_emb = dihedral_emb * structure_mask[:, :, :, None]

        # 5. Combine all features
        all_features = torch.cat([aa_pair_emb, relative_pos_emb, dist_emb, dihedral_emb], dim=-1)
        all_features = all_features * mask2d_pair[:, :, :, None].expand_as(all_features)

        # 6. Apply MLP for final pairwise embedding
        out = self.mlp(all_features)
        out = out * mask2d_pair[:, :, :, None]

        return out


class DihedralEncoding(nn.Module):
    """
    Dihedral angle encoding using sinusoidal and cosinusoidal transformations.

    Parameters
    ----------
    num_freq_bands : int, optional
        Number of frequency bands for encoding (default is 3).
    """
    def __init__(self, num_freq_bands=3):
        super().__init__()

        self.num_freq_bands = num_freq_bands
        self.register_buffer('freq_bands', torch.FloatTensor([i + 1 for i in range(num_freq_bands)] + [1. / (i + 1) for i in range(num_freq_bands)]))

    def forward(self, x):
        """
        Forward pass for dihedral encoding.

        Parameters
        ----------
        x : torch.Tensor
            Backbone dihedral angles, shape (B, L, 3, 1).

        Returns
        -------
        torch.Tensor
            Encoded dihedral angles, shape (B, L, 3, -1).
        """
        shape = list(x.shape[:-1]) + [-1]
        x = x.unsqueeze(-1)
        angle_emb = torch.cat([x, torch.sin(x * self.freq_bands), torch.cos(x * self.freq_bands)], dim=-1)
        return angle_emb.reshape(shape)

    def get_dim(self, num_dim=3):
        """
        Returns the dimension of the dihedral encoding.

        Parameters
        ----------
        num_dim : int, optional
            Number of dihedral angles (default is 3).

        Returns
        -------
        int
            Dimension of the dihedral encoding.
        """
        return num_dim * (1 + 2 * 2 * self.num_freq_bands)
```

Contents of utils/transformations.py:
```
"""
Author: Talip Ucar
email: ucabtuc@gmail.com

Description: A library of transformations applied to antibodies
"""

import copy
import random
import numpy as np
import torch
from typing import List, Optional
from utils.protein_constants import BBHeavyAtom, AALib, resindex_to_ressymb


class MaskCDRs:
    """
    A class to mask the Complementarity-Determining Regions (CDRs) of an antibody.
    It allows masking of specific CDRs, random CDR selection, and the option to perturb CDR lengths.

    Parameters
    ----------
    config : dict
        Configuration dictionary that specifies the CDRs to mask and other settings.
    sampling : bool, optional
        Whether to use sampling mode (default is False).
    """
    
    def __init__(self, config, sampling=False):
        self.config = config
        self.cdrs_to_mask = config["sampling"]["cdrs_to_mask"] if sampling else config["cdrs_to_mask"]
        self.perturb_length = config["perturb_length"]
        
    def __call__(self, structure):
        """
        Apply masking to CDR regions in the provided antibody.

        Parameters
        ----------
        structure : dict
            Antibody structure containing 'heavy' and 'light' chains.

        Returns
        -------
        dict
            Updated structure with masked CDRs.
        """
        data_to_mask = []
        cdrs_to_mask = copy.deepcopy(self.cdrs_to_mask)

        # If no specific CDRs are provided, randomly select one from the heavy or light chain
        if not cdrs_to_mask:
            ab_data = []
            if structure['heavy'] is not None:
                ab_data.append({'heavy': structure['heavy']})
            if structure['light'] is not None:
                ab_data.append({'light': structure['light']})
            data_to_mask.append(random.choice(ab_data))
            
            # Randomly choose CDR for heavy or light chain
            if 'heavy' in data_to_mask[0]:
                cdrs_to_mask = [random.choice([1, 2, 3])]
            else:
                cdrs_to_mask = [random.choice([4, 5, 6])]

        # Handle specific single CDR masking
        elif len(self.cdrs_to_mask) == 1:
            if cdrs_to_mask[0] in [1, 2, 3]:
                if structure['heavy'] is not None:
                    data_to_mask.append({'heavy': structure['heavy']})
                else:
                    data_to_mask.append({'light': structure['light']})
                    cdrs_to_mask[0] += 3  # Convert heavy CDR to light CDR
            elif cdrs_to_mask[0] in [4, 5, 6]:
                if structure['light'] is not None:
                    data_to_mask.append({'light': structure['light']})
                else:
                    data_to_mask.append({'heavy': structure['heavy']})
                    cdrs_to_mask[0] -= 3  # Convert light CDR to heavy CDR
            else:
                raise ValueError("CDR index should be in the range [1, 2, 3] for heavy or [4, 5, 6] for light chains")

        # Handle multiple CDRs to mask
        elif len(cdrs_to_mask) > 1:
            if structure['heavy'] is not None:
                data_to_mask.append({'heavy': structure['heavy']})
            if structure['light'] is not None:
                data_to_mask.append({'light': structure['light']})

        # Apply the mask to the selected chain(s)
        for data in data_to_mask:
            if 'heavy' in data:
                cdrs_to_apply = [cdr_idx for cdr_idx in cdrs_to_mask if cdr_idx in [1, 2, 3]]
                self.mask_chain(data['heavy'], cdrs_to_mask=cdrs_to_apply)
            
            if 'light' in data:
                cdrs_to_apply = [cdr_idx for cdr_idx in cdrs_to_mask if cdr_idx in [4, 5, 6]]
                self.mask_chain(data['light'], cdrs_to_mask=cdrs_to_apply)

        return structure
    
    def mask_chain(self, data, cdrs_to_mask=None):
        """
        Masks the specified CDRs in a given antibody chain.

        Parameters
        ----------
        data : dict
            Dictionary containing chain data, including CDR locations.
        cdrs_to_mask : list of int, optional
            List of CDR indices to mask (default is None, which will select random CDRs).
        """
        cdr_locations = data["cdr_locations"]
        cdr_types = cdr_locations[cdr_locations > 0].unique().tolist()
        
        if cdrs_to_mask is None:
            random.shuffle(cdr_types)
            num_cdrs_to_mask = random.randint(1, len(cdr_types))
            cdrs_to_mask = cdr_types[:num_cdrs_to_mask]
            
        for cdr in cdrs_to_mask:
            self.mask_single_cdr(data, cdr_to_mask=cdr)

    def mask_single_cdr(self, data, cdr_to_mask=3):
        """
        Masks a single CDR in the provided data.

        Parameters
        ----------
        data : dict
            Dictionary containing chain data, including CDR locations.
        cdr_to_mask : int
            Index of the CDR to mask.
        """
        cdr_locations = data["cdr_locations"]
        
        # Check if the CDR exists, otherwise randomly select one
        if cdr_to_mask is None or sum(cdr_locations == cdr_to_mask) == 0:
            cdr_types = cdr_locations[cdr_locations > 0].unique().tolist()
            cdr_to_mask = random.choice(cdr_types)

        # Create the CDR mask and modify its length if needed
        cdr_mask = (cdr_locations == cdr_to_mask)
        cdr_mask = self.change_length(cdr_mask) if self.perturb_length else cdr_mask

        # Identify anchor points
        cdr_first_idx, cdr_last_idx, _, _ = self.get_start_end_index(cdr_mask)
        left_idx = max(0, cdr_first_idx - 1)
        right_idx = min(data['aa'].size(0) - 1, cdr_last_idx + 1)
        anchor_mask = torch.zeros(data['aa'].shape, dtype=torch.bool)
        anchor_mask[left_idx] = True
        anchor_mask[right_idx] = True

        # Update generation and anchor masks
        if 'generation_mask' not in data:
            data['generation_mask'] = cdr_mask
            data['anchor_mask'] = anchor_mask
        else:
            data['generation_mask'] |= cdr_mask
            data['anchor_mask'] |= anchor_mask

    def change_length(self, mask):
        """
        Randomly shrinks or extends a mask to perturb the CDR length.

        Parameters
        ----------
        mask : torch.Tensor
            Tensor representing the mask for a CDR.

        Returns
        -------
        torch.Tensor
            Perturbed mask with adjusted length.
        """
        min_length = self.config["min_length"]
        shorten_by = self.config["shorten_by"]
        extend_by = self.config["extend_by"]
        
        first_index, last_index, cdr_length, seq_length = self.get_start_end_index(mask)
        
        shorten_by = 0 if (cdr_length - 2 * shorten_by) < min_length else shorten_by
        new_first_index = max(0, first_index - random.randint(-shorten_by, extend_by))
        new_last_index = min(last_index + random.randint(-shorten_by, extend_by), seq_length - 1)
        
        new_mask = torch.zeros_like(mask, dtype=torch.bool)
        new_mask[new_first_index:new_last_index + 1] = True
        
        return new_mask

    def get_start_end_index(self, mask):
        """
        Get the start and end indices of the masked CDR region.

        Parameters
        ----------
        mask : torch.Tensor
            Tensor representing the mask.

        Returns
        -------
        tuple
            First index, last index, CDR length, and sequence length.
        """
        seq_length = mask.size(0)
        indexes = torch.arange(0, seq_length)[mask]
        first_index = indexes[0]
        last_index = indexes[-1]
        cdr_length = mask.sum()
        
        return first_index, last_index, cdr_length, seq_length

class MaskAntibody:
    """
    A class for masking and handling antibody.
    
    Parameters
    ----------
    config : dict
        Configuration dictionary containing various settings such as contact distance.
    """
    def __init__(self, config):
        self.config = config

    def mask_ab_chain(self, data):
        """
        Masks the entire antibody chain by setting the generation mask to True for all residues.

        Parameters
        ----------
        data : dict
            Dictionary containing antibody chain information.
        """
        data['generation_mask'] = torch.ones(data['aa'].shape, dtype=torch.bool)

    def add_ab_calpha(self, structure, pos_ab_calpha, chain='heavy'):
        """
        Adds the C-alpha positions of the specified antibody chain to a list.

        Parameters
        ----------
        structure : dict
            The structure containing the antibody chains.
        pos_ab_calpha : list
            List to store the C-alpha positions.
        chain : str, optional
            The chain to process ('heavy' or 'light'), by default 'heavy'.

        Returns
        -------
        list
            Updated list of C-alpha positions.
        """
        if structure[chain] is not None:
            self.mask_ab_chain(structure[chain])
            pos_ab_calpha.append(structure[chain]['pos_heavyatom'][:, BBHeavyAtom.CA])
        return pos_ab_calpha

    def add_ag_calpha(self, structure, pos_ab_calpha):
        """
        Processes antigen C-alpha positions and computes contact regions with the antibody.

        Parameters
        ----------
        structure : dict
            The structure containing antigen information.
        pos_ab_calpha : torch.Tensor
            Tensor of C-alpha positions from the antibody.

        Returns
        -------
        dict
            Updated structure with antigen contact and anchor masks.
        """
        if structure['antigen'] is not None:
            pos_ag_calpha = structure['antigen']['pos_heavyatom'][:, BBHeavyAtom.CA]
            
            # Calculate pairwise distances between antigen and antibody C-alpha atoms
            ag_ab_dist = torch.cdist(pos_ag_calpha, pos_ab_calpha)
            
            # Find nearest antibody distances for each antigen atom
            nn_ab_dist = ag_ab_dist.min(dim=1)[0]
            contact_mask = (nn_ab_dist <= self.config["contact_distance"])
            
            # Ensure at least one contact exists; if not, pick the closest atom
            if contact_mask.sum().item() == 0:
                contact_mask[nn_ab_dist.argmin()] = True
            
            # Randomly select a contact anchor point
            anchor_idx = torch.multinomial(contact_mask.float(), num_samples=1).item()
            anchor_mask = torch.zeros(structure['antigen']['aa'].shape, dtype=torch.bool)
            anchor_mask[anchor_idx] = True
            
            # Update antigen structure with contact and anchor masks
            structure['antigen']['contact_mask'] = contact_mask
            structure['antigen']['anchor_mask'] = anchor_mask
            
        return structure

    def __call__(self, structure):
        """
        Main function to mask antibody chains and update the structure with antigen contact information.

        Parameters
        ----------
        structure : dict
            Antibody and antigen structure.

        Returns
        -------
        dict
            Updated structure with masked chains and antigen information.
        """
        pos_ab_calpha = []

        # Process heavy and light chains
        pos_ab_calpha = self.add_ab_calpha(structure, pos_ab_calpha, chain='heavy')
        pos_ab_calpha = self.add_ab_calpha(structure, pos_ab_calpha, chain='light')
        
        # Concatenate C-alpha positions from both chains
        pos_ab_calpha = torch.cat(pos_ab_calpha, dim=0)
        
        # Update structure with antigen contact information
        return self.add_ag_calpha(structure, pos_ab_calpha)


class MergeChains:
    """
    A class for merging antibody and antigen chains into a unified structure. Handles multiple chains
    (heavy, light, antigen) and combines them into a single data structure.

    Parameters
    ----------
    config : dict
        Configuration dictionary containing fragment types and other settings.
    is_evaluation : bool, optional
        Flag to indicate if evaluation mode is enabled, by default False.
    """
    def __init__(self, config, is_evaluation=False):
        self.config = config
        self.is_evaluation = is_evaluation
        self.heavy_idx = config['fragment_type']['heavy']
        self.light_kappa_idx = config['fragment_type']['light_kappa']
        self.light_lambda_idx = config['fragment_type']['light_lambda']
        self.antigen_idx = config['fragment_type']['antigen']

    def _data_attr(self, data, name):
        """
        Retrieves a specific attribute from a data dictionary. If the attribute does not exist,
        a default value is returned for mask-related attributes.

        Parameters
        ----------
        data : dict
            Dictionary containing chain or fragment data.
        name : str
            Name of the attribute to retrieve.

        Returns
        -------
        torch.Tensor or list
            The requested attribute or a default value if it doesn't exist.
        """
        if name in ['generation_mask', 'anchor_mask'] and name not in data:
            return torch.zeros(data['aa'].shape, dtype=torch.bool)
        else:
            return data[name]

    def add_fragment(self, fragment, fname='heavy', fidx=1):
        """
        Adds a fragment (e.g., heavy, light, antigen) to the structure, setting its fragment type and
        processing special cases like sequence discrepancies.

        Parameters
        ----------
        fragment : dict
            Fragment data (e.g., heavy, light, or antigen chain).
        fname : str, optional
            Name of the fragment (default is 'heavy').
        fidx : int, optional
            Index representing the fragment type (default is 1).
        """
        if fragment is not None:
            fragment['fragment_type'] = torch.full_like(fragment['aa'], fill_value=fidx)

            # Antigen-specific: initialize CDR locations
            if fname == "antigen":
                fragment['cdr_locations'] = torch.zeros_like(fragment['aa'])

            # Add fragment to the list
            self.fragment_list.append(fragment)

    def __call__(self, structure):
        """
        Merges antibody (heavy and light) and antigen chains into a unified structure, ensuring proper indexing
        and handling of fragment-specific attributes.

        Parameters
        ----------
        structure : dict
            Structure containing heavy, light, and antigen chains.

        Returns
        -------
        dict
            Merged data dictionary containing the combined structure.
        """
        if 'light_ctype' not in structure or structure['light_ctype'] is None:
            structure['light_ctype'] = 'U'  

        self.fragment_list = []

        list_props = {
            'chain_id': [],
            'icode': [],
        }

        tensor_props = {
            'resseq': [],
            'res_nb': [],
            'aa': [],
            'pos_heavyatom': [],
            'mask_heavyatom': [],
            'generation_mask': [],
            'cdr_locations': [],
            'anchor_mask': [],
            'fragment_type': [],
        }

        # Add heavy and light chains to the structure list
        if structure['heavy'] is not None:
            self.add_fragment(structure['heavy'], fname='heavy', fidx=self.heavy_idx)

        if structure['light'] is not None:
            fidx = (
                self.light_kappa_idx if structure['light_ctype'] == 'K'
                else self.light_lambda_idx if structure['light_ctype'] == 'L'
                else self.config["fragment_type"]["unknown_light"]
            )
            self.add_fragment(structure['light'], fname='light', fidx=fidx)

        # Add antigen to the structure list if present
        if structure['antigen'] is not None:
            self.add_fragment(structure['antigen'], fname='antigen', fidx=self.antigen_idx)

        # Add properties of structures into lists
        for fragment in self.fragment_list:
            
            for k in list_props.keys():
                list_props[k].append(self._data_attr(fragment, k))
            
            for k in tensor_props.keys():
                tensor_props[k].append(self._data_attr(fragment, k))

        # Merge fragment properties into unified lists/tensors
        list_props = {k: sum(v, start=[]) for k, v in list_props.items()}
        tensor_props = {k: torch.cat(v, dim=0) for k, v in tensor_props.items()}

        # Return the combined data dictionary
        data_dict = {**list_props, **tensor_props}
        data_dict['structure_type'] = structure['structure_type']

        return data_dict


class PatchAroundAnchor:
    """
    A class that selects a patch of residues around anchor points in antibody-antigen complexes. The patch 
    can include both antibody and antigen residues based on proximity to the anchor points.

    Parameters
    ----------
    config : dict
        Configuration dictionary containing fragment types and other settings.
    patch_size : int, optional
        The size of the patch to extract, by default 200.
    antigen_size : int, optional
        The maximum size of the antigen patch, by default 200.
    is_training : bool, optional
        Whether the model is in training mode, by default True.
    """
    def __init__(self, config, patch_size=200, antigen_size=200, is_training=True):
        self.config = config
        self.is_training = is_training
        self.patch_size = patch_size
        self.antigen_size = antigen_size
        self.antigen_idx = config['fragment_type']['antigen']
        
    def __call__(self, data):
        """
        Selects a patch around the anchor points and antigen contact regions.

        Parameters
        ----------
        data : dict
            A dictionary containing structure and fragment information for antibody-antigen complexes.

        Returns
        -------
        dict
            The structure data with selected patch regions and centered coordinates.
        """
        anchor_mask = data["anchor_mask"]
        generation_mask = data['generation_mask']
                
        # Get anchor points and CDR positions
        anchor_points = data['pos_heavyatom'][anchor_mask, BBHeavyAtom.CA]
        cdr_points = data['pos_heavyatom'][generation_mask, BBHeavyAtom.CA]
        
        # Determine which residues are part of the antigen or antibody
        antigen_mask = (data['fragment_type'] == self.antigen_idx)
        antibody_mask = ~antigen_mask
        
        # If no anchor point is provided, use the entire antibody fragment
        if anchor_mask.sum().item() == 0:
            antibody = self._filter_data(data, antibody_mask)
            origin = antibody['pos_heavyatom'][:, BBHeavyAtom.CA].mean(dim=0)
            antibody = self._center(antibody, origin)
            return antibody
        
        pos_calpha = data['pos_heavyatom'][:, BBHeavyAtom.CA]

        if 'A' in data["structure_type"] and not self.config["antibody_only"]:
            # Compute distances to the anchor points
            dist_to_anchors = torch.cdist(pos_calpha, anchor_points).min(dim=1)[0]
            
            # Get the closest points to the anchor for both antibody and antigen
            initial_patch_idxs = torch.topk(dist_to_anchors, k=min(self.patch_size, dist_to_anchors.size(0)), largest=False)[1]
            dist_to_anchors_antigen = dist_to_anchors.masked_fill(mask=antibody_mask, value=float('inf'))
            antigen_patch_idxs = torch.topk(dist_to_anchors_antigen, k=min(self.antigen_size, antigen_mask.sum().item()), largest=False)[1]
            
            # Create a patch mask that includes both anchor and antigen points
            patch_mask = torch.logical_or(generation_mask, anchor_mask)
            patch_mask[initial_patch_idxs] = True
            patch_mask[antigen_patch_idxs] = True
                
        else:
            # Compute distances to the anchor points (antibody only)
            dist_to_anchors = torch.cdist(pos_calpha, anchor_points).min(dim=1)[0]
            dist_to_anchors_antibody = dist_to_anchors.masked_fill(mask=~antibody_mask, value=float('inf'))
            initial_patch_idxs = torch.topk(dist_to_anchors_antibody, k=min(self.patch_size, dist_to_anchors_antibody.size(0)), largest=False)[1]
            
            # Create a patch mask for the antibody
            patch_mask = torch.logical_or(generation_mask, anchor_mask)
            patch_mask[initial_patch_idxs] = True
            
        # Extract the patch and center the coordinates
        data_patch = self._filter_data(data, patch_mask)
        data_patch = self._center(data_patch, origin=anchor_points.mean(dim=0))

        # Store patch indexes relative to the original sequence length
        patch_idxs = torch.arange(0, patch_mask.shape[0])[patch_mask]
        data_patch['patch_idxs'] = patch_idxs
        
        return data_patch

    def _center(self, data, origin):
        """
        Centers the coordinates of the structure around the origin.

        Parameters
        ----------
        data : dict
            A dictionary containing structure data.
        origin : torch.Tensor
            A tensor representing the new origin for the structure coordinates.

        Returns
        -------
        dict
            Updated structure data with centered coordinates.
        """
        data['origin'] = origin
        data['pos_heavyatom'] = data['pos_heavyatom'] - origin.view(1, 1, 3)
        data['pos_heavyatom'] *= data['mask_heavyatom'][:, :, None]
        return data

    def _filter_data(self, data, mask):
        """
        Filters data based on a given mask.

        Parameters
        ----------
        data : dict
            Structure data to be filtered.
        mask : torch.Tensor
            Boolean mask indicating which parts of the data to keep.

        Returns
        -------
        dict
            Filtered structure data.
        """
        return {k: self._filter(v, mask) for k, v in data.items()}

    def _filter(self, v, mask):
        """
        Filters a tensor or list based on a given mask.

        Parameters
        ----------
        v : torch.Tensor or list
            Data to filter.
        mask : torch.Tensor
            Boolean mask for filtering.

        Returns
        -------
        torch.Tensor or list
            Filtered data.
        """
        if isinstance(v, torch.Tensor) and v.size(0) == mask.size(0):
            return v[mask]
        elif isinstance(v, list) and len(v) == mask.size(0):
            return [v[i] for i, b in enumerate(mask) if b]
        else:
            return v


class RemoveAntigen:
    """
    Removes the antigen from the structure, useful for antibody-only tasks.
    """
    def __call__(self, structure):
        structure['antigen'] = None
        structure['antigen_seqmap'] = None
        return structure


class SelectAtom:
    """
    Selects atom coordinates from the structure based on the resolution (full or backbone).

    Parameters
    ----------
    resolution : str
        The resolution for selecting atoms ('full' or 'backbone').
    """
    def __init__(self, resolution):
        assert resolution in ('full', 'backbone')
        self.resolution = resolution

    def __call__(self, data):
        """
        Updates the structure data by selecting atom coordinates based on resolution.

        Parameters
        ----------
        data : dict
            Structure data containing atom positions and masks.

        Returns
        -------
        dict
            Updated structure data with selected atom positions and masks.
        """
        data['pos_atoms'] = data['pos_heavyatom'] if self.resolution == 'full' else data['pos_heavyatom'][:, :5]
        data['mask_atoms'] = data['mask_heavyatom'] if self.resolution == 'full' else data['mask_heavyatom'][:, :5]
        return data


class RemoveNative:
    """
    Removes native sequence or structure information based on configuration settings.

    Parameters
    ----------
    remove_structure : bool
        Whether to remove the native structure.
    remove_sequence : bool
        Whether to remove the native sequence.
    """
    def __init__(self, remove_structure, remove_sequence):
        self.remove_structure = remove_structure
        self.remove_sequence = remove_sequence

    def __call__(self, data):
        """
        Removes sequence or structure information for regions marked by the generation mask.

        Parameters
        ----------
        data : dict
            Structure data containing sequences and positions.

        Returns
        -------
        dict
            Updated structure data with removed sequences or structures.
        """
        generation_mask = data['generation_mask'].clone()

        # Remove sequence information
        if self.remove_sequence:
            data['aa'] = torch.where(
                generation_mask, 
                torch.full_like(data['aa'], fill_value=int(AALib.UNK)),
                data['aa']
            )

        # Remove structure information
        if self.remove_structure:
            data['pos_heavyatom'] = torch.where(
                generation_mask[:, None, None].expand(data['pos_heavyatom'].shape),
                torch.randn_like(data['pos_heavyatom']) * 10,
                data['pos_heavyatom']
            )

        return data

```

Contents of utils/load_data.py:
```
"""
Author: Talip Ucar
email: ucabtuc@gmail.com

Description: A library for data loaders.
"""

import lmdb
import os
import pickle
import random
from itertools import chain

import pandas as pd
import torch
from torchvision.transforms import Compose
from torch.utils.data import DataLoader, Dataset
from torch.utils.data._utils.collate import default_collate
from tqdm.auto import tqdm

from utils.utils import set_seed
from utils.protein_constants import AALib
from utils.transformations import MaskCDRs, MaskAntibody, MergeChains, PatchAroundAnchor, RemoveAntigen


class TransformComplex:
    """
    Composes a set of transformations based on the given configuration.

    Parameters
    ----------
    config : dict
        Dictionary containing transformation configuration options.
    """
    def __init__(self, config):
        super().__init__()
        transform_dict = {
            'mask_cdrs': MaskCDRs(config),
            'mask_antibody': MaskAntibody(config),
            'merge_chains': MergeChains(config),
            'patch_around_anchor': PatchAroundAnchor(config, patch_size=config["patch_size"], antigen_size=config["patch_size"]),
            'remove_antigen': RemoveAntigen,
        }
        # Compose selected transformations
        list_of_transforms = [transform_dict[d] for d in config['transform']]
        self.composed_transforms = Compose(list_of_transforms)


class PaddingCollate:
    """
    Pads sequences and collates the data for batching.

    Parameters
    ----------
    config : dict
        Configuration dictionary containing options and arguments.
    training : bool, optional
        Whether the model is in training mode, by default True.
    padding_token : int or str, optional
        Token to use for padding sequences, by default AALib.PAD.

    Attributes
    ----------
    pad_values : dict
        A dictionary specifying the padding values for different variables:
        - 'aa': Uses `padding_token` (typically AALib.PAD).
        - 'chain_id': Pads with a space (' ').
        - 'icode': Pads with a space (' ').
        - 'structure_type': Pads with a space (' ').
    """
    def __init__(self, config, training=True, padding_token=AALib.PAD):
        super().__init__()
        self.config = config
        self.training = training
        self.pad_values = {
            'aa': padding_token,
            'chain_id': ' ',
            'icode': ' ',
            'structure_type': ' ',
        }
        # Fields that do not require padding
        self.no_padding = {'origin'}

    def __call__(self, data_list):
        """
        Pads each data sample in `data_list` to the maximum length and collates them.

        Parameters
        ----------
        data_list : list
            List of data samples to be padded and collated.

        Returns
        -------
        dict
            Padded and collated batch of data.
        """
        max_length = self.config["max_length"]
        keys = self._get_common_keys(data_list)
        data_list_padded = []

        for data in data_list:
            data_padded = {}

            for k, v in data.items():
                if k in keys and v is not None:
                    value = v
                    if k not in self.no_padding:
                        # Pad sequences to the max_length if necessary
                        if (isinstance(v, torch.Tensor) and v.size(0) <= max_length) or (isinstance(v, list) and len(v) <= max_length):
                            value = self._pad_last(v, max_length, value=self._get_pad_value(k))
                        else:
                            value = v

                    data_padded.update({k: value})

            if data_padded:
                # Create padding mask using the hardcoded length reference key ('aa')
                data_padded['residue_mask'] = self._get_pad_mask(data['aa'].size(0), max_length)
                data_list_padded.append(data_padded)

        try:
            final_data = default_collate(data_list_padded)
            return final_data
        except Exception as e:
            print(e)

    @staticmethod
    def _pad_last(x, n, value=0):
        """
        Pads the sequence `x` to length `n`.

        Parameters
        ----------
        x : torch.Tensor or list
            Input sequence to pad.
        n : int
            Length to pad to.
        value : int, optional
            Value to use for padding, by default 0.

        Returns
        -------
        torch.Tensor or list
            Padded sequence.
        """
        if isinstance(x, torch.Tensor):
            assert x.size(0) <= n
            if x.size(0) == n:
                return x

            pad_size = [n - x.size(0)] + list(x.shape[1:])
            pad = torch.full(pad_size, fill_value=value).to(x)
            return torch.cat([x, pad], dim=0)

        elif isinstance(x, list):
            pad = [value] * (n - len(x))
            return x + pad
        return x

    @staticmethod
    def _get_pad_mask(l, n):
        """
        Creates a padding mask indicating which parts of the sequence are padded.

        Parameters
        ----------
        l : int
            Length of the original sequence.
        n : int
            Total padded length.

        Returns
        -------
        torch.Tensor
            Padding mask.
        """
        return torch.cat([torch.ones([l], dtype=torch.bool), torch.zeros([n - l], dtype=torch.bool)], dim=0)

    @staticmethod
    def _get_common_keys(list_of_dict):
        """
        Gets the common keys across a list of dictionaries.

        Parameters
        ----------
        list_of_dict : list
            List of dictionaries to extract common keys from.

        Returns
        -------
        set
            Set of common keys.
        """
        keys = set(list_of_dict[0].keys())
        for d in list_of_dict[1:]:
            keys = keys.intersection(d.keys())
        return keys

    def _get_pad_value(self, key):
        """
        Returns the padding value for a specific key.

        Parameters
        ----------
        key : str
            Key for which to retrieve the padding value.

        Returns
        -------
        int or str
            Padding value for the key.
        """
        return self.pad_values.get(key, 0)


class AbLoader:
    """
    Data loader for training, validation, and test datasets.

    Parameters
    ----------
    config : dict
        Configuration dictionary containing options and arguments.
    dataset_name : str
        Name of the dataset to load.
    drop_last : bool, optional
        Whether to drop the last incomplete batch, by default True.
    kwargs : dict, optional
        Additional keyword arguments, by default {}.
    """
    def __init__(self, config, dataset_name, drop_last=False, kwargs={}):
        super().__init__()
        bs = config["batch_size"]
        nw = min(8, config["num_workers"])
        self.config = config

        # Get the datasets
        train_dataset, test_dataset, validation_dataset, rabd_dataset = self.get_dataset(dataset_name)

        # Set the loader for training set
        self.train_loader = DataLoader(train_dataset, batch_size=bs, collate_fn=PaddingCollate(config, padding_token=AALib.PAD), shuffle=True, drop_last=drop_last, num_workers=nw)
        if self.config['load_val_test']:
            # Set the loader for test set
            self.test_loader = DataLoader(test_dataset, batch_size=bs, collate_fn=PaddingCollate(config, padding_token=AALib.PAD, training=False), shuffle=False, drop_last=drop_last, num_workers=nw)
            # Set the loader for validation set
            self.validation_loader = DataLoader(validation_dataset, batch_size=bs, collate_fn=PaddingCollate(config, padding_token=AALib.PAD, training=False), shuffle=False, drop_last=drop_last, num_workers=nw)
            # Set the loader for rabd set
            self.rabd_loader = rabd_dataset

    def get_dataset(self, dataset_name):
        """
        Returns the datasets for training, validation, test, and rabd sets.

        Parameters
        ----------
        dataset_name : str
            Name of the dataset to load.

        Returns
        -------
        tuple
            Training, validation, test, and rabd datasets.
        """
        reset = self.config['reset']
        is_transform = self.config['is_transform']
        # Training dataset
        train_dataset = StructureDataset(self.config, split='train', reset=reset, is_transform=is_transform)
        # Validation dataset
        validation_dataset = None if reset else StructureDataset(self.config, split="val", reset=False, is_transform=is_transform)
        # Test dataset
        test_dataset = None if reset else StructureDataset(self.config, split='test', reset=False, is_transform=False)
        # RABD dataset
        rabd_dataset = None if reset else StructureDataset(self.config, split='test', reset=False, is_transform=False)

        return train_dataset, test_dataset, validation_dataset, rabd_dataset


class StructureDataset(Dataset):
    """
    Dataset class for handling tabular data.

    Parameters
    ----------
    config : dict
        Configuration dictionary containing options and arguments.
    split : str, optional
        The data split, either 'train', 'val', or 'test', by default 'train'.
    reset : bool, optional
        Whether to reset the dataset, by default False.
    is_transform : bool, optional
        Whether to apply data transformations, by default False.
    """
    def __init__(self, config, split='train', reset=False, is_transform=False):
        super().__init__()
        transform = TransformComplex(config)

        self.config = config
        self.split = split
        self.reset = reset
        self.is_transform = is_transform
        self.transform = transform.composed_transforms
        self.db_connection = None

        # Data paths
        self.data_path = config["paths"]["data"]
        self.processed_dir = config["data_pdb_dir"]
        self.map_size = 64 * 1024**3  # Maximum size of the DB

        # Load clusters, entries, and split the data
        self._load_clusters()
        self._load_entries()
        self._load_split()

    def __len__(self):
        """
        Returns the number of samples in the dataset.

        Returns
        -------
        int
            Number of samples.
        """
        return len(self.split_ids)

    def __getitem__(self, idx):
        """
        Returns the data for a given index.

        Parameters
        ----------
        idx : int
            Index of the data to retrieve.

        Returns
        -------
        dict
            Data for the given index.
        """
        structure_id = self.split_ids[idx]
        return self._get_data_from_idx(structure_id)

    def _get_data_from_idx(self, structure_id):
        """
        Fetches and transforms data for a given structure ID.

        Parameters
        ----------
        structure_id : str
            The structure ID to fetch data for.

        Returns
        -------
        dict
            Transformed or raw data for the structure.
        """
        data = self._get_structure(structure_id)
        return self.transform(data) if self.is_transform else data

    @property
    def structure_data_path(self):
        """Returns the path to the structure LMDB database."""
        return os.path.join(self.processed_dir, 'structures.lmdb')

    def _get_structure(self, db_id):
        """
        Retrieves the structure data from LMDB.

        Parameters
        ----------
        db_id : str
            The database ID for the structure.

        Returns
        -------
        dict
            The structure data.
        """
        # Initialize LMDB connection if not done yet
        if self.db_connection is None:
            self.db_connection = lmdb.open(self.structure_data_path, 
                                           map_size=self.map_size, 
                                           create=False,
                                           subdir=False,
                                           readonly=True,
                                           lock=False,
                                           readahead=False,
                                           meminit=False)

        # Load structure from LMDB
        with self.db_connection.begin() as txn:
            return pickle.loads(txn.get(db_id.encode()))

    def _load_entries(self):
        """
        Loads the entries of the dataset from a pickle file.
        """
        entries_path = os.path.join(self.processed_dir, 'entries_list.pkl')
        with open(entries_path, 'rb') as f:
            self.all_entries = pickle.load(f)

    def _load_clusters(self):
        """
        Loads the cluster information from a TSV file.
        """
        cluster_path = os.path.join(self.processed_dir, "cluster_results.tsv")
        clusters, id_to_cluster = {}, {}

        with open(cluster_path, 'r') as f:
            for line in f.readlines():
                cluster_name, data_id = line.split()
                clusters.setdefault(cluster_name, []).append(data_id)
                id_to_cluster[data_id] = cluster_name

        self.clusters = clusters
        self.id_to_cluster = id_to_cluster

    def _load_split(self):
        """
        Loads the data split (train, val, or test) based on the configuration.
        """
        # Set the random seed
        set_seed(self.config)

        # Get test IDs
        test_ids = [entry_dict['id'] for entry_dict in self.all_entries if entry_dict is not None and entry_dict['entry']['ag_name'] in self.config['test_set']]
        print(f"Number of initial test IDs: {len(test_ids)}")

        # Get RABD PDB IDs
        rabd_df = pd.read_csv(f"{self.config['paths']['data']}/rabd/rabd.csv", header=None, usecols=[0], names=["ids"])
        rabd_ids = rabd_df["ids"].tolist()

        # Include RABD IDs in the test set
        test_ids += [entry_dict['id'] for entry_dict in self.all_entries if entry_dict is not None and entry_dict['id'][:4] in rabd_ids]
        test_ids_prefix = [tid[:4] for tid in test_ids]
        print(f"Number of final test IDs: {len(test_ids)}")

        # Find clusters corresponding to the test IDs
        test_clusters = list(set([self.id_to_cluster[test_id] for test_id in test_ids]))

        # Load SAbDab PDB IDs
        sabdab_df = pd.read_csv(os.path.join(self.data_path, 'sabdab_summary_all.tsv'), sep='\t')
        sabdab_ids = sabdab_df["pdb"].tolist()

        # Exclude RABD IDs from SAbDab
        sabdab_ids = [sid for sid in sabdab_ids if sid not in test_ids_prefix]

        # Get the remaining SAbDab IDs for training
        train_sabdab_ids = [entry_dict['id'] for entry_dict in self.all_entries if entry_dict is not None and entry_dict['id'][:4] in sabdab_ids]

        # Group the training SAbDab IDs into clusters
        train_clusters_sabdab = list(set([self.id_to_cluster[sid] for sid in train_sabdab_ids if sid in self.id_to_cluster]))

        # Select validation clusters
        num_val_cluster_keys = self.config["validation_size"]
        random.shuffle(train_clusters_sabdab)
        val_clusters = train_clusters_sabdab[:num_val_cluster_keys]
        train_clusters_sabdab = train_clusters_sabdab[num_val_cluster_keys:]

        # Shuffle training clusters again
        random.shuffle(train_clusters_sabdab)

        print("test and val clusters ==================")
        print(f"Number of clusters in test: {len(test_clusters)}")
        print(f"Number of clusters in validation: {len(val_clusters)}")
        print(f"Number of clusters in training SAbDab: {len(train_clusters_sabdab)}")

        # Assign structure IDs based on the selected split
        if self.split == "test":
            self.split_ids = list(chain.from_iterable(self.clusters[c_id] for c_id in test_clusters if c_id in self.clusters))
            print(f"Number of structures in the test split: {len(self.split_ids)}")
        elif self.split == "val":
            self.split_ids = list(chain.from_iterable(self.clusters[c_id] for c_id in val_clusters if c_id in self.clusters))
            print(f"Number of structures in the validation split: {len(self.split_ids)}")
        elif self.split == "rabd":
            self.split_ids = rabd_ids
        else:
            self.split_ids = list(chain.from_iterable(self.clusters[c_id] for c_id in train_clusters_sabdab if c_id in self.clusters))
            print(f"Number of structures from SAbDab in the train split: {len(self.split_ids)}")

```

Contents of utils/geometry.py:
```
"""
Author: Talip Ucar
email: ucabtuc@gmail.com

Description: Library of utils for geometry
"""

import numpy as np
import torch
import torch.nn.functional as F
from utils.protein_constants import CDR, AALib, restype_to_heavyatom_names, BBHeavyAtom, backbone_atom_coordinates_tensor, bb_oxygen_coordinate_tensor


def compose_rotation_and_translation(R1, t1, R2, t2):
    """
    Compose two rotations and translations.

    Parameters
    ----------
    R1 : torch.Tensor
        Frame basis, shape (N, L, 3, 3).
    t1 : torch.Tensor
        Translation, shape (N, L, 3).
    R2 : torch.Tensor
        Rotation to be applied, shape (N, L, 3, 3).
    t2 : torch.Tensor
        Translation to be applied, shape (N, L, 3).

    Returns
    -------
    R_new : torch.Tensor
        Composed rotation, shape (N, L, 3, 3).
    t_new : torch.Tensor
        Composed translation, shape (N, L, 3).
    """
    R_new = torch.matmul(R1, R2)
    t_new = torch.matmul(R1, t2.unsqueeze(-1)).squeeze(-1) + t1
    return R_new, t_new


def compose_rotation_translation(Ts):
    """
    Iteratively compose a list of rotations and translations.

    Parameters
    ----------
    Ts : list of tuples
        List of (R, t) pairs where R is the rotation matrix and t is the translation vector.

    Returns
    -------
    tuple
        Composed (R, t) pair.
    """
    while len(Ts) >= 2:
        R1, t1 = Ts[-2]
        R2, t2 = Ts[-1]
        T_next = compose_rotation_and_translation(R1, t1, R2, t2)
        Ts = Ts[:-2] + [T_next]
    return Ts[0]


def normalize_vector(v, dim, eps=1e-6):
    """
    Normalize a vector along the specified dimension.

    Parameters
    ----------
    v : torch.Tensor
        Input vector to be normalized.
    dim : int
        Dimension along which to normalize.
    eps : float, optional
        Small epsilon value to avoid division by zero (default is 1e-6).

    Returns
    -------
    torch.Tensor
        Normalized vector.
    """
    return v / (torch.linalg.norm(v, ord=2, dim=dim, keepdim=True) + eps)


def project_v2v(v, e, dim):
    """
    Project vector `v` onto vector `e`.

    Parameters
    ----------
    v : torch.Tensor
        Input vector, shape (N, L, 3).
    e : torch.Tensor
        Vector onto which `v` will be projected, shape (N, L, 3).
    dim : int
        Dimension along which to compute the projection.

    Returns
    -------
    torch.Tensor
        Projected vector, shape (N, L, 3).
    """
    return (e * v).sum(dim=dim, keepdim=True) * e


def get_3d_basis(center, p1, p2):
    """
    Compute a 3D orthogonal basis given three points.

    Parameters
    ----------
    center : torch.Tensor
        Central point, usually the position of C_alpha, shape (N, L, 3).
    p1 : torch.Tensor
        First point, usually the position of C, shape (N, L, 3).
    p2 : torch.Tensor
        Second point, usually the position of N, shape (N, L, 3).

    Returns
    -------
    torch.Tensor
        Orthogonal basis matrix, shape (N, L, 3, 3).
    """
    v1 = p1 - center
    e1 = normalize_vector(v1, dim=-1)

    v2 = p2 - center
    u2 = v2 - project_v2v(v2, e1, dim=-1)
    e2 = normalize_vector(u2, dim=-1)

    e3 = torch.cross(e1, e2, dim=-1)

    return torch.cat([e1.unsqueeze(-1), e2.unsqueeze(-1), e3.unsqueeze(-1)], dim=-1)


def local2global(R, t, p):
    """
    Convert local coordinates to global coordinates.

    Parameters
    ----------
    R : torch.Tensor
        Rotation matrix, shape (N, L, 3, 3).
    t : torch.Tensor
        Translation vector, shape (N, L, 3).
    p : torch.Tensor
        Local coordinates, shape (N, L, ..., 3).

    Returns
    -------
    torch.Tensor
        Global coordinates, shape (N, L, ..., 3).
    """
    assert p.size(-1) == 3
    p_size = p.size()
    N, L = p_size[0], p_size[1]

    p = p.view(N, L, -1, 3).transpose(-1, -2)
    q = torch.matmul(R, p) + t.unsqueeze(-1)
    q = q.transpose(-1, -2).reshape(p_size)
    return q


def global2local(R, t, q):
    """
    Convert global coordinates to local coordinates.

    Parameters
    ----------
    R : torch.Tensor
        Rotation matrix, shape (N, L, 3, 3).
    t : torch.Tensor
        Translation vector, shape (N, L, 3).
    q : torch.Tensor
        Global coordinates, shape (N, L, ..., 3).

    Returns
    -------
    torch.Tensor
        Local coordinates, shape (N, L, ..., 3).
    """
    assert q.size(-1) == 3
    q_size = q.size()
    N, L = q_size[0], q_size[1]

    q = q.view(N, L, -1, 3).transpose(-1, -2)
    p = torch.matmul(R.transpose(-1, -2), (q - t.unsqueeze(-1)))
    p = p.transpose(-1, -2).reshape(q_size)
    return p


def apply_rotation_to_vector(R, p):
    """
    Apply a rotation matrix to a vector without translation.

    Parameters
    ----------
    R : torch.Tensor
        Rotation matrix, shape (N, L, 3, 3).
    p : torch.Tensor
        Input vector, shape (N, L, ..., 3).

    Returns
    -------
    torch.Tensor
        Rotated vector, shape (N, L, ..., 3).
    """
    return local2global(R, torch.zeros_like(p), p)


# Copyright (c) Meta Platforms, Inc. and affiliates.
# All rights reserved.
#
# This source code is licensed under the BSD-style license found in the
# LICENSE file in the root directory of this source tree.
def quaternion_to_rotation_matrix(quaternions):
    """
    Convert quaternions to rotation matrices.

    Parameters
    ----------
    quaternions : torch.Tensor
        Quaternions with the real part first, shape (..., 4).

    Returns
    -------
    torch.Tensor
        Rotation matrices, shape (..., 3, 3).
    """
    quaternions = F.normalize(quaternions, dim=-1)
    r, i, j, k = torch.unbind(quaternions, -1)
    two_s = 2.0 / (quaternions * quaternions).sum(-1)

    o = torch.stack(
        (
            1 - two_s * (j * j + k * k),
            two_s * (i * j - k * r),
            two_s * (i * k + j * r),
            two_s * (i * j + k * r),
            1 - two_s * (i * i + k * k),
            two_s * (j * k - i * r),
            two_s * (i * k - j * r),
            two_s * (j * k + i * r),
            1 - two_s * (i * i + j * j),
        ),
        -1,
    )
    return o.reshape(quaternions.shape[:-1] + (3, 3))


# Copyright (c) Meta Platforms, Inc. and affiliates.
# All rights reserved.
#
# This source code is licensed under the BSD-style license found in the
# LICENSE file in the root directory of this source tree.
def quaternion_1ijk_to_rotation_matrix(q):
    """
    Convert quaternion (1 + ai + bj + ck) to rotation matrix.

    Parameters
    ----------
    q : torch.Tensor
        Quaternion components (b, c, d), shape (..., 3).

    Returns
    -------
    torch.Tensor
        Rotation matrix, shape (..., 3, 3).
    """
    b, c, d = torch.unbind(q, dim=-1)
    s = torch.sqrt(1 + b ** 2 + c ** 2 + d ** 2)
    a, b, c, d = 1 / s, b / s, c / s, d / s

    o = torch.stack(
        (
            a**2 + b**2 - c**2 - d**2, 2 * b * c - 2 * a * d, 2 * b * d + 2 * a * c,
            2 * b * c + 2 * a * d, a**2 - b**2 + c**2 - d**2, 2 * c * d - 2 * a * b,
            2 * b * d - 2 * a * c, 2 * c * d + 2 * a * b, a**2 - b**2 - c**2 + d**2,
        ),
        -1,
    )
    return o.reshape(q.shape[:-1] + (3, 3))


def get_consecutive_flag(chain_nb, res_nb, mask):
    """
    Compute flag indicating whether consecutive residues are connected.

    Parameters
    ----------
    chain_nb : torch.Tensor
        Chain indices, shape (N, L).
    res_nb : torch.Tensor
        Residue numbers, shape (N, L).
    mask : torch.Tensor
        Mask indicating valid residues, shape (N, L).

    Returns
    -------
    torch.Tensor
        Boolean tensor indicating connected residues, shape (N, L-1).
    """
    d_res_nb = (res_nb[:, 1:] - res_nb[:, :-1]).abs()
    same_chain = (chain_nb[:, 1:] == chain_nb[:, :-1])
    consec = torch.logical_and(d_res_nb == 1, same_chain)
    consec = torch.logical_and(consec, mask[:, :-1])

    return consec


def get_terminus_flag(chain_nb, res_nb, mask):
    """
    Identify N-terminus and C-terminus flags for residues.

    Parameters
    ----------
    chain_nb : torch.Tensor
        Chain indices, shape (N, L).
    res_nb : torch.Tensor
        Residue numbers, shape (N, L).
    mask : torch.Tensor
        Mask indicating valid residues, shape (N, L).

    Returns
    -------
    tuple of torch.Tensor
        N-terminus and C-terminus flags, both of shape (N, L).
    """
    consec = get_consecutive_flag(chain_nb, res_nb, mask)
    N_term_flag = F.pad(torch.logical_not(consec), pad=(1, 0), value=1)
    C_term_flag = F.pad(torch.logical_not(consec), pad=(0, 1), value=1)
    return N_term_flag, C_term_flag


def dihedral_from_four_points(p0, p1, p2, p3):
    """
    Compute dihedral angle given four points.

    Parameters
    ----------
    p0, p1, p2, p3 : torch.Tensor
        Coordinates of four points, shape (*, 3).

    Returns
    -------
    torch.Tensor
        Dihedral angles in radians, shape (*,).
    """
    v0 = p2 - p1
    v1 = p0 - p1
    v2 = p3 - p2

    u1 = torch.cross(v0, v1, dim=-1)
    n1 = u1 / torch.linalg.norm(u1, dim=-1, keepdim=True)

    u2 = torch.cross(v0, v2, dim=-1)
    n2 = u2 / torch.linalg.norm(u2, dim=-1, keepdim=True)

    sgn = torch.sign((torch.cross(v1, v2, dim=-1) * v0).sum(-1))
    dihed = sgn * torch.acos((n1 * n2).sum(-1).clamp(min=-0.999999, max=0.999999))
    dihed = torch.nan_to_num(dihed)
    return dihed


def get_bb_dihedral_angles(pos_atoms, chain_nb, res_nb, mask_residue):
    """
    Compute backbone dihedral angles (Omega, Phi, Psi) from atomic positions.

    Parameters
    ----------
    pos_atoms : torch.Tensor
        Atomic positions, shape (N, L, A, 3).
    chain_nb : torch.Tensor
        Chain indices, shape (N, L).
    res_nb : torch.Tensor
        Residue numbers, shape (N, L).
    mask_residue : torch.Tensor
        Mask for valid residues, shape (N, L).

    Returns
    -------
    tuple of torch.Tensor
        Backbone dihedral angles and their masks, both of shape (N, L, 3).
    """
    pos_N = pos_atoms[:, :, BBHeavyAtom.N]
    pos_CA = pos_atoms[:, :, BBHeavyAtom.CA]
    pos_C = pos_atoms[:, :, BBHeavyAtom.C]

    N_term_mask, C_term_mask = get_terminus_flag(chain_nb, res_nb, mask_residue)

    omega_mask = torch.logical_not(N_term_mask)
    phi_mask = torch.logical_not(N_term_mask)
    psi_mask = torch.logical_not(C_term_mask)

    omega = F.pad(dihedral_from_four_points(pos_CA[:, :-1], pos_C[:, :-1], pos_N[:, 1:], pos_CA[:, 1:]), pad=(1, 0), value=0)
    phi = F.pad(dihedral_from_four_points(pos_C[:, :-1], pos_N[:, 1:], pos_CA[:, 1:], pos_C[:, 1:]), pad=(1, 0), value=0)
    psi = F.pad(dihedral_from_four_points(pos_N[:, :-1], pos_CA[:, :-1], pos_C[:, :-1], pos_N[:, 1:]), pad=(0, 1), value=0)

    mask_bb_dihed = torch.stack([omega_mask, phi_mask, psi_mask], dim=-1)
    bb_dihed = torch.stack([omega, phi, psi], dim=-1) * mask_bb_dihed

    return bb_dihed, mask_bb_dihed


def pairwise_dihedrals(pos_atoms):
    """
    Compute inter-residue Phi and Psi angles.

    Parameters
    ----------
    pos_atoms : torch.Tensor
        Atomic positions, shape (N, L, A, 3).

    Returns
    -------
    torch.Tensor
        Inter-residue Phi and Psi angles, shape (N, L, L, 2).
    """
    N, L = pos_atoms.size()[:2]
    pos_N = pos_atoms[:, :, BBHeavyAtom.N]
    pos_CA = pos_atoms[:, :, BBHeavyAtom.CA]
    pos_C = pos_atoms[:, :, BBHeavyAtom.C]

    ir_phi = dihedral_from_four_points(
        pos_C[:, :, None, :].expand(N, L, L, 3),
        pos_N[:, None, :, :].expand(N, L, L, 3),
        pos_CA[:, None, :, :].expand(N, L, L, 3),
        pos_C[:, None, :, :].expand(N, L, L, 3)
    )

    ir_psi = dihedral_from_four_points(
        pos_N[:, :, None, :].expand(N, L, L, 3),
        pos_CA[:, :, None, :].expand(N, L, L, 3),
        pos_C[:, :, None, :].expand(N, L, L, 3),
        pos_N[:, None, :, :].expand(N, L, L, 3)
    )

    ir_dihed = torch.stack([ir_phi, ir_psi], dim=-1)

    return ir_dihed


def log_rotation(R):
    """
    Compute the logarithm of a rotation matrix.

    Parameters
    ----------
    R : torch.Tensor
        Rotation matrix, shape (..., 3, 3).

    Returns
    -------
    torch.Tensor
        Logarithm of the rotation matrix, shape (..., 3, 3).
    """
    trace = R[..., range(3), range(3)].sum(-1)
    min_cos = -0.999 if torch.is_grad_enabled() else -1.0
    cos_theta = ((trace - 1) / 2).clamp_min(min=min_cos)
    sin_theta = torch.sqrt(1 - cos_theta ** 2)
    theta = torch.acos(cos_theta)
    coef = ((theta + 1e-8) / (2 * sin_theta + 2e-8))[..., None, None]
    logR = coef * (R - R.transpose(-1, -2))
    return logR


def skewsym_to_so3vec(S):
    """
    Convert a skew-symmetric matrix to an SO(3) vector.

    Parameters
    ----------
    S : torch.Tensor
        Skew-symmetric matrix, shape (..., 3, 3).

    Returns
    -------
    torch.Tensor
        SO(3) vector, shape (..., 3).
    """
    x = S[..., 1, 2]
    y = S[..., 2, 0]
    z = S[..., 0, 1]
    w = torch.stack([x, y, z], dim=-1)
    return w


def exp_skewsym(S):
    """
    Compute the matrix exponential of a skew-symmetric matrix.

    Parameters
    ----------
    S : torch.Tensor
        Skew-symmetric matrix, shape (..., 3, 3).

    Returns
    -------
    torch.Tensor
        Exponential of the skew-symmetric matrix, shape (..., 3, 3).
    """
    x = torch.linalg.norm(skewsym_to_so3vec(S), dim=-1)
    I = torch.eye(3).to(S).view([1 for _ in range(S.dim() - 2)] + [3, 3])
    sinx, cosx = torch.sin(x), torch.cos(x)
    b = (sinx + 1e-8) / (x + 1e-8)
    c = (1 - cosx + 1e-8) / (x ** 2 + 2e-8)
    S2 = S @ S
    return I + b[..., None, None] * S + c[..., None, None] * S2


def so3vec_to_skewsym(w):
    """
    Convert an SO(3) vector to a skew-symmetric matrix.

    Parameters
    ----------
    w : torch.Tensor
        SO(3) vector, shape (..., 3).

    Returns
    -------
    torch.Tensor
        Skew-symmetric matrix, shape (..., 3, 3).
    """
    x, y, z = torch.unbind(w, dim=-1)
    o = torch.zeros_like(x)
    S = torch.stack([o, z, -y, -z, o, x, y, -x, o], dim=-1).reshape(w.shape[:-1] + (3, 3))
    return S


def so3_vec2rotation(w):
    """
    Convert an SO(3) vector to a rotation matrix.

    Parameters
    ----------
    w : torch.Tensor
        SO(3) vector, shape (..., 3).

    Returns
    -------
    torch.Tensor
        Rotation matrix, shape (..., 3, 3).
    """
    return exp_skewsym(so3vec_to_skewsym(w))


def construct_3d_basis(center, p1, p2):
    """
    Construct an orthogonal 3D basis given three points.

    Parameters
    ----------
    center : torch.Tensor
        The center point (C_alpha), shape (N, L, 3).
    p1 : torch.Tensor
        First point (C), shape (N, L, 3).
    p2 : torch.Tensor
        Second point (N), shape (N, L, 3).

    Returns
    -------
    torch.Tensor
        Orthogonal 3D basis matrix, shape (N, L, 3, 3).
    """
    v1 = p1 - center
    e1 = normalize_vector(v1, dim=-1)

    v2 = p2 - center
    u2 = v2 - project_v2v(v2, e1, dim=-1)
    e2 = normalize_vector(u2, dim=-1)

    e3 = torch.cross(e1, e2, dim=-1)

    return torch.cat([e1.unsqueeze(-1), e2.unsqueeze(-1), e3.unsqueeze(-1)], dim=-1)


def rotation_to_so3vec(R):
    """
    Convert a rotation matrix to an SO(3) vector.

    Parameters
    ----------
    R : torch.Tensor
        Rotation matrix, shape (..., 3, 3).

    Returns
    -------
    torch.Tensor
        SO(3) vector, shape (..., 3).
    """
    logR = log_rotation(R)
    return skewsym_to_so3vec(logR)


def random_uniform_so3(size, device='cpu'):
    """
    Generate random SO(3) vectors uniformly from a distribution.

    Parameters
    ----------
    size : list of int
        Size of the output.
    device : str
        Device to create the tensor on (default is 'cpu').

    Returns
    -------
    torch.Tensor
        Random SO(3) vectors, shape (..., 3).
    """
    q = F.normalize(torch.randn(list(size) + [4], device=device), dim=-1)
    R = quaternion_to_rotation_matrix(q)
    return rotation_to_so3vec(R)


def randn_so3(std_idx, angular_distribution, device='cpu'):
    """
    Generate random SO(3) vectors from a normal distribution with specified angular distribution.

    Parameters
    ----------
    std_idx : torch.Tensor
        Indices for the standard deviation, shape (...).
    angular_distribution : ApproxAngularDistribution
        Angular distribution object.
    device : str
        Device to create the tensor on.

    Returns
    -------
    torch.Tensor
        Random SO(3) vectors, shape (..., 3).
    """
    size = std_idx.size()
    u = F.normalize(torch.randn(list(size) + [3], device=device), dim=-1)
    theta = angular_distribution.sample(std_idx)
    return u * theta[..., None]


def reconstruct_backbone(rot, pos, seq, chain_nb, res_nb, mask):
    """
    Reconstruct backbone atoms (N, CA, C, O) from rotations and translations.

    Parameters
    ----------
    rot : torch.Tensor
        Rotation matrices, shape (N, L, 3, 3).
    pos : torch.Tensor
        Positions of backbone atoms, shape (N, L, 3).
    seq : torch.Tensor
        Amino acid sequence indices, shape (N, L).
    chain_nb : torch.Tensor
        Chain numbers, shape (N, L).
    res_nb : torch.Tensor
        Residue numbers, shape (N, L).
    mask : torch.Tensor
        Mask indicating valid residues, shape (N, L).

    Returns
    -------
    torch.Tensor
        Reconstructed backbone atoms, shape (N, L, 4, 3).
    """
    N, L = seq.size()
    bb_coords = backbone_atom_coordinates_tensor.clone().to(pos)
    oxygen_coords = bb_oxygen_coordinate_tensor.clone().to(pos)
    seq = seq.clamp(min=0, max=20)

    bb_coords = bb_coords[seq.flatten()].reshape(N, L, -1, 3)
    oxygen_coords = oxygen_coords[seq.flatten()].reshape(N, L, -1)

    bb_pos = local2global(rot, pos, bb_coords)
    bb_dihedral, _ = get_bb_dihedral_angles(bb_pos, chain_nb, res_nb, mask)

    psi = bb_dihedral[..., 2]
    psi_sin = torch.sin(psi).reshape(N, L, 1, 1)
    psi_cos = torch.cos(psi).reshape(N, L, 1, 1)
    zeros = torch.zeros_like(psi_sin)
    ones = torch.ones_like(psi_sin)

    row1 = torch.cat([ones, zeros, zeros], dim=-1)
    row2 = torch.cat([zeros, psi_cos, -psi_sin], dim=-1)
    row3 = torch.cat([zeros, psi_sin, psi_cos], dim=-1)

    rot_psi = torch.cat([row1, row2, row3], dim=-2)
    rot_psi, pos_psi = compose_rotation_translation([
        (rot, pos),
        (rot_psi, torch.zeros_like(pos)),
    ])

    oxy_pos = local2global(rot_psi, pos_psi, oxygen_coords.reshape(N, L, 1, 3))
    bb_pos = torch.cat([bb_pos, oxy_pos], dim=2)

    return bb_pos


def reconstruct_backbone_partially(pos_atoms, rot_new, pos_new, seq_new, chain_nb, res_nb, mask_atoms, generation_mask):
    """
    Partially reconstruct backbone atoms for generated regions.

    Parameters
    ----------
    pos_atoms : torch.Tensor
        Positions of atoms, shape (N, L, A, 3).
    rot_new : torch.Tensor
        New rotation matrices, shape (N, L, 3, 3).
    pos_new : torch.Tensor
        New positions, shape (N, L, 3).
    seq_new : torch.Tensor
        New amino acid sequence, shape (N, L).
    chain_nb : torch.Tensor
        Chain numbers, shape (N, L).
    res_nb : torch.Tensor
        Residue numbers, shape (N, L).
    mask_atoms : torch.Tensor
        Mask for atoms, shape (N, L, A).
    generation_mask : torch.Tensor
        Mask indicating generated regions, shape (N, L).

    Returns
    -------
    tuple of torch.Tensor
        Updated positions of atoms, shape (N, L, A, 3), and updated mask, shape (N, L, A).
    """
    N, L, A = mask_atoms.size()
    mask_res = mask_atoms[:, :, BBHeavyAtom.CA]

    pos_recons = reconstruct_backbone(rot_new, pos_new, seq_new, chain_nb, res_nb, mask_res)
    pos_recons = F.pad(pos_recons, pad=(0, 0, 0, A - 4), value=0)
    pos_new = torch.where(generation_mask[:, :, None, None].expand_as(pos_atoms), pos_recons, pos_atoms)

    mask_bb_atoms = torch.zeros_like(mask_atoms)
    mask_bb_atoms[:, :, :4] = True
    mask_new = torch.where(generation_mask[:, :, None].expand_as(mask_atoms), mask_bb_atoms, mask_atoms)

    return pos_new, mask_new

```

Contents of utils/protein_constants.py:
```
"""
Author: Talip Ucar
email: ucabtuc@gmail.com

Description: Constants used throughout the library.
"""


import torch
import enum


class CDR(enum.IntEnum):
    H1 = 1
    H2 = 2
    H3 = 3
    L1 = 4
    L2 = 5
    L3 = 6


class UnionCDRRange:

    """
    Defines the CDR regions as the union of Kabat, Chothia, IMGT etc. schemes.
    """
    # Union ranges for Heavy Chain CDRs
    H1 = (26, 38)   # Extended to cover residues from all schemes
    H2 = (50, 65)   # Extended to cover residues from all schemes
    H3 = (93, 102)  # Covers CDR-H3 across all schemes

    # Union ranges for Light Chain CDRs
    L1 = (24, 38)   # Extended to cover residues from all schemes
    L2 = (46, 56)   # Extended to cover residues from all schemes
    L3 = (89, 97)   # Covers CDR-L3 across all schemes


    @classmethod
    def to_cdr(cls, chain_type, resseq):
        assert chain_type in ('H', 'L')
        if chain_type == 'H':
            if cls.H1[0] <= resseq <= cls.H1[1]:
                return CDR.H1
            elif cls.H2[0] <= resseq <= cls.H2[1]:
                return CDR.H2
            elif cls.H3[0] <= resseq <= cls.H3[1]:
                return CDR.H3
        elif chain_type == 'L':
            if cls.L1[0] <= resseq <= cls.L1[1]:
                return CDR.L1
            elif cls.L2[0] <= resseq <= cls.L2[1]:
                return CDR.L2
            elif cls.L3[0] <= resseq <= cls.L3[1]:
                return CDR.L3


# Residue identities
"""
This is part of the OpenMM molecular simulation toolkit originating from
Simbios, the NIH National Center for Physics-Based Simulation of
Biological Structures at Stanford, funded under the NIH Roadmap for
Medical Research, grant U54 GM072970. See https://simtk.org.

Portions copyright (c) 2013 Stanford University and the Authors.
Authors: Peter Eastman
Contributors:

Permission is hereby granted, free of charge, to any person obtaining a
copy of this software and associated documentation files (the "Software"),
to deal in the Software without restriction, including without limitation
the rights to use, copy, modify, merge, publish, distribute, sublicense,
and/or sell copies of the Software, and to permit persons to whom the
Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
THE AUTHORS, CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
USE OR OTHER DEALINGS IN THE SOFTWARE.
"""
non_standard_residue_substitutions = {
    '2AS':'ASP', '3AH':'HIS', '5HP':'GLU', 'ACL':'ARG', 'AGM':'ARG', 'AIB':'ALA', 'ALM':'ALA', 'ALO':'THR', 'ALY':'LYS', 'ARM':'ARG',
    'ASA':'ASP', 'ASB':'ASP', 'ASK':'ASP', 'ASL':'ASP', 'ASQ':'ASP', 'AYA':'ALA', 'BCS':'CYS', 'BHD':'ASP', 'BMT':'THR', 'BNN':'ALA',
    'BUC':'CYS', 'BUG':'LEU', 'C5C':'CYS', 'C6C':'CYS', 'CAS':'CYS', 'CCS':'CYS', 'CEA':'CYS', 'CGU':'GLU', 'CHG':'ALA', 'CLE':'LEU', 'CME':'CYS',
    'CSD':'ALA', 'CSO':'CYS', 'CSP':'CYS', 'CSS':'CYS', 'CSW':'CYS', 'CSX':'CYS', 'CXM':'MET', 'CY1':'CYS', 'CY3':'CYS', 'CYG':'CYS',
    'CYM':'CYS', 'CYQ':'CYS', 'DAH':'PHE', 'DAL':'ALA', 'DAR':'ARG', 'DAS':'ASP', 'DCY':'CYS', 'DGL':'GLU', 'DGN':'GLN', 'DHA':'ALA',
    'DHI':'HIS', 'DIL':'ILE', 'DIV':'VAL', 'DLE':'LEU', 'DLY':'LYS', 'DNP':'ALA', 'DPN':'PHE', 'DPR':'PRO', 'DSN':'SER', 'DSP':'ASP',
    'DTH':'THR', 'DTR':'TRP', 'DTY':'TYR', 'DVA':'VAL', 'EFC':'CYS', 'FLA':'ALA', 'FME':'MET', 'GGL':'GLU', 'GL3':'GLY', 'GLZ':'GLY',
    'GMA':'GLU', 'GSC':'GLY', 'HAC':'ALA', 'HAR':'ARG', 'HIC':'HIS', 'HIP':'HIS', 'HMR':'ARG', 'HPQ':'PHE', 'HTR':'TRP', 'HYP':'PRO',
    'IAS':'ASP', 'IIL':'ILE', 'IYR':'TYR', 'KCX':'LYS', 'LLP':'LYS', 'LLY':'LYS', 'LTR':'TRP', 'LYM':'LYS', 'LYZ':'LYS', 'MAA':'ALA', 'MEN':'ASN',
    'MHS':'HIS', 'MIS':'SER', 'MLE':'LEU', 'MPQ':'GLY', 'MSA':'GLY', 'MSE':'MET', 'MVA':'VAL', 'NEM':'HIS', 'NEP':'HIS', 'NLE':'LEU',
    'NLN':'LEU', 'NLP':'LEU', 'NMC':'GLY', 'OAS':'SER', 'OCS':'CYS', 'OMT':'MET', 'PAQ':'TYR', 'PCA':'GLU', 'PEC':'CYS', 'PHI':'PHE',
    'PHL':'PHE', 'PR3':'CYS', 'PRR':'ALA', 'PTR':'TYR', 'PYX':'CYS', 'SAC':'SER', 'SAR':'GLY', 'SCH':'CYS', 'SCS':'CYS', 'SCY':'CYS',
    'SEL':'SER', 'SEP':'SER', 'SET':'SER', 'SHC':'CYS', 'SHR':'LYS', 'SMC':'CYS', 'SOC':'CYS', 'STY':'TYR', 'SVA':'SER', 'TIH':'ALA',
    'TPL':'TRP', 'TPO':'THR', 'TPQ':'ALA', 'TRG':'LYS', 'TRO':'TRP', 'TYB':'TYR', 'TYI':'TYR', 'TYQ':'TYR', 'TYS':'TYR', 'TYY':'TYR'
}


ressymb_to_resindex = {
    'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4,
    'G': 5, 'H': 6, 'I': 7, 'K': 8, 'L': 9,
    'M': 10, 'N': 11, 'P': 12, 'Q': 13, 'R': 14,
    'S': 15, 'T': 16, 'V': 17, 'W': 18, 'Y': 19,
    'X': 20, '-': 21, '|': 22, '*': 23
}

resindex_to_ressymb = {v:k for k, v in ressymb_to_resindex.items()}

class AALib(enum.IntEnum):
    ALA = 0; CYS = 1; ASP = 2; GLU = 3; PHE = 4
    GLY = 5; HIS = 6; ILE = 7; LYS = 8; LEU = 9
    MET = 10; ASN = 11; PRO = 12; GLN = 13; ARG = 14
    SER = 15; THR = 16; VAL = 17; TRP = 18; TYR = 19
    UNK = 20; PAD = 21; SEPA = 22; MASK = 23

    @classmethod
    def _missing_(cls, value):
        if isinstance(value, str) and len(value) == 3:      # three representation
            if value in non_standard_residue_substitutions:
                value = non_standard_residue_substitutions[value]
            if value in cls._member_names_:
                return getattr(cls, value)
        elif isinstance(value, str) and len(value) == 1:    # one representation
            if value in ressymb_to_resindex:
                return cls(ressymb_to_resindex[value])

        return super()._missing_(value)

    def __str__(self):
        return self.name

    @classmethod
    def is_aa(cls, value):
        return (value in ressymb_to_resindex) or \
            (value in non_standard_residue_substitutions) or \
            (value in cls._member_names_) or \
            (value in cls._member_map_.values())


num_aa_types = len(AALib)

# #
# Atom identities

class BBHeavyAtom(enum.IntEnum):
    N = 0; CA = 1; C = 2; O = 3; CB = 4; OXT=14;

max_num_heavyatoms = 15

# Copyright 2021 DeepMind Technologies Limited
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
restype_to_heavyatom_names = {
    AALib.ALA: ['N', 'CA', 'C', 'O', 'CB', '',    '',    '',    '',    '',    '',    '',    '',    '', 'OXT'],
    AALib.ARG: ['N', 'CA', 'C', 'O', 'CB', 'CG',  'CD',  'NE',  'CZ',  'NH1', 'NH2', '',    '',    '', 'OXT'],
    AALib.ASN: ['N', 'CA', 'C', 'O', 'CB', 'CG',  'OD1', 'ND2', '',    '',    '',    '',    '',    '', 'OXT'],
    AALib.ASP: ['N', 'CA', 'C', 'O', 'CB', 'CG',  'OD1', 'OD2', '',    '',    '',    '',    '',    '', 'OXT'],
    AALib.CYS: ['N', 'CA', 'C', 'O', 'CB', 'SG',  '',    '',    '',    '',    '',    '',    '',    '', 'OXT'],
    AALib.GLN: ['N', 'CA', 'C', 'O', 'CB', 'CG',  'CD',  'OE1', 'NE2', '',    '',    '',    '',    '', 'OXT'],
    AALib.GLU: ['N', 'CA', 'C', 'O', 'CB', 'CG',  'CD',  'OE1', 'OE2', '',    '',    '',    '',    '', 'OXT'],
    AALib.GLY: ['N', 'CA', 'C', 'O', '',   '',    '',    '',    '',    '',    '',    '',    '',    '', 'OXT'],
    AALib.HIS: ['N', 'CA', 'C', 'O', 'CB', 'CG',  'ND1', 'CD2', 'CE1', 'NE2', '',    '',    '',    '', 'OXT'],
    AALib.ILE: ['N', 'CA', 'C', 'O', 'CB', 'CG1', 'CG2', 'CD1', '',    '',    '',    '',    '',    '', 'OXT'],
    AALib.LEU: ['N', 'CA', 'C', 'O', 'CB', 'CG',  'CD1', 'CD2', '',    '',    '',    '',    '',    '', 'OXT'],
    AALib.LYS: ['N', 'CA', 'C', 'O', 'CB', 'CG',  'CD',  'CE',  'NZ',  '',    '',    '',    '',    '', 'OXT'],
    AALib.MET: ['N', 'CA', 'C', 'O', 'CB', 'CG',  'SD',  'CE',  '',    '',    '',    '',    '',    '', 'OXT'],
    AALib.PHE: ['N', 'CA', 'C', 'O', 'CB', 'CG',  'CD1', 'CD2', 'CE1', 'CE2', 'CZ',  '',    '',    '', 'OXT'],
    AALib.PRO: ['N', 'CA', 'C', 'O', 'CB', 'CG',  'CD',  '',    '',    '',    '',    '',    '',    '', 'OXT'],
    AALib.SER: ['N', 'CA', 'C', 'O', 'CB', 'OG',  '',    '',    '',    '',    '',    '',    '',    '', 'OXT'],
    AALib.THR: ['N', 'CA', 'C', 'O', 'CB', 'OG1', 'CG2', '',    '',    '',    '',    '',    '',    '', 'OXT'],
    AALib.TRP: ['N', 'CA', 'C', 'O', 'CB', 'CG',  'CD1', 'CD2', 'NE1', 'CE2', 'CE3', 'CZ2', 'CZ3', 'CH2', 'OXT'],
    AALib.TYR: ['N', 'CA', 'C', 'O', 'CB', 'CG',  'CD1', 'CD2', 'CE1', 'CE2', 'CZ',  'OH',  '',    '', 'OXT'],
    AALib.VAL: ['N', 'CA', 'C', 'O', 'CB', 'CG1', 'CG2', '',    '',    '',    '',    '',    '',    '', 'OXT'],
    AALib.UNK: ['',  '',   '',  '',  '',   '',    '',    '',    '',    '',    '',    '',    '',    '',    ''],
}

for names in restype_to_heavyatom_names.values(): assert len(names) == max_num_heavyatoms

backbone_atom_coordinates = {
    AALib.ALA: [
        (-0.525, 1.363, 0.0),  # N
        (0.0, 0.0, 0.0),  # CA
        (1.526, -0.0, -0.0),  # C
    ],
    AALib.ARG: [
        (-0.524, 1.362, -0.0),  # N
        (0.0, 0.0, 0.0),  # CA
        (1.525, -0.0, -0.0),  # C
    ],
    AALib.ASN: [
        (-0.536, 1.357, 0.0),  # N
        (0.0, 0.0, 0.0),  # CA
        (1.526, -0.0, -0.0),  # C
    ],
    AALib.ASP: [
        (-0.525, 1.362, -0.0),  # N
        (0.0, 0.0, 0.0),  # CA
        (1.527, 0.0, -0.0),  # C
    ],
    AALib.CYS: [
        (-0.522, 1.362, -0.0),  # N
        (0.0, 0.0, 0.0),  # CA
        (1.524, 0.0, 0.0),  # C
    ],
    AALib.GLN: [
        (-0.526, 1.361, -0.0),  # N
        (0.0, 0.0, 0.0),  # CA
        (1.526, 0.0, 0.0),  # C
    ],
    AALib.GLU: [
        (-0.528, 1.361, 0.0),  # N
        (0.0, 0.0, 0.0),  # CA
        (1.526, -0.0, -0.0),  # C
    ],
    AALib.GLY: [
        (-0.572, 1.337, 0.0),  # N
        (0.0, 0.0, 0.0),  # CA
        (1.517, -0.0, -0.0),  # C
    ],
    AALib.HIS: [
        (-0.527, 1.36, 0.0),  # N
        (0.0, 0.0, 0.0),  # CA
        (1.525, 0.0, 0.0),  # C
    ],
    AALib.ILE: [
        (-0.493, 1.373, -0.0),  # N
        (0.0, 0.0, 0.0),  # CA
        (1.527, -0.0, -0.0),  # C
    ],
    AALib.LEU: [
        (-0.52, 1.363, 0.0),  # N
        (0.0, 0.0, 0.0),  # CA
        (1.525, -0.0, -0.0),  # C
    ],
    AALib.LYS: [
        (-0.526, 1.362, -0.0),  # N
        (0.0, 0.0, 0.0),  # CA
        (1.526, 0.0, 0.0),  # C
    ],
    AALib.MET: [
        (-0.521, 1.364, -0.0),  # N
        (0.0, 0.0, 0.0),  # CA
        (1.525, 0.0, 0.0),  # C
    ],
    AALib.PHE: [
        (-0.518, 1.363, 0.0),  # N
        (0.0, 0.0, 0.0),  # CA
        (1.524, 0.0, -0.0),  # C
    ],
    AALib.PRO: [
        (-0.566, 1.351, -0.0),  # N
        (0.0, 0.0, 0.0),  # CA
        (1.527, -0.0, 0.0),  # C
    ],
    AALib.SER: [
        (-0.529, 1.36, -0.0),  # N
        (0.0, 0.0, 0.0),  # CA
        (1.525, -0.0, -0.0),  # C
    ],
    AALib.THR: [
        (-0.517, 1.364, 0.0),  # N
        (0.0, 0.0, 0.0),  # CA
        (1.526, 0.0, -0.0),  # C
    ],
    AALib.TRP: [
        (-0.521, 1.363, 0.0),  # N
        (0.0, 0.0, 0.0),  # CA
        (1.525, -0.0, 0.0),  # C
    ],
    AALib.TYR: [
        (-0.522, 1.362, 0.0),  # N
        (0.0, 0.0, 0.0),  # CA
        (1.524, -0.0, -0.0),  # C
    ],
    AALib.VAL: [
        (-0.494, 1.373, -0.0),  # N
        (0.0, 0.0, 0.0),  # CA
        (1.527, -0.0, -0.0),  # C
    ],
}

bb_oxygen_coordinate = {
    AALib.ALA: (2.153, -1.062, 0.0),
    AALib.ARG: (2.151, -1.062, 0.0),
    AALib.ASN: (2.151, -1.062, 0.0),
    AALib.ASP: (2.153, -1.062, 0.0),
    AALib.CYS: (2.149, -1.062, 0.0),
    AALib.GLN: (2.152, -1.062, 0.0),
    AALib.GLU: (2.152, -1.062, 0.0),
    AALib.GLY: (2.143, -1.062, 0.0),
    AALib.HIS: (2.15, -1.063, 0.0),
    AALib.ILE: (2.154, -1.062, 0.0),
    AALib.LEU: (2.15, -1.063, 0.0),
    AALib.LYS: (2.152, -1.062, 0.0),
    AALib.MET: (2.15, -1.062, 0.0),
    AALib.PHE: (2.15, -1.062, 0.0),
    AALib.PRO: (2.148, -1.066, 0.0),
    AALib.SER: (2.151, -1.062, 0.0),
    AALib.THR: (2.152, -1.062, 0.0),
    AALib.TRP: (2.152, -1.062, 0.0),
    AALib.TYR: (2.151, -1.062, 0.0),
    AALib.VAL: (2.154, -1.062, 0.0),
}

backbone_atom_coordinates_tensor = torch.zeros([21, 3, 3])
bb_oxygen_coordinate_tensor = torch.zeros([21, 3])

def make_coordinate_tensors():
    for restype, atom_coords in backbone_atom_coordinates.items():
        for atom_id, atom_coord in enumerate(atom_coords):
            backbone_atom_coordinates_tensor[restype][atom_id] = torch.FloatTensor(atom_coord)
    
    for restype, bb_oxy_coord in bb_oxygen_coordinate.items():
        bb_oxygen_coordinate_tensor[restype] = torch.FloatTensor(bb_oxy_coord)

make_coordinate_tensors()

```

Contents of utils/loss_functions.py:
```
"""
Author: Talip Ucar
email: ucabtuc@gmail.com

Description: Library of loss functions.
"""

import numpy as np
import torch
import torch.nn.functional as F


def rotation_loss(R_pred, R_true):
    """
    Computes the loss between predicted and true rotation matrices using cosine embedding loss.

    Parameters
    ----------
    R_pred : torch.Tensor
        Predicted rotation matrices, shape (N, L, 3, 3).
    R_true : torch.Tensor
        True rotation matrices, shape (N, L, 3, 3).

    Returns
    -------
    torch.Tensor
        Per-matrix loss, shape (N, L), representing the loss for each predicted rotation.
    """
    size = list(R_pred.shape[:-2])  # Batch dimensions (N, L)
    ncol = R_pred.numel() // 3  # Number of columns after reshaping

    # Transpose and reshape the predicted and true rotation matrices
    RT_pred = R_pred.transpose(-2, -1).reshape(ncol, 3)
    RT_true = R_true.transpose(-2, -1).reshape(ncol, 3)

    # Compute the cosine embedding loss
    ones = torch.ones([ncol], dtype=torch.long, device=R_pred.device)
    loss = F.cosine_embedding_loss(RT_pred, RT_true, ones, reduction='none')
    
    # Reshape loss and sum over the last dimension
    loss = loss.reshape(size + [3]).sum(dim=-1)  # Shape (N, L)
    
    return loss


def sum_weighted_losses(losses, weights):
    """
    Sums the weighted losses.

    Parameters
    ----------
    losses : dict
        Dictionary of scalar tensors representing different losses.
    weights : dict
        Dictionary of weights for each loss.

    Returns
    -------
    torch.Tensor
        Weighted sum of losses.
    """
    loss = 0
    for key in losses.keys():
        if weights is None:
            loss += losses[key]
        else:
            loss += weights[key] * losses[key]
    return loss

```

Contents of utils/utils.py:
```
"""
Author: Talip Ucar
email: ucabtuc@gmail.com

Description: Utility functions.
"""

import cProfile
import os
import pstats
import random as python_random
import sys

import numpy as np
import torch
import yaml
from numpy.random import seed
from sklearn import manifold
from texttable import Texttable
import logging




def set_seed(options):
    """
    Sets the seed for reproducibility in various modules (numpy, torch, etc.).

    Parameters
    ----------
    options : dict
        Dictionary containing seed value under the key "seed".
    """
    seed = options["seed"]
    np.random.seed(seed)
    python_random.seed(seed)
    torch.manual_seed(seed)


def create_dir(dir_path):
    """
    Creates a directory if it does not already exist.

    Parameters
    ----------
    dir_path : str
        The path of the directory to create.
    """
    if not os.path.exists(dir_path):
        os.makedirs(dir_path)


def set_dirs(config):
    """
    Sets up directory structure for loading data, saving results, and logging.

    The directory structure follows the pattern:
        results > experiment > training > task > model
                                      > evaluation > plots > loss

    Parameters
    ----------
    config : dict
        Dictionary containing configuration options including paths and dataset names.
    """
    paths = config["paths"]

    # Data directories
    data_processed_dir = make_dir(paths["data"], "processed")
    data_pdb_dir = make_dir(paths["data"], f"{config['dataset']}_{config['scheme']}")
    config["data_pdb_dir"] = data_pdb_dir
    sabdab_pdb_dir = make_dir(paths["data"], f"sabdab_{config['scheme']}")
    config["sabdab_pdb_dir"] = sabdab_pdb_dir

    # Results directories
    results_dir = make_dir(paths["results"], "")
    results_dir = make_dir(results_dir, config["experiment"])
    training_dir = make_dir(results_dir, "training")
    evaluation_dir = make_dir(results_dir, "evaluation")
    model_mode_dir = make_dir(training_dir, config["task"])
    training_model_dir = make_dir(model_mode_dir, "model")
    training_plot_dir = make_dir(model_mode_dir, "plots")
    training_loss_dir = make_dir(model_mode_dir, "loss")
    config["results_dir"] = results_dir

    if 'antigen' in config and 'antibody' in config:
        evaluation_dir_abag = make_dir(results_dir, f"{config['antigen']}_{config['antibody']}")
        lo_dir = make_dir(evaluation_dir_abag, "lead_optimization")
        denovo_dir = make_dir(evaluation_dir_abag, "denovo")

        config.update({
            "denovo_dir": denovo_dir,
            "lo_dir": lo_dir,
        })

    print("Directories are set.")


def make_dir(directory_path, new_folder_name):
    """
    Creates a directory with the specified folder name if it does not exist.

    Parameters
    ----------
    directory_path : str
        Parent directory path.
    new_folder_name : str
        Name of the new folder to create.

    Returns
    -------
    str
        Full path of the created directory.
    """
    directory_path = os.path.join(directory_path, new_folder_name)
    if not os.path.exists(directory_path):
        os.makedirs(directory_path)
    return directory_path


def get_runtime_and_model_config(args):
    """
    Loads runtime configuration from a YAML file.

    Parameters
    ----------
    args : argparse.Namespace
        Command-line arguments.

    Returns
    -------
    dict
        Configuration dictionary loaded from the YAML file.
    """
    try:
        with open(f"./config/{args.dataset}.yaml", "r") as file:
            config = yaml.safe_load(file)
    except Exception as e:
        sys.exit("Error reading runtime config file")

    config["dataset"] = args.dataset
    return config


def update_config_with_model_dims(data_loader, config):
    """
    Updates configuration with the dimension of input features.

    Parameters
    ----------
    data_loader : DataLoader
        DataLoader object for the training dataset.
    config : dict
        Configuration dictionary to be updated.

    Returns
    -------
    dict
        Updated configuration dictionary.
    """
    x, _ = next(iter(data_loader.train_loader))
    dim = x.shape[-1]
    config["dims"].insert(0, dim)
    return config


def run_with_profiler(main_fn, config):
    """
    Runs the main function with a profiler to measure time spent on each step.

    Parameters
    ----------
    main_fn : function
        Main function to run with profiling.
    config : dict
        Configuration dictionary.
    """
    profiler = cProfile.Profile()
    profiler.enable()
    main_fn(config)
    profiler.disable()
    stats = pstats.Stats(profiler).sort_stats('ncalls')
    stats.print_stats()


def tsne(latent):
    """
    Reduces the dimensionality of the embeddings using t-SNE.

    Parameters
    ----------
    latent : np.ndarray
        Input embeddings to reduce dimensionality.

    Returns
    -------
    np.ndarray
        Reduced 2D embeddings.
    """
    tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)
    return tsne.fit_transform(latent)


def print_config(args):
    """
    Prints out the configuration settings in a tabular format.

    Parameters
    ----------
    args : dict or argparse.Namespace
        Configuration or arguments to print.
    """
    if not isinstance(args, dict):
        args = vars(args)

    keys = sorted(args.keys())
    table = Texttable()
    table.add_rows([["Parameter", "Value"]] + [[k.replace("_", " ").capitalize(), args[k]] for k in keys])
    print(table.draw())


def nan_to_none_or_empty_str(val, string=True):
    """
    Converts NaN values to None or an empty string based on the input type.

    Parameters
    ----------
    val : any
        Input value.
    string : bool, optional
        Whether to convert to an empty string if `val` is NaN, by default True.

    Returns
    -------
    any
        None or an empty string if `val` is NaN, otherwise returns `val`.
    """
    if val != val or not val:
        return '' if string else None
    return val


def split_delimiter_pipe2str(val):
    """
    Splits a string by pipe ('|') and trims whitespace from the resulting parts.

    Parameters
    ----------
    val : str
        Input string to split.

    Returns
    -------
    list
        List of split and trimmed strings.
    """
    if not val:
        return []
    return [s.strip() for s in val.split('|')]


def parse_resolution(val):
    """
    Parses the resolution value from a string.

    Parameters
    ----------
    val : str or None
        Input resolution value.

    Returns
    -------
    float or None
        Parsed resolution as a float, or None if input is invalid.
    """
    if val in {'NOT', '', None} or val != val:
        return None

    if isinstance(val, str) and ',' in val:
        return float(val.split(',')[0].strip())

    return float(val)


def get_logger(name, log_dir=None):
    """
    Configures and returns a logger for logging messages to console and file.

    Parameters
    ----------
    name : str
        Logger name.
    log_dir : str, optional
        Directory to save log files, by default None.

    Returns
    -------
    logging.Logger
        Configured logger instance.
    """
    logger = logging.getLogger(name)
    logger.setLevel(logging.DEBUG)
    formatter = logging.Formatter('[%(asctime)s::%(name)s::%(levelname)s] %(message)s')

    stream_handler = logging.StreamHandler()
    stream_handler.setLevel(logging.DEBUG)
    stream_handler.setFormatter(formatter)
    logger.addHandler(stream_handler)

    if log_dir is not None:
        file_handler = logging.FileHandler(os.path.join(log_dir, 'log.txt'))
        file_handler.setLevel(logging.DEBUG)
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)

    return logger

```

Contents of utils/utils_diff.py:
```
"""
Author: Talip Ucar
email: ucabtuc@gmail.com

Description: Library of utils needed for training diffusion model.
"""

import logging
import torch
import numpy as np
import torch.nn.functional as F
from torch.profiler import record_function
from inspect import isfunction
from easydict import EasyDict

import torch
import torch.nn.functional as F
import numpy as np

def clampped_one_hot(x, num_classes):
    """
    Computes a clamped one-hot encoding of the input tensor.

    Parameters
    ----------
    x : torch.Tensor
        Input tensor containing class indices, shape (N, L).
    num_classes : int
        The number of classes for one-hot encoding.

    Returns
    -------
    torch.Tensor
        One-hot encoded tensor with the same batch size, shape (N, L, C).
    """
    mask = (x >= 0) & (x < num_classes)
    x = x.clamp(min=0, max=num_classes - 1)
    y = F.one_hot(x, num_classes) * mask[..., None]
    return y


def move2device(obj, device='cuda'):
    """
    Moves a given object (Tensor, list, tuple, dict) to a specific device (CPU or GPU).

    Parameters
    ----------
    obj : any
        Object to move to the specified device. Can be a torch.Tensor, list, tuple, or dict.
    device : str, optional
        The target device (default is 'cuda').

    Returns
    -------
    any
        Object moved to the specified device.
    """
    if isinstance(obj, torch.Tensor):
        return obj.to(device)
    elif isinstance(obj, list):
        return [move2device(o, device=device) for o in obj]
    elif isinstance(obj, tuple):
        return tuple(move2device(o, device=device) for o in obj)
    elif isinstance(obj, dict):
        return {k: move2device(v, device=device) for k, v in obj.items()}
    return obj


def inf_iterator(iterable):
    """
    Creates an infinite iterator over the provided iterable.

    Parameters
    ----------
    iterable : iterable
        The iterable to create an infinite loop over.

    Yields
    ------
    any
        Next item from the iterable.
    """
    iterator = iter(iterable)
    while True:
        try:
            yield next(iterator)
        except StopIteration:
            iterator = iter(iterable)


def normal_kl(mean1, logvar1, mean2, logvar2):
    """
    Computes the KL divergence between two Gaussian distributions.

    Parameters
    ----------
    mean1, logvar1, mean2, logvar2 : torch.Tensor
        Mean and log-variance tensors for both distributions.

    Returns
    -------
    torch.Tensor
        KL divergence between the two distributions.
    """
    logvar1, logvar2 = [
        x if isinstance(x, torch.Tensor) else torch.tensor(x).to(mean1.device)
        for x in (logvar1, logvar2)
    ]

    return 0.5 * (
        -1.0 + logvar2 - logvar1 + torch.exp(logvar1 - logvar2)
        + ((mean1 - mean2) ** 2) * torch.exp(-logvar2)
    )


def approx_standard_normal_cdf(x):
    """
    A fast approximation of the cumulative distribution function (CDF) of the standard normal distribution.

    Parameters
    ----------
    x : torch.Tensor
        Input tensor.

    Returns
    -------
    torch.Tensor
        Approximated CDF values.
    """
    return 0.5 * (1.0 + torch.tanh(np.sqrt(2.0 / np.pi) * (x + 0.044715 * torch.pow(x, 3))))


def discretized_gaussian_log_likelihood(x, *, means, log_scales):
    """
    Computes the log-likelihood of a Gaussian distribution discretizing to a given image.

    Parameters
    ----------
    x : torch.Tensor
        The target images, assumed to be uint8 values rescaled to the range [-1, 1].
    means : torch.Tensor
        The Gaussian mean tensor.
    log_scales : torch.Tensor
        The Gaussian log stddev tensor.

    Returns
    -------
    torch.Tensor
        Log probabilities (in nats).
    """
    centered_x = x - means
    inv_stdv = torch.exp(-log_scales)
    plus_in = inv_stdv * (centered_x + 1.0 / 255.0)
    cdf_plus = approx_standard_normal_cdf(plus_in)
    min_in = inv_stdv * (centered_x - 1.0 / 255.0)
    cdf_min = approx_standard_normal_cdf(min_in)

    log_cdf_plus = torch.log(cdf_plus.clamp(min=1e-12))
    log_one_minus_cdf_min = torch.log((1.0 - cdf_min).clamp(min=1e-12))
    cdf_delta = cdf_plus - cdf_min

    log_probs = torch.where(
        x < -0.999, log_cdf_plus, torch.where(x > 0.999, log_one_minus_cdf_min, torch.log(cdf_delta.clamp(min=1e-12)))
    )
    return log_probs


def sum_except_batch(x, num_dims=1):
    """
    Sums all dimensions except the first `num_dims` batch dimensions.

    Parameters
    ----------
    x : torch.Tensor
        Input tensor of shape (batch_size, ...).
    num_dims : int, optional
        Number of batch dimensions, by default 1.

    Returns
    -------
    torch.Tensor
        Tensor with batch dimensions retained, shape (batch_size,).
    """
    return x.reshape(*x.shape[:num_dims], -1).sum(-1)


def mean_flat(tensor):
    """
    Computes the mean across all non-batch dimensions.

    Parameters
    ----------
    tensor : torch.Tensor
        Input tensor.

    Returns
    -------
    torch.Tensor
        Mean across non-batch dimensions.
    """
    return tensor.mean(dim=list(range(1, tensor.ndim)))


def ohe_to_categories(ohe, K):
    """
    Converts one-hot encoded tensor to categorical indices.

    Parameters
    ----------
    ohe : torch.Tensor
        One-hot encoded tensor, shape (N, sum(K)).
    K : list
        List of class sizes for each categorical variable.

    Returns
    -------
    torch.Tensor
        Categorical indices, shape (N, len(K)).
    """
    K = torch.from_numpy(K)
    indices = torch.cat([torch.zeros((1,)), K.cumsum(dim=0)], dim=0).int().tolist()
    res = [ohe[:, indices[i]:indices[i+1]].argmax(dim=1) for i in range(len(indices) - 1)]
    return torch.stack(res, dim=1)


def log_1_min_a(a):
    """
    Computes the log of `1 - exp(a)` safely to avoid numerical instability.

    Parameters
    ----------
    a : torch.Tensor
        Input tensor.

    Returns
    -------
    torch.Tensor
        Log of `1 - exp(a)`.
    """
    return torch.log(1 - a.exp() + 1e-40)


def log_add_exp(a, b):
    """
    Computes the log of the sum of two exponentials in a numerically stable way.

    Parameters
    ----------
    a, b : torch.Tensor
        Input tensors.

    Returns
    -------
    torch.Tensor
        Logarithm of the sum of exponentials of the inputs.
    """
    maximum = torch.max(a, b)
    return maximum + torch.log(torch.exp(a - maximum) + torch.exp(b - maximum))


def exists(x):
    """
    Checks if a variable is not None.

    Parameters
    ----------
    x : any
        Input variable.

    Returns
    -------
    bool
        True if x is not None, False otherwise.
    """
    return x is not None


def extract(a, t, x_shape):
    """
    Extracts values from tensor `a` at index `t` and reshapes them to match `x_shape`.

    Parameters
    ----------
    a : torch.Tensor
        Input tensor from which values are extracted.
    t : torch.Tensor
        Indices at which to extract values.
    x_shape : tuple
        Shape of the output tensor.

    Returns
    -------
    torch.Tensor
        Extracted and reshaped tensor.
    """
    out = a.gather(-1, t.to(a.device))
    while len(out.shape) < len(x_shape):
        out = out[..., None]
    return out.expand(x_shape)


def default(val, d):
    """
    Returns `val` if it is not None, otherwise returns `d`.

    Parameters
    ----------
    val : any
        The value to check.
    d : any
        The default value to return if `val` is None.

    Returns
    -------
    any
        `val` if not None, otherwise `d`.
    """
    return val if exists(val) else d() if callable(d) else d


def log_categorical(log_x_start, log_prob):
    """
    Computes the log-likelihood for categorical data.

    Parameters
    ----------
    log_x_start : torch.Tensor
        Logarithm of the starting values.
    log_prob : torch.Tensor
        Logarithm of the probabilities.

    Returns
    -------
    torch.Tensor
        Log-likelihood for categorical data.
    """
    return (log_x_start.exp() * log_prob).sum(dim=1)


def index_to_log_onehot(x, num_classes):
    """
    Converts index tensor to a log one-hot encoded tensor.

    Parameters
    ----------
    x : torch.Tensor
        Input index tensor.
    num_classes : int
        Number of classes for one-hot encoding.

    Returns
    -------
    torch.Tensor
        Log one-hot encoded tensor.
    """
    onehots = [F.one_hot(x[:, i], num_classes[i]) for i in range(len(num_classes))]
    x_onehot = torch.cat(onehots, dim=1)
    return torch.log(x_onehot.float().clamp(min=1e-30))


def log_sum_exp_by_classes(x, slices):
    """
    Computes the log-sum-exp over specific class slices in a tensor.

    Parameters
    ----------
    x : torch.Tensor
        Input tensor.
    slices : list of slice
        List of slices to sum over.

    Returns
    -------
    torch.Tensor
        Tensor with log-sum-exp over the specified slices.
    """
    res = torch.zeros_like(x)
    for ixs in slices:
        res[:, ixs] = torch.logsumexp(x[:, ixs], dim=1, keepdim=True)
    return res


@torch.jit.script
def log_sub_exp(a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:
    """
    Computes the log of the difference of two exponentials in a numerically stable way.

    Parameters
    ----------
    a, b : torch.Tensor
        Input tensors.

    Returns
    -------
    torch.Tensor
        Logarithm of the difference of exponentials of the inputs.
    """
    m = torch.maximum(a, b)
    return torch.log(torch.exp(a - m) - torch.exp(b - m)) + m


@torch.jit.script
def sliced_logsumexp(x, slices):
    """
    Computes the log-sum-exp over specific slices of the input tensor.

    Parameters
    ----------
    x : torch.Tensor
        Input tensor.
    slices : list
        List of slices defining the sections to compute log-sum-exp.

    Returns
    -------
    torch.Tensor
        Tensor with log-sum-exp applied to the specified slices.
    """
    lse = torch.logcumsumexp(F.pad(x, [1, 0, 0, 0], value=-float('inf')), dim=-1)
    slice_starts, slice_ends = slices[:-1], slices[1:]
    slice_lse = log_sub_exp(lse[:, slice_ends], lse[:, slice_starts])
    return torch.repeat_interleave(slice_lse, slice_ends - slice_starts, dim=-1)


def log_onehot_to_index(log_x):
    """
    Converts a log one-hot tensor to categorical indices.

    Parameters
    ----------
    log_x : torch.Tensor
        Log one-hot encoded tensor.

    Returns
    -------
    torch.Tensor
        Categorical index tensor.
    """
    return log_x.argmax(dim=1)


class FoundNANsError(BaseException):
    """
    Exception raised when NaNs are found during sampling.

    Attributes
    ----------
    message : str
        Error message to display when exception is raised.
    """
    def __init__(self, message='Found NaNs during sampling.'):
        super().__init__(message)

```

Contents of foldseek/README.md:
```

# Foldseek 
Foldseek enables fast and sensitive comparisons of large protein structure sets.

<p align="center"><img src="https://github.com/steineggerlab/foldseek/blob/master/.github/foldseek.png" height="250"/></p>

## Publications
[van Kempen M, Kim S, Tumescheit C, Mirdita M, Lee J, Gilchrist CLM, S√∂ding J, and Steinegger M. Fast and accurate protein structure search with Foldseek. Nature Biotechnology, doi:10.1038/s41587-023-01773-0 (2023)](https://www.nature.com/articles/s41587-023-01773-0)

[Barrio-Hernandez I, Yeo J, J√§nes J, Mirdita M, Gilchrist CLM, Wein T, Varadi M, Velankar S, Beltrao P and Steinegger M. Clustering predicted structures at the scale of the known protein universe. Nature, doi:10.1038/s41586-023-06510-w (2023)](https://www.nature.com/articles/s41586-023-06510-w)

[Kim W, Mirdita M, Levy Karin E, Gilchrist CLM, Schweke H, S√∂ding J, Levy E, and Steinegger M. Rapid and Sensitive Protein Complex Alignment with Foldseek-Multimer. bioRxiv, doi:10.1101/2024.04.14.589414 (2024)](https://www.biorxiv.org/content/10.1101/2024.04.14.589414v1)

# Table of Contents

- [Foldseek](#foldseek)
  - [Publications](#publications)
- [Table of Contents](#table-of-contents)
  - [Webserver](#webserver)
  - [Installation](#installation)
  - [Memory requirements](#memory-requirements)
  - [Tutorial Video](#tutorial-video)
  - [Documentation](#documentation)
  - [Quick start](#quick-start)
    - [Search](#search)
      - [Output Search](#output-search)
        - [Tab-separated](#tab-separated)
        - [Superpositioned CŒ± only PDB files](#superpositioned-cŒ±-only-pdb-files)
        - [Interactive HTML](#interactive-html)
      - [Important search parameters](#important-search-parameters)
      - [Alignment Mode](#alignment-mode)
      - [Structure search from FASTA input](#structure-search-from-fasta-input)
    - [Databases](#databases)
      - [Create custom databases and indexes](#create-custom-databases-and-indexes)
    - [Cluster](#cluster)
      - [Output Cluster](#output-cluster)
        - [Tab-separated cluster](#tab-separated-cluster)
        - [Representative fasta](#representative-fasta)
        - [All member fasta](#all-member-fasta)
      - [Important cluster parameters](#important-cluster-parameters)
    - [Multimersearch](#multimersearch)
      - [Using Multimersearch](#using-multimersearch)
      - [Multimer Search Output](#multimer-search-output)
        - [Tab-separated-complex](#tab-separated-complex)
        - [Complex Report](#complex-report)
    - [Multimercluster](#multimercluster)
      - [Output MultimerCluster](#output-multimercluster)
        - [Tab-separated multimercluster](#tab-separated-multimercluster)
        - [Representative multimer fasta](#representative-multimer-fasta)
        - [Filtered search result](#filtered-search-result)
      - [Important multimer cluster parameters](#important-multimer-cluster-parameters)
  - [Main Modules](#main-modules)
  - [Examples](#examples)
    - [Rescore aligments using TMscore](#rescore-aligments-using-tmscore)
    - [Query centered multiple sequence alignment](#query-centered-multiple-sequence-alignment)

## Webserver 
Search your protein structures against the [AlphaFoldDB](https://alphafold.ebi.ac.uk/) and [PDB](https://www.rcsb.org/) in seconds using the Foldseek webserver ([code](https://github.com/soedinglab/mmseqs2-app)): [search.foldseek.com](https://search.foldseek.com) üöÄ

## Installation
```
# Linux AVX2 build (check using: cat /proc/cpuinfo | grep avx2)
wget https://mmseqs.com/foldseek/foldseek-linux-avx2.tar.gz; tar xvzf foldseek-linux-avx2.tar.gz; export PATH=$(pwd)/foldseek/bin/:$PATH

# Linux SSE2 build (check using: cat /proc/cpuinfo | grep sse2)
wget https://mmseqs.com/foldseek/foldseek-linux-sse2.tar.gz; tar xvzf foldseek-linux-sse2.tar.gz; export PATH=$(pwd)/foldseek/bin/:$PATH

# Linux ARM64 build
wget https://mmseqs.com/foldseek/foldseek-linux-arm64.tar.gz; tar xvzf foldseek-linux-arm64.tar.gz; export PATH=$(pwd)/foldseek/bin/:$PATH

# MacOS
wget https://mmseqs.com/foldseek/foldseek-osx-universal.tar.gz; tar xvzf foldseek-osx-universal.tar.gz; export PATH=$(pwd)/foldseek/bin/:$PATH

# Conda installer (Linux and macOS)
conda install -c conda-forge -c bioconda foldseek
```
Other precompiled binaries for ARM64 amd SSE2 are available at [https://mmseqs.com/foldseek](https://mmseqs.com/foldseek).

## Memory requirements 
For optimal software performance, consider three options based on your RAM and search requirements:

1. **With CŒ± info (default).** 
   Use this formula to calculate RAM - `(6 bytes CŒ± + 1 3Di byte + 1 AA byte) * (database residues)`. The 54M AFDB50 entries require 151GB.

2. **Without CŒ± info.** 
   By disabling `--sort-by-structure-bits 0`, RAM requirement reduces to 35GB. However, this alters hit rankings and final scores but not E-values. Structure bits are mostly relevant for hit ranking for E-value > 10^-1.

3. **Single query searches.** 
   Use the `--prefilter-mode 1`, which isn't memory-limited and computes all ungapped alignments. This option optimally utilizes foldseek's multithreading capabilities for single queries.

## Tutorial Video
We presented a Foldseek tutorial at the SBGrid where we demonstrated Foldseek's webserver and command line interface. 
Check it out [here](https://www.youtube.com/watch?v=k5Rbi22TtOA).

<a href="https://www.youtube.com/watch?v=k5Rbi22TtOA"><img src="https://img.shields.io/youtube/views/k5Rbi22TtOA?style=social"></a>.

## Documentation
Many of Foldseek's modules (subprograms) rely on MMseqs2. For more information about these modules, refer to the [MMseqs2 wiki](https://github.com/soedinglab/MMseqs2/wiki). For documentation specific to Foldseek, checkout the Foldseek wiki [here](https://github.com/steineggerlab/foldseek/wiki).

## Quick start

### Search
The `easy-search` module allows to query one or more single-chain protein structures, formatted in PDB/mmCIF format (flat or gzipped), against a target database, folder or individual single-chain protein structures (for multi-chain proteins see [complexsearch](#complexsearch)). The default alignment information output is a [tab-separated file](#tab-separated) but Foldseek also supports [Superposed CŒ± PDBs](#superpositioned-cŒ±-only-pdb-files) and [HTML](#interactive-html).

    foldseek easy-search example/d1asha_ example/ aln tmpFolder
    
#### Output Search
##### Tab-separated
  
The default output fields are: `query,target,fident,alnlen,mismatch,gapopen,qstart,qend,tstart,tend,evalue,bits` but they can be customized with the `--format-output` option e.g., `--format-output "query,target,qaln,taln"` returns the query and target accessions and the pairwise alignments in tab-separated format. You can choose many different output columns.

| Code | Description |
| --- | --- |
|query | Query sequence identifier |
|target | Target sequence identifier |
|qca        | Calpha coordinates of the query |
|tca        | Calpha coordinates of the target |
|alntmscore | TM-score of the alignment | 
|qtmscore   | TM-score normalized by the query length |
|ttmscore   | TM-score normalized by the target length |
|u          | Rotation matrix (computed to by TM-score) |
|t          | Translation vector (computed to by TM-score) |
|lddt       | Average LDDT of the alignment |
|lddtfull   | LDDT per aligned position |
|prob       | Estimated probability for query and target to be homologous (e.g. being within the same SCOPe superfamily) |

Check out the [MMseqs2 documentation for additional output format codes](https://github.com/soedinglab/MMseqs2/wiki#custom-alignment-format-with-convertalis).

##### Superpositioned CŒ± only PDB files
Foldseek's `--format-mode 5` generates PDB files with all target CŒ± atoms superimposed onto the query structure based on the aligned coordinates. 
For each pairwise alignment it will write its own PDB file, so be careful when using this options for large searches. 

##### Interactive HTML
Locally run Foldseek can generate an HTML search result, similar to the one produced by the [webserver](https://search.foldseek.com) by specifying `--format-mode 3`

```
foldseek easy-search example/d1asha_ example/ result.html tmp --format-mode 3
```

<p align="center"><img src="./.github/results.png" height="400"/></p>

#### Important search parameters

| Option            | Category        | Description                                                                                               |
|-------------------|-----------------|-----------------------------------------------------------------------------------------------------------|
| -s              | Sensitivity     | Adjust sensitivity to speed trade-off; lower is faster, higher more sensitive (fast: 7.5, default: 9.5)   |
| --exhaustive-search | Sensitivity | Skips prefilter and performs an all-vs-all alignment (more sensitive but much slower)                     |
| --max-seqs      | Sensitivity     | Adjust the amount of prefilter handed to alignment; increasing it can lead to more hits (default: 1000)   |
| -e              | Sensitivity     | List matches below this E-value (range 0.0-inf, default: 0.001); increasing it reports more distant structures |
| --alignment-type| Alignment       | 0: 3Di Gotoh-Smith-Waterman (local, not recommended), 1: TMalign (global, slow), 2: 3Di+AA Gotoh-Smith-Waterman (local, default) |
| -c              | Alignment  | List matches above this fraction of aligned (covered) residues (see --cov-mode) (default: 0.0); higher coverage = more global alignment |
| --cov-mode      | Alignment  | 0: coverage of query and target, 1: coverage of target, 2: coverage of query                               |

#### Alignment Mode
By default, Foldseek uses its local 3Di+AA structural alignment but it also supports realigning hits using the global TMalign as well as rescoring alignments using TMscore. 

    foldseek easy-search example/d1asha_ example/ aln tmp --alignment-type 1

If alignment type is set to tmalign (`--alignment-type 1`), the results will be sorted by the TMscore normalized by query length. The TMscore is used for reporting two fields: the e-value=(qTMscore+tTMscore)/2 and the score=(qTMscore*100). All output fields (e.g., pident, fident, and alnlen) are calculated based on the TMalign alignment.

#### Structure search from FASTA input
Search by predicting 3Di directly from amino acid sequences without the need for existing protein structures. 
This feature uses the [ProstT5](https://www.biorxiv.org/content/10.1101/2023.07.23.550085v2) protein language model and runs by default on CPU and is about 400-4000x compared to predicted structures by [ColabFold](https://github.com/sokrypton/ColabFold).

```
foldseek databases ProstT5 weights tmp
foldseek databases PDB pdb tmp
foldseek easy-search QUERY.fasta pdb result.m8 tmp --prostt5-model weights
```

Or create your a structural database from a fasta files.

```
foldseek createdb db.fasta db --prostt5-model weights
```

Faster inference using GPU/CUDA is also supported. Compile from source with `cmake -DCMAKE_BUILD_TYPE=Release  -DENABLE_CUDA=1 -DCUDAToolkit_ROOT=Path-To-Cuda-Toolkit` and call with `createdb/easy-search --prostt5-model weights --gpu 1`.

### Databases 
The `databases` command downloads pre-generated databases like PDB or AlphaFoldDB.
    
    # pdb  
    foldseek databases PDB pdb tmp 
    # alphafold db
    foldseek databases Alphafold/Proteome afdb tmp 

We currently support the following databases: 
```
  Name                   	Type     	Taxonomy	Url
- Alphafold/UniProt   	Aminoacid	     yes	https://alphafold.ebi.ac.uk/
- Alphafold/UniProt50 	Aminoacid	     yes	https://alphafold.ebi.ac.uk/
- Alphafold/Proteome  	Aminoacid	     yes	https://alphafold.ebi.ac.uk/
- Alphafold/Swiss-Prot	Aminoacid	     yes	https://alphafold.ebi.ac.uk/
- ESMAtlas30          	Aminoacid	       -	https://esmatlas.com
- PDB                 	Aminoacid	     yes	https://www.rcsb.org
```

#### Create custom databases and indexes
The target database can be pre-processed by `createdb`. This is useful when searching multiple times against the same set of target structures. 
 
    foldseek createdb example/ targetDB
    foldseek createindex targetDB tmp  #OPTIONAL generates and stores the index on disk
    foldseek easy-search example/d1asha_ targetDB aln.m8 tmpFolder

### Cluster
The `easy-cluster` algorithm is designed for structural clustering by assigning structures to a representative protein structure using structural alignment. It accepts input in either PDB or mmCIF format, with support for both flat and gzipped files. By default, easy-cluster generates three output files with the following prefixes: (1) `_clu.tsv`, (2) `_repseq.fasta`, and (3) `_allseq.fasta`. The first file (1) is a [tab-separated](#tab-separated-cluster) file describing the mapping from representative to member, while the second file (2) contains only [representative sequences](#representative-fasta), and the third file (3) includes all [cluster member sequences](#all-member-fasta).

    foldseek easy-cluster example/ res tmp -c 0.9 
    
#### Output Cluster
##### Tab-separated cluster
The provided format represents protein structure clustering in a tab-separated, two-column layout (representative and member). Each line denotes a cluster-representative and cluster-member relationship, signifying that the member shares significant structural similarity with the representative, and thus belongs to the same cluster.
```
Q0KJ32	Q0KJ32
Q0KJ32	C0W539
Q0KJ32	D6KVP9
E3HQM9	E3HQM9
E3HQM9	F0YHT8
```

##### Representative fasta
The `_repseq.fasta` contains all representative protein sequences of the clustering.
```
>Q0KJ32
MAGA....R
>E3HQM9
MCAT...Q
```

##### All member fasta
In the `_allseq.fasta` file all sequences of the cluster are present. A new cluster is marked by two identical name lines of the representative sequence, where the first line stands for the cluster and the second is the name line of the first cluster sequence. It is followed by the fasta formatted sequences of all its members.

```
>Q0KJ32	
>Q0KJ32
MAGA....R
>C0W539
MVGA....R
>D6KVP9
MVGA....R
>D1Y890
MVGV....R
>E3HQM9	
>E3HQM9
MCAT...Q
>Q223C0
MCAR...Q
```

#### Important cluster parameters

| Option            | Category        | Description                                                                                               |
|-------------------|-----------------|-----------------------------------------------------------------------------------------------------------|
| -e              | Sensitivity     | List matches below this E-value (range 0.0-inf, default: 0.001); increasing it reports more distant structures |
| --alignment-type| Alignment       | 0: 3Di Gotoh-Smith-Waterman (local, not recommended), 1: TMalign (global, slow), 2: 3Di+AA Gotoh-Smith-Waterman (local, default) |
| -c              | Alignment  | List matches above this fraction of aligned (covered) residues (see --cov-mode) (default: 0.0); higher coverage = more global alignment |
| --cov-mode      | Alignment  | 0: coverage of query and target, 1: coverage of target, 2: coverage of query                               |
| --min-seq-id      | Alignment  | the minimum sequence identity to be clustered                               |
| --tmscore-threshold      | Alignment  | accept alignments with an alignment TMscore > thr                               |
| --tmscore-threshold-mode    | Alignment  | normalize TMscore by 0: alignment, 1: representative, 2: member length                             |
| --lddt-threshold      | Alignment  | accept alignments with an alignment LDDT score > thr                               |


### Multimersearch
The `easy-multimersearch` module is designed for querying one or more protein complex (multi-chain) structures (supported input formats: PDB/mmCIF, flat or gzipped) against a target database of protein complex structures. It reports the similarity metrices between the complexes (e.g., the TMscore).

#### Using Multimersearch
The examples below use files that can be found in the `example` directory, which is part of the Foldseek repo, if you clone it. 
If you use the precompiled version of the software, you can download the files directly: [1tim.pdb.gz](https://github.com/steineggerlab/foldseek/raw/master/example/1tim.pdb.gz) and [8tim.pdb.gz](https://github.com/steineggerlab/foldseek/raw/master/example/8tim.pdb.gz).

For a pairwise alignment of complexes using `easy-multimersearch`, run the following command:
```
foldseek easy-multimersearch example/1tim.pdb.gz example/8tim.pdb.gz result tmpFolder
```
Foldseek `easy-multimersearch` can also be used for searching one or more query complexes against a target database: 
```
foldseek databases PDB pdb tmp 
foldseek easy-multimersearch example/1tim.pdb.gz pdb result tmpFolder
```

#### Multimer Search Output
##### Tab-separated-complex
By default, `easy-multimersearch` reports the output alignment in a tab-separated file.
The default output fields are: `query,target,fident,alnlen,mismatch,gapopen,qstart,qend,tstart,tend,evalue,bits,complexassignid` but they can be customized with the `--format-output` option e.g., `--format-output "query,target,complexqtmscore,complexttmscore,complexassignid"` alters the output to show specific scores and identifiers.

| Code | Description |
| --- | --- |
| **Commons** |
|query | Query sequence identifier |
|target | Target sequence identifier |
| **Only for scorecomplex** |
|complexqtmscore| TM-score of Complex alignment normalized by the query length |
|complexttmscore| TM-score of Complex alignment normalized by the target length |
|complexu       | Rotation matrix of Complex alignment (computed to by TM-score) |
|complext       | Translation vector of Complex alignment (computed to by TM-score) |
|complexassignid| Index of Complex alignment |

**Example Output:**
```
1tim.pdb.gz_A   8tim.pdb.gz_A   0.967   247 8   0   1   247 1   247 5.412E-43   1527    0
1tim.pdb.gz_B   8tim.pdb.gz_B   0.967   247 8   0   1   247 1   247 1.050E-43   1551    0
```

##### Complex Report
`easy-multimersearch` also generates a report (prefixed `_report`), which provides a summary of the inter-complex chain matching, including identifiers, chains, TMscores, rotation matrices, translation vectors, and assignment IDs. The report includes the following fields:
| Column | Description |
| --- | --- |
| 1 | Identifier of the query complex |
| 2 | Identifier of the target complex |
| 3 | Comma separated matched chains in the query complex |
| 4 | Comma separated matched chains in the target complex |
| 5 | TM score normalized by query length [0-1] |
| 6 | TM score normalized by target length [0-1] |
| 7 | Comma separated nine rotation matrix (U) values |
| 8 | Comma separated three translation vector (T) values |
| 9 | Complex alignment ID |

**Example Output:**
```
1tim.pdb.gz 8tim.pdb.gz A,B A,B 0.98941 0.98941 0.999983,0.000332,0.005813,-0.000373,0.999976,0.006884,-0.005811,-0.006886,0.999959 0.298992,0.060047,0.565875  0
```

### Multimercluster
The `easy-multimercluster` module is designed for multimer-level structural clustering(supported input formats: PDB/mmCIF, flat or gzipped). By default, easy-multimercluster generates three output files with the following prefixes: (1) `_cluster.tsv`, (2) `_rep_seq.fasta` and (3) `_cluster_report`.  The first file (1) is a [tab-separated](#tab-separated-multimercluster) file describing the mapping from representative multimer to member, while the second file (2) contains only [representative sequences](#representative-multimer-fasta). The third file (3) is also a [tab-separated](#filtered-search-result) file describing filtered alignments.

Make sure chain names in PDB/mmcIF files does not contain underscores(_).

    foldseek easy-multimercluster example/ clu tmp --multimer-tm-threshold 0.65 --chain-tm-threshold 0.5 --interface-lddt-threshold 0.65

#### Output MultimerCluster
##### Tab-separated multimercluster
```
5o002	   5o002
194l2	   194l2
194l2	   193l2
10mh121	 10mh121
10mh121	 10mh114
10mh121	 10mh119
```
##### Representative multimer fasta
```
#5o002
>5o002_A
SHGK...R
>5o002_B
SHGK...R
#194l2
>194l2_A0
KVFG...L
>194l2_A6
KVFG...L
#10mh121
...
```
##### Filtered search result
The `_cluster_report` contains `qcoverage, tcoverage, multimer qTm, multimer tTm, interface lddt, ustring, tstring` of alignments after filtering and before clustering. 
```
5o0f2	5o0f2	1.000	1.000	1.000	1.000	1.000	1.000,0.000,0.000,0.000,1.000,0.000,0.000,0.000,1.000	0.000,0.000,0.000
5o0f2	5o0d2	1.000	1.000	0.999	0.992	1.000	0.999,0.000,-0.000,-0.000,0.999,-0.000,0.000,0.000,0.999	-0.004,-0.001,0.084
5o0f2	5o082	1.000	0.990	0.978	0.962	0.921	0.999,-0.025,-0.002,0.025,0.999,-0.001,0.002,0.001,0.999	-0.039,0.000,-0.253
```
The query and target coverages here represent the sum of the coverages of all aligned chains, divided by the total query and target multimer length respectively.

#### Important multimer cluster parameters

| Option            | Category        | Description                                                                                               |
|-------------------|-----------------|-----------------------------------------------------------------------------------------------------------|
| -e              | Sensitivity     | List matches below this E-value (range 0.0-inf, default: 0.001); increasing it reports more distant structures |
| --alignment-type| Alignment       | 0: 3Di Gotoh-Smith-Waterman (local, not recommended), 1: TMalign (global, slow), 2: 3Di+AA Gotoh-Smith-Waterman (local, default) |
| -c              | Alignment  | List matches above this fraction of aligned (covered) residues (see --cov-mode) (default: 0.0); higher coverage = more global alignment |
| --cov-mode      | Alignment  | 0: coverage of query and target (cluster multimers only with same chain numbers), 1: coverage of target, 2: coverage of query |
| --multimer-tm-threshold      | Alignment  | accept alignments with multimer alignment TMscore > thr |
| --chain-tm-threshold      | Alignment  | accept alignments if every single chain TMscore > thr |
| --interface-lddt-threshold      | Alignment  | accept alignments with an interface LDDT score > thr |

## Main Modules
- `easy-search`       fast protein structure search  
- `easy-cluster`      fast protein structure clustering  
- `easy-multimersearch`       fast protein multimer-level structure search  
- `easy-multimercluster`       fast protein multimer-level structure clustering  
- `createdb`          create a database from protein structures (PDB,mmCIF, mmJSON)
- `databases`         download pre-assembled databases

## Examples
### Rescore aligments using TMscore
The easiest way to get the alignment TMscore normalized by min(alnLen,qLen,targetLen) as well as a rotation matrix is through the following command:
```
foldseek easy-search example/ example/ aln tmp --format-output query,target,alntmscore,u,t
```

Alternatively, it is possible to compute TMscores for the kind of alignment output (e.g., 3Di+AA) using the following commands: 
```
foldseek createdb example/ targetDB
foldseek createdb example/ queryDB
foldseek search queryDB targetDB aln tmpFolder -a
foldseek aln2tmscore queryDB targetDB aln aln_tmscore
foldseek createtsv queryDB targetDB aln_tmscore aln_tmscore.tsv
```

Output format `aln_tmscore.tsv`: query and target identifiers, TMscore, translation(3) and rotation vector=(3x3)

### Query centered multiple sequence alignment 
Foldseek can output multiple sequence alignments in a3m format using the following commands. 
To convert a3m to FASTA format, the following script can be used [reformat.pl](https://raw.githubusercontent.com/soedinglab/hh-suite/master/scripts/reformat.pl) (`reformat.pl in.a3m out.fas`).

```
foldseek createdb example/ targetDB
foldseek createdb example/ queryDB
foldseek search queryDB targetDB aln tmpFolder -a
foldseek result2msa queryDB targetDB aln msa --msa-format-mode 6
foldseek unpackdb msa msa_output --unpack-suffix a3m --unpack-name-mode 0
```

```

Contents of foldseek/bin/foldseek:
```
[Could not decode file contents]

```

Contents of config/sabdab.yaml:
```
---
# General settings
seed: 2025                 # Seed for reproducibility
model_name: DiffAbXL       # Name of the model
debug: False               # Debug mode: If True, a subset of data is used for quick testing
wandb: False               # Use Weights and Biases for logging
load_val_test: True        # Load validation and test sets during training; False for data pre-processing
reset: False               # To reset the database

# Data transformation settings
is_transform: True         # Apply transformations to the data
antigen: "ag"              # Antigen name (placeholder used here)
scheme: chothia            # Sequence alignment scheme (e.g., chothia)

# Paths for data storage and retrieval
paths:
    data: ./data/
    results: ./results/

# Task configuration
task: codesign_single      # Task options: codesign_single, codesign_fv, fixbb, strpred

# CDR length perturbation settings
perturb_length: True       # Allow perturbation of CDR lengths during training
min_length: 5              # Minimum CDR length
shorten_by: 2              # Maximum number of residues to shorten CDRs by
extend_by: 2               # Maximum number of residues to extend CDRs by

# Masking settings for CDR regions
cdrs_to_mask: [3]          # CDRs to mask during training; used in sampling

# Data transformations applied during processing
# Available options: mask_cdrs, merge_chains, patch_around_anchor, mask_ab (for FV codesigning)
transform:
  - mask_cdrs
  - merge_chains
  - patch_around_anchor

# Training settings
scheduler: True            # Use a learning rate scheduler
scheduler_type: plateau     # Type of scheduler (e.g., plateau)
validate: True              # Run validation during training
epochs: 10                 # Total number of training epochs
nth_epoch: 1               # Validate every nth epoch
validation_size: 20        # Size of validation set
batch_size: 8              # Training batch size
model_save_freq: 1         # Frequency to save the model (every n epochs)
learning_rate: 0.0001      # Initial learning rate
min_lr: 1.0e-5             # Minimum learning rate allowed by scheduler
patience: 1                # Scheduler patience (epochs without improvement)
max_grad_norm: 100         # Maximum gradient norm for clipping

# Loss weights for different tasks
loss_weights:
  rot: 1.0                 # Weight for rotational loss
  pos: 1.0                 # Weight for positional loss
  seq: 1.0                 # Weight for sequence loss
  aff: 1.0                 # Weight for affinity loss

# Noising scheme for sequence generation
noising_scheme: uniform    # Scheme for adding noise to sequence during training

# Sequence length definitions for Fv region
heavy_max_seq: 150         # Maximum sequence length for the heavy chain
light_max_seq: 150         # Maximum sequence length for the light chain
cdr3_max_seq: 30           # Maximum length for CDR3
max_num_heavyatoms: 15     # Maximum number of heavy atoms in a residue
max_aa_types: 24           # Total number of amino acid types (including extras)
num_aa_types: 20           # Standard amino acids
max_chain_types: 10        # Maximum number of chain types

# Atom inclusion settings
num_atoms: 15              # Number of atoms to include (max is 15, representing the backbone and side chains)

# Diffusion model parameters
ns_bias: 0.01              # Bias
residue_dim: 128           # Dimension of residue embedding
pair_dim: 64               # Dimension for pair embeddings
num_steps: 100             # Number of diffusion steps
num_layers: 6              # Number of layers in the diffusion model
position_mean:             # Mean position for atom placement
  - 0.0
  - 0.0
  - 0.0
position_scale:            # Scale for atom positions
  - 10.0

# Training options
train_structure: True      # Train on structure
train_sequence: True       # Train on sequence

# Antibody-antigen interaction parameters
contact_distance: 6        # Maximum distance (in √Ö) for defining contacts between antigen and antibody

# 'fragment_type': {'heavy': 1, 'light_kappa': 2, 'light_lambda': 3, 'antigen': 4}

# Fragment type IDs for different chains
fragment_type:
  heavy: 1                 # ID for heavy chain
  light_kappa: 2           # ID for light chain
  light_lambda: 4
  antigen: 3               # ID for antigen

# SabDab database filtering settings
resolution_threshold: 4.0  # Maximum allowed resolution (in √Ö) for structures
ag_types:                  # Types of antigens to include
  - null
  - protein
  - protein | protein
  - protein | protein | protein
  - protein | protein | protein | protein
  - protein | protein | protein | protein | protein

# Test set configurations
test_set:
  - sars-cov-2 receptor binding domain
  - hiv-1 envelope glycoprotein gp160
  - mers s
  - influenza a virus
  - cd27 antigen

# Sampling related options
sampling:
  mode: "design_cdrs"      # Sampling mode: design_cdrs, design_fv, optimize_ab
  sample_structure: true   # Whether to sample structure
  sample_sequence: true    # Whether to sample sequence
  cdrs_to_mask: [3]        # CDRs to mask during sampling
  num_samples: 100         # Number of samples to generate
  optimize_steps:          # Steps for optimization (if optimize_ab is enabled)
    - 100
  batch_size: 20           # Batch size during sampling

# Miscellaneous settings
antibody_only: False       # If True, only the antibody will be considered
input_error: True          # Adjust for input errors
patch_size: 200            # Patch size for structure generation
antigen_size: 200          # Size of antigen to consider

# Dataset settings
dataset_to_use: sabdab     # Dataset to use (e.g., sabdab)
use_maxlength: False       # Whether to enforce a maximum sequence length
max_length: 450            # Maximum sequence length allowed

# Hardware and logging configurations
num_gpus: 4                # Number of GPUs to use for training
log_every_n_steps: 100     # Log training metrics every n steps
val_check_interval: 0.1    # Interval (as a fraction of an epoch) to check validation

```

Contents of src/model.py:
```
"""
Author: Talip Ucar
email: ucabtuc@gmail.com

Description: DiffAbXL wrapper class.
"""
import gc
import os
import torch
import numpy as np
import pandas as pd
from torch.nn.utils import clip_grad_norm_
import torch.nn.functional as F
from torch.optim.lr_scheduler import ReduceLROnPlateau
from tqdm import tqdm

from utils.model_utils import DiffAbXL
from utils.utils import set_seed, set_dirs
from utils.utils_diff import move2device
from utils.loss_functions import sum_weighted_losses
import lightning as L


torch.autograd.set_detect_anomaly(True)


class DiffAbXLWrapper(L.LightningModule):
    """
    Model: Trains DiffAbXL. This wrapper class manages the training and validation
    steps, optimizer configuration, and memory management for DiffAbXL models.

    Parameters
    ----------
    config : dict
        Configuration dictionary containing model parameters and settings.
    """

    def __init__(self, config):
        """
        Initialize the DiffAbXLWrapper model wrapper class.

        Parameters
        ----------
        config : dict
            Configuration dictionary containing model parameters and settings.
        """
        super().__init__()
        self.config = config
        self.model_dict = {}
        self.loss = {
            "tloss_b": [],
            "seqloss_b": [],
            "rotloss_b": [],
            "posloss_b": [],
            "grad": [],
            "vtloss_b": [],
            "vseqloss_b": [],
            "vrotloss_b": [],
            "vposloss_b": []
        }
        self.automatic_optimization = True  # Enable automatic optimization in Lightning

        # Set random seed and directories
        set_seed(self.config)
        set_dirs(self.config)

        # Initialize model and paths
        self._set_paths()
        self.set_diffabxl()
        self.print_model_summary()

    def set_diffabxl(self):
        """Sets up the DiffAbXL model and moves it to the appropriate device."""
        self.encoder = DiffAbXL(self.config)
        self.encoder.to(self.device)
        self.model_dict.update({"encoder": self.encoder})

    def clean_up_memory(self, losses):
        """
        Frees memory by deleting loss variables and running garbage collection.

        Parameters
        ----------
        losses : list
            List of loss tensors to delete and clean up.
        """
        for loss in losses:
            del loss
        gc.collect()

    def training_step(self, batch, batch_idx):
        """
        Executes a single training step. It computes the loss, performs a backward pass,
        and updates the model parameters.

        Parameters
        ----------
        batch : dict
            Input data batch.
        batch_idx : int
            Index of the batch.

        Returns
        -------
        torch.Tensor
            Computed loss for the training step.
        """
        data = move2device(batch, self.config['device'])

        # Forward pass
        loss_all = self.encoder(data)

        # Compute the overall loss
        enc_loss = sum_weighted_losses(loss_all, self.config['loss_weights'])

        # Log the individual losses
        self.loss["tloss_b"].append((loss_all['seq'].sum().item() + loss_all['rot'].sum().item() + loss_all['pos'].sum().item()))
        self.loss["seqloss_b"].append(loss_all['seq'].sum().item())
        self.loss["rotloss_b"].append(loss_all['rot'].sum().item())
        self.loss["posloss_b"].append(loss_all['pos'].sum().item())

        self.log("Tot", self.loss['tloss_b'][-1], on_step=True, on_epoch=True, prog_bar=True, logger=True)
        self.log("Pos", self.loss['posloss_b'][-1], on_step=True, on_epoch=True, prog_bar=True, logger=True)
        self.log("Rot", self.loss['rotloss_b'][-1], on_step=True, on_epoch=True, prog_bar=True, logger=True)
        self.log("Seq", self.loss['seqloss_b'][-1], on_step=True, on_epoch=True, prog_bar=True, logger=True)

        return enc_loss

    def validation_step(self, batch, batch_idx):
        """
        Executes a single validation step. It computes and records the validation losses.

        Parameters
        ----------
        batch : dict
            Input data batch.
        batch_idx : int
            Index of the batch.

        Returns
        -------
        torch.Tensor
            The computed loss for the validation step.
        """
        loss, loss_all = self.step(batch)

        # Save validation losses
        self.loss["vtloss_b"].append((loss_all['seq'].sum().item() + loss_all['rot'].sum().item() + loss_all['pos'].sum().item()))
        self.loss["vseqloss_b"].append(loss_all['seq'].sum().item())
        self.loss["vrotloss_b"].append(loss_all['rot'].sum().item())
        self.loss["vposloss_b"].append(loss_all['pos'].sum().item())

        return loss

    def step(self, batch):
        """
        Computes the loss for a given data batch.

        Parameters
        ----------
        batch : dict
            Input data batch.

        Returns
        -------
        tuple
            Tuple of total loss and individual loss components.
        """
        data = move2device(batch, self.config['device'])
        loss_all = self.encoder(data)
        loss = sum_weighted_losses(loss_all, self.config['loss_weights'])

        return loss, loss_all

    def print_model_summary(self):
        """
        Prints a summary of the model architecture and its parameters.
        """
        description = f"{40 * '-'}Summary of the models:{40 * '-'}\n"
        description += f"{self.encoder}\n"
        description += f"{100 * '*'}\n"
        self.config["total_params"] = str(round(sum(p.numel() for _, model in self.model_dict.items() for p in model.parameters()) / 1e6, 2)) + ' Million'
        description += f"Total number of trainable parameters: {self.config['total_params']}\n"
        description += f"{100 * '*'}\n"
        print(description)

    def _set_paths(self):
        """
        Sets up the directory paths for saving results, models, plots, and losses.
        """
        self._results_path = os.path.join(self.config["paths"]["results"], self.config["experiment"])
        self._model_path = os.path.join(self._results_path, "training", self.config["task"], "model")
        self._plots_path = os.path.join(self._results_path, "training", self.config["task"], "plots")
        self._loss_path = os.path.join(self._results_path, "training", self.config["task"], "loss")

    def configure_optimizers(self):
        """
        Sets up the AdamW optimizer and learning rate scheduler.

        Returns
        -------
        dict
            Dictionary containing optimizer and learning rate scheduler configuration.
        """
        optimizer = torch.optim.AdamW(self.parameters(), lr=self.config["learning_rate"], betas=(0.9, 0.999), weight_decay=0)
        scheduler = ReduceLROnPlateau(optimizer, factor=0.8, patience=self.config["patience"], min_lr=self.config["min_lr"])
        return {'optimizer': optimizer, 'lr_scheduler': scheduler, 'monitor': 'Tot_epoch'}

```

Contents of assets/qr_img.png:
```
[Could not decode file contents]

```

Contents of assets/diffabxl_results2.png:
```
[Could not decode file contents]

```

Contents of assets/diffabxl_results1.png:
```
[Could not decode file contents]

```

